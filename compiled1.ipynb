{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "stop = stop + punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ModPosTag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def simple_clean(words):\n",
    "#     output_words = [w.lower() for w in words if not w.lower() in stop]\n",
    "#     return output_words\n",
    "\n",
    "def simple_clean(words):\n",
    "    output_words = [w for w in words if not w in stop]\n",
    "    return output_words\n",
    "\n",
    "\n",
    "# def complex_clean(words):\n",
    "#     output_words = []\n",
    "#     for w in words:\n",
    "#         if w.lower() not in stop:\n",
    "#             pos = pos_tag([w])\n",
    "#             clean_w = lemmatizer.lemmatize(w, pos = ModPosTag(pos[0][1]))\n",
    "#             output_words.append(clean_w.lower())\n",
    "#     return output_words\n",
    "\n",
    "# remove lemetize\n",
    "def complex_clean(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w not in stop:\n",
    "            pos = pos_tag([w])\n",
    "            clean_w = lemmatizer.lemmatize(w, pos = ModPosTag(pos[0][1]))\n",
    "            output_words.append(clean_w)\n",
    "    return output_words\n",
    "\n",
    "\n",
    "def read_words(words_dir):\n",
    "\n",
    "    files = [os.path.join(words_dir, fi) for fi in os.listdir(words_dir)]\n",
    "\n",
    "    #features_matrix = np.zeros((len(files), 3000))\n",
    "    docID = 0;\n",
    "    all_words = []\n",
    "    all_words_heading = []\n",
    "    major_words_abstract = []\n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            words_abstract = []\n",
    "            for i, line in enumerate(fi):\n",
    "                if (i == 0):\n",
    "                    temp = line.split()\n",
    "                    temp1 = simple_clean(temp)\n",
    "                    \n",
    "                    words_abstract += temp1\n",
    "                    all_words_heading += temp1\n",
    "                else:\n",
    "                    temp = line.split()\n",
    "                    temp1 = complex_clean(temp)\n",
    "                    print(fil)\n",
    "                    print()\n",
    "                    print(temp1)\n",
    "                    words_abstract += temp1\n",
    "                    all_words += temp1\n",
    "\n",
    "            major_words_abstract.append(words_abstract)\n",
    "            len(all_words)\n",
    "    return major_words_abstract, all_words, all_words_heading\n",
    "\n",
    "def tag_updater(df, variable_code):\n",
    "    for key, values in variable_code.items():\n",
    "        temp = str(key)\n",
    "        area = variable_code[key]\n",
    "        for val in area:\n",
    "            df.at[val-1, temp] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_tags(words_dir):\n",
    "    files = [os.path.join(words_dir, fi) for fi in os.listdir(words_dir)]\n",
    "\n",
    "    # features_matrix = np.zeros((len(files), 3000))\n",
    "    docID = 0;\n",
    "    tagss = set()\n",
    "    for fil in files:\n",
    "        docID+=1\n",
    "        with open(fil) as fi:\n",
    "            for i, line in enumerate(fi):\n",
    "                temp = line.split(',')\n",
    "                tagss.update(temp)\n",
    "    return docID, tagss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "\n",
    "def read_files(words_directory, tags_directory):\n",
    "\n",
    "    wo = [os.path.join(words_directory, wi) for wi in os.listdir(words_directory)]\n",
    "    ta = [os.path.join(tags_directory, ti) for ti in os.listdir(tags_directory)]\n",
    "    ctr=0\n",
    "    for (ab, t) in zip(wo, ta):\n",
    "        ctr +=1\n",
    "        with open(t) as su:\n",
    "            for i, line in enumerate(su):\n",
    "                tag = line.split(',')\n",
    "                for q in tag:\n",
    "                    if q not in mydict:\n",
    "                        mydict[q] = []\n",
    "                    mydict[q].append(ctr)\n",
    "\n",
    "    return mydict,ctr\n",
    "\n",
    "def extract_features(Words, features):\n",
    "    feature_matrix = np.zeros((len(Words), len(features)))\n",
    "    docID = 0\n",
    "    for doc in Words:\n",
    "        for word in doc:\n",
    "            for i in range(len(features)):\n",
    "                if features[i] == word:\n",
    "                    wordID = i\n",
    "                    feature_matrix[docID, wordID] += 1\n",
    "        docID = docID + 1\n",
    "    np.shape(feature_matrix)\n",
    "    print(feature_matrix)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\1.txt\n",
      "\n",
      "['There', 'many', 'study', 'researcher', 'attempt', 'classify', 'student', 'attentiveness.', 'Many', 'approach', 'depend', 'qualitative', 'analysis', 'lack', 'quantitative', 'analysis.', 'Therefore,', 'work', 'focus', 'bridging', 'gap', 'qualitative', 'quantitative', 'approach', 'classify', 'student', 'attentiveness.', 'Thus,', 'research', 'applies', 'machine', 'learn', 'algorithm', '(K-means', 'SVM)', 'automatically', 'classify', 'student', 'attentive', 'inattentive', 'use', 'data', 'consumer', 'RGB-D', 'sensor.', 'Results', 'research', 'use', 'improve', 'teach', 'strategy', 'instructor', 'level', 'aid', 'instructor', 'implement', 'personalize', 'learn', 'systems,', 'National', 'Academy', 'Engineering', 'Grand', 'Challenge.', 'This', 'research', 'applies', 'machine', 'learn', 'algorithm', 'educational', 'setting.', 'Data', 'algorithm', 'use', 'instructor', 'provide', 'valuable', 'feedback', 'effectiveness', 'instructional', 'strategy', 'pedagogies.', 'Instructors', 'use', 'feedback', 'improve', 'instructional', 'strategies,', 'student', 'benefit', 'achieve', 'improve', 'learn', 'subject', 'mastery.', 'Ultimately,', 'result', \"students'\", 'increase', 'ability', 'work', 'respective', 'areas.', 'Broadly,', 'work', 'help', 'advance', 'effort', 'many', 'area', 'education', 'instruction.', 'It', 'expect', 'improve', 'instructional', 'strategy', 'implement', 'personalize', 'learn', 'help', 'create', 'competent,', 'capable,', 'prepared', 'person', 'available', 'future', 'workforce.']\n",
      "abstract\\10.txt\n",
      "\n",
      "['To', 'assure', 'cyber', 'security', 'enterprise,', 'typically', 'SIEM', '(Security', 'Information', 'Event', 'Management)', 'system', 'place', 'normalize', 'security', 'event', 'different', 'preventive', 'technology', 'flag', 'alerts.', 'Analysts', 'security', 'operation', 'center', '(SOC)', 'investigate', 'alert', 'decide', 'truly', 'malicious', 'not.', 'However,', 'generally', 'number', 'alert', 'overwhelm', 'majority', 'false', 'positive', 'exceed', \"SOC's\", 'capacity', 'handle', 'alerts.', 'Because', 'this,', 'potential', 'malicious', 'attack', 'compromise', 'host', 'may', 'missed.', 'Machine', 'learn', 'viable', 'approach', 'reduce', 'false', 'positive', 'rate', 'improve', 'productivity', 'SOC', 'analysts.', 'In', 'paper,', 'develop', 'user-centric', 'machine', 'learn', 'framework', 'cyber', 'security', 'operation', 'center', 'real', 'enterprise', 'environment.', 'We', 'discus', 'typical', 'data', 'source', 'SOC,', 'work', 'flow,', 'leverage', 'process', 'data', 'set', 'build', 'effective', 'machine', 'learn', 'system.', 'The', 'paper', 'target', 'towards', 'two', 'group', 'readers.', 'The', 'first', 'group', 'data', 'scientist', 'machine', 'learn', 'researcher', 'cyber', 'security', 'domain', 'knowledge', 'want', 'build', 'machine', 'learn', 'system', 'security', 'operation', 'center.', 'The', 'second', 'group', 'audience', 'cyber', 'security', 'practitioner', 'deep', 'knowledge', 'expertise', 'cyber', 'security,', 'machine', 'learn', 'experience', 'wish', 'build', 'one', 'themselves.', 'Throughout', 'paper,', 'use', 'system', 'built', 'Symantec', 'SOC', 'production', 'environment', 'example', 'demonstrate', 'complete', 'step', 'data', 'collection,', 'label', 'creation,', 'feature', 'engineering,', 'machine', 'learn', 'algorithm', 'selection,', 'model', 'performance', 'evaluations,', 'risk', 'score', 'generation.']\n",
      "abstract\\11.txt\n",
      "\n",
      "['Recent', 'development', 'information', 'system', 'well', 'computerization', 'business', 'process', 'organization', 'lead', 'faster,', 'easy', 'accurate', 'data', 'analysis.', 'Data', 'mining', 'machine', 'learn', 'technique', 'use', 'increasingly', 'analysis', 'data', 'various', 'field', 'range', 'medicine', 'finance,', 'education', 'energy', 'applications.', 'Machine', 'learn', 'technique', 'make', 'possible', 'deduct', 'meaningful', 'information', 'data', 'process', 'data', 'mining.', 'Such', 'meaningful', 'significant', 'information', 'help', 'organization', 'establish', 'future', 'policy', 'sounder', 'basis,', 'gain', 'major', 'advantage', 'term', 'time', 'cost.', 'This', 'study', 'applies', 'classification', 'algorithm', 'use', 'data', 'mining', 'machine', 'learn', 'technique', 'data', 'obtain', 'individual', 'vocational', 'guidance', 'process,', 'try', 'determine', 'appropriate', 'algorithm.']\n",
      "abstract\\12.txt\n",
      "\n",
      "['Establishing', 'fatigue', 'crack', 'propagation', 'rate', 'key', 'forecasting', 'structure', 'fatigue', 'lifetime,', 'nine', 'parameter', 'fatigue', 'crack', 'propagation', 'rate', 'model', 'McEvily', 'model', 'widely', 'apply', 'present,', 'complex', 'realize', 'models,', 'partial', 'derivative', 'must', 'calculate', 'large', 'deviation', 'fit', 'static', 'parameter', 'actual', 'value', 'physical', 'conception', 'clear.', 'In', 'accordance', 'disadvantage', 'methods,', 'Based', 'optimum', 'parameter', 'selection', 'grid', 'search', 'cross', 'validation,', 'present', 'optimal', 'common', 'machine', 'learn', 'algorithm', '(least', 'square', 'support', 'vector', 'machine-LSSVM)', 'method', 'fatigue', 'crack', 'propagation', 'rate', 'forecast.', 'Complicated', 'strong', 'nonlinear', 'fatigue', 'crack', 'propagation', 'rate', 'curve', 'simulated', 'network', 'design', 'conformation', 'LSSVM', 'learn', 'algorithm', 'optimize', 'SVM', 'parameter', 'select', 'method', 'network', 'search', 'cross', 'validation.', 'Compared', 'error', 'output', 'value', 'optimize', 'model', 'output', 'value', 'nine', 'parameter', 'fatigue', 'crack', 'propagation', 'rate', 'fitting', 'model,', 'LSSVM', 'whose', 'parameter', 'optimize', 'cross', 'validation', 'excellent', 'ability', 'nonlinear', 'model', 'generalization.', 'It', 'provide', 'simple', 'feasible', 'intelligent', 'approach', 'material', 'fatigue', 'analysis.']\n",
      "abstract\\13.txt\n",
      "\n",
      "['With', 'rapid', 'development', 'e-commerce,', 'financial', 'data', 'mining', 'one', 'important', 'research', 'topic', 'data', 'mining', 'community.', 'Support', 'vector', 'machine', '(SVMs)', 'ensemble', 'learn', 'two', 'popular', 'technique', 'machine', 'learn', 'field.', 'In', 'paper,', 'support', 'vector', 'machine', 'ensemble', 'learn', 'use', 'classify', 'financial', 'data', 'respectively.', 'The', 'experiment', 'conduct', 'public', 'dataset', 'show', 'compare', 'SVMs,', 'ensemble', 'learn', 'achieves', 'obvious', 'improvement', 'performance.']\n",
      "abstract\\14.txt\n",
      "\n",
      "['Incremental', 'learn', 'technique', 'possible', 'solution', 'handle', 'vast', 'data', 'information', 'Internet', 'update', 'get', 'faster.', 'Support', 'vector', 'machine', 'work', 'well', 'incremental', 'learn', 'model', 'impressive', 'performance', 'outstanding', 'power', 'summarize', 'data', 'space', 'concise', 'way.', 'This', 'paper', 'proposes', 'heuristic', 'algorithm', 'incremental', 'learn', 'SVM', 'take', 'possible', 'impact', 'new', 'training', 'data', 'history', 'data', 'account.', 'The', 'idea', 'heuristic', 'algorithm', 'partition', 'difference', 'set', 'less', 'elements,', 'exist', 'hyperplane', 'much', 'closer', 'optimal', 'one.', 'New', 'support', 'vector', 'algorithm', 'consist', 'exist', 'support', 'vector', 'partition', 'difference', 'set', 'new', 'training', 'data', 'history', 'data', 'separate', 'hyperplane.', 'The', 'algorithm', 'improves', 'classification', 'precision', 'add', 'partition', 'difference', 'set,', 'decrease', 'computation', 'complexity', 'construct', 'new', 'classification', 'hyperplane', 'support', 'vector', 'set.', 'The', 'experimental', 'result', 'show', 'heuristic', 'algorithm', 'efficient', 'effective', 'improve', 'classification', 'precision.']\n",
      "abstract\\15.txt\n",
      "\n",
      "['IASS', 'integrate', 'anti-spam', 'system,', 'adopts', 'machine', 'learn', 'filter', 'spam', 'intelligent,', 'flexible,', 'precise,', 'self-adaptive', 'way.', 'The', 'method', 'linear', 'classification', 'base', 'optimal', 'separate', 'hyperplane', 'K-means', 'cluster', 'use', 'action', 'recognition', 'layer.', 'The', 'method', 'improve', 'naive', 'Bayes', 'use', 'content', 'analysis', 'layer.', 'The', 'application', 'machine', 'learn', 'help', 'improve', 'performance', 'IASS.']\n",
      "abstract\\16.txt\n",
      "\n",
      "['Single', 'machine', 'schedule', 'method', 'attract', 'lot', 'attention', 'recent', 'years.', 'Most', 'dynamic', 'single', 'machine', 'schedule', 'problem', 'practice', 'address', 'use', 'dispatch', 'rules.', 'However,', 'single', 'dispatch', 'rule', 'found', 'perform', 'well', 'important', 'criteria,', 'rule', 'take', 'account', 'status', 'resource', \"system's\", 'environment.', 'In', 'research,', 'intelligent', 'agent-based', 'single', 'machine', 'schedule', 'system', 'proposed,', 'agent', 'train', 'new', 'improve', 'Q-learning', 'algorithm.', 'In', 'schedule', 'system,', 'agent', 'selects', 'one', 'appropriate', 'dispatch', 'rule', 'machine', 'base', 'available', 'information.', 'The', 'agent', 'train', 'new', 'simulated', 'annealing-based', 'Q-learning', 'algorithm.', 'The', 'simulation', 'result', 'show', 'simulated', 'annealing-based', 'Q-learning', 'agent', 'able', 'learn', 'select', 'best', 'dispatch', 'rule', 'different', 'system', 'objectives.', 'The', 'result', 'also', 'indicate', 'simulated', 'annealing-based', 'Q-learning', 'agent', 'could', 'perform', 'well', 'criteria,', 'impossible', 'use', 'one', 'dispatch', 'rule', 'independently.']\n",
      "abstract\\17.txt\n",
      "\n",
      "['How', 'define', 'architecture', 'classifier', 'dynamically', 'one', 'major', 'research', 'topic', 'online', 'learning.', 'This', 'paper', 'present', 'new', 'online', 'learn', 'algorithm', 'Radial', 'Basis', 'Function', 'Network', 'name', 'Sensitivity', 'Based', 'Neurons', 'Growing', 'Pruning', 'Method', 'RBF', 'network', '(SBGAP).', 'The', 'performance', 'SBGAP', 'evaluate', 'experimentally', 'compare', 'accuracy', 'number', 'neuron', 'exist', 'methods.', 'The', 'experimental', 'result', 'show', 'SBGAP', 'achieve', 'litter', 'high', 'accuracy', 'few', 'hidden', 'unit', 'situations.']\n",
      "abstract\\18.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'new', 'fuzzy', 'multicategory', 'support', 'vector', 'machine', '(FMSVM)', 'classifier.', 'The', 'main', 'idea', 'propose', 'FMSVM', 'us', 'knowledge', 'ambiguity', 'associate', 'membership', 'sample', 'give', 'class', 'relative', 'location', 'sample', 'origin.', 'Compared', 'exist', 'SVMs,', 'new', 'propose', 'FMSVM', 'us', 'L2-norm', 'objective', 'function', 'improvement', 'aspect', 'classification', 'accuracy', 'reduce', 'effect', 'noise', 'outliers.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\19.txt\n",
      "\n",
      "['This', 'paper', 'investigates', 'improve', 'fuzzy', 'multicategory', 'support', 'vector', 'machine', 'classifier', '(IFMSVM).', 'It', 'us', 'knowledge', 'ambiguity', 'associate', 'membership', 'data', 'sample', 'give', 'class', 'relative', 'location', 'origin,', 'improve', 'classification', 'performance', 'high', 'generalization', 'capability.', 'In', 'aspects,', 'classify', 'accuracy', 'new', 'algorithm', 'well', 'classical', 'support', 'vector', 'classification', 'algorithms.', 'Numerical', 'simulation', 'show', 'feasibility', 'effectiveness', 'algorithm']\n",
      "abstract\\2.txt\n",
      "\n",
      "['This', 'paper', 'firstly', 'analysis', 'actual', 'underwriting', 'method', 'Chinese', 'life', 'insurance', 'companies,', 'point', 'merit', 'shortcoming', 'methods.', 'Then', 'incomplete', 'database', 'insurance', 'company', 'mine', 'data', \"mining's\", 'association', 'rule', 'algorithm.', 'Thirdly', 'support', 'vector', 'machine', '(SVM)', 'apply', 'underwriting', 'process', 'classify', 'applicants.', 'Finally', 'direction', 'improve', 'algorithm', 'point', 'out.', 'The', 'algorithm', 'propose', 'paper', 'promising', 'future', 'underwriting', 'process.']\n",
      "abstract\\20.txt\n",
      "\n",
      "['Active', 'learn', 'hot', 'topic', 'machine', 'learn', 'field.', 'The', 'main', 'task', 'active', 'learn', 'automatically', 'select', 'representative', 'instance', 'efficiently', 'reduce', 'sample', 'complexity.', 'This', 'paper', 'present', 'brief', 'survey', 'active', 'learn', 'regard', 'selection', 'methods,', 'query', 'strategies,', 'application', 'related', 'works.']\n",
      "abstract\\21.txt\n",
      "\n",
      "['Analyzed', 'theoretically,', '/spl', 'nu/-SVM', 'found', 'over-dependent', 'training', 'sample,', 'even', 'sample', 'value.', 'This', 'dependence', 'would', 'result', 'time', 'training,', 'support', 'vector', 'decision', 'time.', 'In', 'order', 'overcome', 'problem,', 'propose', 'new', '/spl', 'nu/-SVM.', 'This', 'new', '/spl', 'nu/-SVM', 'multiplies', 'slack', 'variable', 'objective', 'function', 'weight', 'factor,', 'automatically', 'computes', 'weight', 'factor', 'number', 'correspond', 'sample', 'value', 'training.', 'Theoretical', 'analysis', 'result', 'experiment', 'show', 'new', '/spl', 'nu/-SVM', 'classification', 'precision', 'rate', 'standard', '/spl', 'nu/-SVM', 'new', '/spl', 'nu/-SVM', 'faster', '/spl', 'nu/-SVM', 'training', 'decision', 'training', 'set', 'value', 'samples.']\n",
      "abstract\\22.txt\n",
      "\n",
      "['In', 'paper,', 'use', 'deep', 'learn', 'method,', 'restrict', 'Boltzmann', 'machine,', 'nonlinear', 'system', 'identification.', 'The', 'neural', 'model', 'deep', 'architecture', 'generate', 'random', 'search', 'method.', 'The', 'initial', 'weight', 'deep', 'neural', 'model', 'obtain', 'restrict', 'Boltzmann', 'machines.', 'To', 'identify', 'nonlinear', 'systems,', 'propose', 'special', 'unsupervised', 'learn', 'method', 'input', 'data.', 'The', 'normal', 'supervise', 'learn', 'use', 'train', 'weight', 'output', 'data.', 'The', 'modify', 'algorithm', 'validate', 'model', 'two', 'benchmark', 'systems.']\n",
      "abstract\\23.txt\n",
      "\n",
      "['In', 'order', 'accurately', 'build', \"learner's\", 'learn', 'style', 'E-Learning,', 'accord', 'need', 'preference', 'provide', 'personalize', 'learn', 'material', 'harmonious', 'human-computer', 'interaction', 'environment.', 'This', 'paper', 'combine', 'Felder-Silverman', 'learn', 'style', 'support', 'vector', 'machine', 'technology,', 'use', 'machine', 'learn', 'technology', 'learner', 'build', 'dynamic', 'learn', 'style.', 'Through', 'analysis', 'Emotion', 'recognition', 'interaction', 'personalize', 'E-Learning', 'base', 'statistical', 'learn', 'theory', 'support', 'vector', 'machine', 'technology,', 'demonstrates', 'correctness', 'feasibility', 'use', 'support', 'vector', 'machine', 'build', 'learn', 'styles.', 'The', 'combination', 'support', 'vector', 'machine,', 'emotion', 'recognition', 'interaction', 'personalize', 'E-Learning', 'make', 'great', 'contribution', 'build', 'human-computer', 'interaction', 'environment.']\n",
      "abstract\\24.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'Learning', 'become', 'central', 'problem', 'try', 'understand', 'intelligence', 'try', 'develop', 'intelligent', 'machines.', 'The', 'paper', 'outline', 'previous', 'effort', 'develop', 'machine', 'learn.', 'It', 'sketch', \"authors's\", 'work', 'statistical', 'learn', 'theory', 'theoretical', 'result', 'problem', 'classification', 'function', 'approximation', 'connect', 'regularization', 'theory', 'support', 'vector', 'machines.', 'The', 'main', 'application', 'focus', 'classification', '(and', 'regression)', 'various', 'domains-such', 'sound,', 'text,', 'video', 'bioinformatics.', 'In', 'particular,', 'paper', 'describe', 'evolution', 'trainable', 'object', 'detection', 'system', 'classify', 'objects-such', 'face', 'people', 'cars-in', 'complex', 'clutter', 'images.', 'Finally,', 'speculates', 'implication', 'research', 'brain', 'work', 'review', 'data', 'provide', 'glimpse', '3D', 'object', 'represent', 'visual', 'cortex.']\n",
      "abstract\\25.txt\n",
      "\n",
      "['Due', 'complexity', 'flexibility', 'natural', 'language,', 'automatic', 'linguistic', 'knowledge', 'acquisition', 'application', 'research', 'becomes', 'difficult.', 'In', 'paper,', 'present', 'machine', 'learn', 'method', 'automatically', 'acquire', 'Chinese', 'linguistic', 'ontology', 'knowledge', 'typical', 'corpus.', 'This', 'study,', 'first,', 'define', 'description', 'frame', 'Chinese', 'linguistic', 'ontology', 'knowledge,', 'then,', 'automatically', 'acquire', 'usage', 'Chinese', 'word', 'co-occurrence', 'context', 'use', 'semantic,', 'pragmatics,', 'syntactic,', 'etc', 'corpus,', 'final,', 'information', 'representation', 'act', 'Chinese', 'linguistic', 'ontology', 'knowledge', 'bank.', 'We', 'complete', 'two', 'group', 'experiments,', 'i.e.', 'document', 'similarity', 'computing,', 'text', 'reorder', 'information', 'retrieval.', 'Compared', 'previous', 'works,', 'propose', 'method', 'solves', 'inferior', 'precision', 'nature', 'language', 'processing.']\n",
      "abstract\\26.txt\n",
      "\n",
      "['The', 'recent', 'success', 'commercial', 'cognitive', 'AI', 'application', 'cast', 'spotlight', 'knowledge', 'graph', 'benefit', 'consume', 'structure', 'semantic', 'data.', 'Today,', 'knowledge', 'graph', 'ubiquitous', 'extent', 'organization', 'often', 'view', '“single', 'source', 'truth”', 'data', 'digital', 'artifacts.', 'In', 'organizations,', 'however,', 'Big', 'Data', 'come', 'many', 'different', 'form', 'include', 'time', 'series,', 'images,', 'unstructured', 'text,', 'often', 'suitable', 'efficient', 'storage', 'within', 'knowledge', 'graph.', 'This', 'paper', 'present', 'Semantics', 'Toolkit', '(SemTK),', 'framework', 'enables', 'access', 'polyglot-persistent', 'Big', 'Data', 'store', 'give', 'appearance', 'data', 'fully', 'capture', 'within', 'knowledge', 'graph.', 'SemTK', 'allows', 'data', 'store', 'across', 'multiple', 'storage', 'platform', '(e.g.,', 'Big', 'Data', 'store', 'Hadoop,', 'graph', 'databases,', 'semantic', 'triple', 'stores)', 'best-suited', 'platform', 'adopt', 'data', 'type', 'maintain', 'single', 'logical', 'interface', 'point', 'access,', 'thereby', 'give', 'user', 'knowledge-driven', 'veneer', 'across', 'data.', 'We', 'describe', 'ease', 'use', 'benefit', 'construct', 'query', 'polystore', 'knowledge', 'graph', 'SemTK', 'via', 'four', 'industrial', 'use', 'case', 'GE.']\n",
      "abstract\\27.txt\n",
      "\n",
      "['As', 'data', 'increase', 'explosively', 'due', 'development', 'social', 'network', 'cloud', 'computing,', 'new', 'challenge', 'storing,', 'processing,', 'analyze', 'large', 'volume', 'data.', 'The', 'traditional', 'technology', 'become', 'proper', 'solution', 'process', 'big', 'data', 'big', 'data', 'platform', 'begin', 'emerge.', 'It', 'certain', 'big', 'data', 'platform', 'help', 'user', 'develop', 'analysis', 'service', 'effectively.', 'However,', 'still', 'take', 'long', 'time', 'collect', 'data,', 'develop', 'algorithm', 'analytics', 'services.', 'We', 'present', 'collaborative', 'big', 'data', 'analytics', 'platform', 'big', 'data', 'service.', 'Developers', 'collaborate', 'platform', 'share', 'data,', 'algorithms,', 'services.', 'Therefore,', 'paper', 'describes', 'big', 'data', 'analytics', 'platform', 'effectively', 'support', 'manage', 'big', 'data', 'develop', 'analytics', 'algorithm', 'services,', 'collaborate', 'data', 'owners,', 'data', 'scientists,', 'service', 'developer', 'Web.', 'Finally,', 'introduce', 'CCTV', 'metadata', 'analytics', 'service', 'developed', 'platform.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\28.txt\n",
      "\n",
      "['The', 'rapid', 'converge', 'big', 'data', 'IoT', '(Internet', 'Things)', 'technology', 'provide', 'opportunity', 'area', 'road', 'traffic', 'applications.', 'In', 'paper,', 'discus', 'timeline', 'visualization', 'tool', 'enables', 'u', 'well', 'understand', 'traffic', 'behavior', 'road', 'traffic', 'big', 'data.']\n",
      "abstract\\29.txt\n",
      "\n",
      "['In', 'paper,', 'describe', 'ongoing', 'research', 'aim', 'define', 'Requirements', 'Engineering', 'Artefact', 'Model', '(REAM)', 'context', 'Big', 'Data', 'software', 'applications.', 'This', 'model', 'aim', 'provide', '“big', 'picture”', 'Requirements', 'Engineering', 'work', 'product', 'create', 'use', 'Big', 'Data', 'software', 'development', 'projects.', 'REAM', 'important', 'tool', 'use', 'reference', 'definition', 'domain-specific', 'RE', 'models,', 'system', 'life-cycle', 'process', 'artefact-centered', 'processes,', 'currently', 'bereft', 'Big', 'Data', 'Software', 'Engineering', 'research.']\n",
      "abstract\\3.txt\n",
      "\n",
      "['Decision', 'tree', 'induction', 'one', 'useful', 'approach', 'extract', 'classification', 'knowledge', 'set', 'feature-based', 'instances.', 'The', 'popular', 'heuristic', 'information', 'use', 'decision', 'tree', 'generation', 'minimum', 'entropy.', 'This', 'heuristic', 'information', 'serious', 'disadvantage-the', 'poor', 'generalization', 'capability', '[3].', 'Support', 'vector', 'machine', '(SVM)', 'classification', 'technique', 'machine', 'learn', 'base', 'statistical', 'learn', 'theory.', 'It', 'good', 'generalization.', 'Considering', 'relationship', 'classification', 'margin', 'support', 'vector', 'machine(SVM)', 'generalization', 'capability,', 'large', 'margin', 'SVM', 'use', 'heuristic', 'information', 'decision', 'tree,', 'order', 'improve', 'generalization', 'capability.', 'This', 'paper', 'proposes', 'decision', 'tree', 'induction', 'algorithm', 'base', 'large', 'margin', 'heuristic.', 'Comparing', 'binary', 'decision', 'tree', 'use', 'minimum', 'entropy', 'heuristic', 'information,', 'experiment', 'show', 'generalization', 'capability', 'improve', 'use', 'new', 'heuristic.']\n",
      "abstract\\30.txt\n",
      "\n",
      "['The', 'Federal', 'Big', 'Data', 'Working', 'Group', 'support', 'Federal', 'Big', 'Data', 'Initiative', 'endorse', 'Federal', 'Government', 'agencies.', 'This', 'work', 'group', 'us', 'meetups', 'onsite', 'virtual', 'participation', 'share', 'best', 'practice', 'implementation', 'Big', 'Data', 'application', 'government', 'science', 'communities.', 'Decision-makers', 'scientific', 'community', 'interact', 'data', 'science', 'order', 'take', 'advantage', 'Big', 'Data', 'transformation', 'information', 'use', 'science,', 'decision', 'support,', 'data', 'discovery', 'data', 'publishing.', 'The', 'work', 'group', 'federates', 'use', 'cases,', 'data', 'publications,', 'solution', 'technologies.', 'The', 'range', 'topic', 'illustrate', 'keynote', 'panel', 'discussion', 'recent', 'Big', 'Data', 'conference', 'summary', 'recent', 'work', 'group', 'meetups.']\n",
      "abstract\\31.txt\n",
      "\n",
      "['This', 'paper', 'outline', 'big', 'data', 'infrastructure', 'processing', 'data', 'streams.', 'Our', 'project', 'distribute', 'stream', 'compute', 'platform', 'provide', 'cost-effective', 'large-scale', 'big', 'data', 'service', 'develop', 'data', 'stream', 'management', 'system.', 'This', 'research', 'contributes', 'advance', 'feasibility', 'big', 'data', 'processing', 'distributed,', 'real-time', 'computation', 'even', 'overloaded.']\n",
      "abstract\\32.txt\n",
      "\n",
      "['With', 'continuous', 'increase', 'heterogeneous', 'multimedia', 'data,', 'question', 'access', 'big', 'multimedia', 'data', 'efficiently', 'become', 'crucial', 'importance.', 'In', 'order', 'provide', 'fast', 'access', 'complex', 'multimedia', 'data,', 'propose', 'approximate', 'content-based', 'feature', 'multimedia', 'object', 'mean', 'generative', 'models.', 'The', 'propose', 'gradient-based', 'signature', 'epitomize', 'high', 'quality', 'content-based', 'approximation', 'multimedia', 'object', 'facilitate', 'efficient', 'index', 'query', 'processing', 'large', 'scale.']\n",
      "abstract\\33.txt\n",
      "\n",
      "['In', 'paper,', 'address', 'problem', 'data', 'confidentiality', 'big', 'data', 'analytics.', 'In', 'many', 'fields,', 'much', 'useful', 'pattern', 'extract', 'apply', 'machine', 'learn', 'technique', 'big', 'data.', 'However,', 'data', 'confidentiality', 'must', 'protected.', 'In', 'many', 'scenarios,', 'data', 'confidentiality', 'could', 'well', 'prerequisite', 'data', 'shared.', 'We', 'present', 'scheme', 'provide', 'provable', 'secure', 'data', 'confidentiality', 'discus', 'various', 'technique', 'optimize', 'performance', 'system.']\n",
      "abstract\\34.txt\n",
      "\n",
      "['This', 'paper', 'analyze', 'challenge', 'data', 'management', 'army', 'data', 'engineering,', 'big', 'data', 'volume,', 'data', 'heterogeneous,', 'high', 'rate', 'data', 'generation', 'update,', 'high', 'time', 'requirement', 'data', 'processing,', 'widely', 'separate', 'data', 'sources.', 'We', 'discuss', 'disadvantage', 'traditional', 'data', 'management', 'technology', 'deal', 'problems.', 'We', 'also', 'highlight', 'key', 'problem', 'data', 'management', 'army', 'data', 'engineering', 'include', 'data', 'integration,', 'data', 'analysis,', 'representation', 'data', 'analysis', 'results,', 'evaluation', 'data', 'quality.']\n",
      "abstract\\35.txt\n",
      "\n",
      "['Data', 'everywhere,', 'non-expert', 'user', 'must', 'able', 'exploit', 'order', 'extract', 'knowledge,', 'get', 'insight', 'make', 'well-informed', 'decisions.', 'The', 'value', 'discover', 'knowledge', 'big', 'data', 'could', 'great', 'value', 'available', 'later', 'consumption', 'reusing.', 'In', 'paper,', 'present', 'infrastructure', 'allows', 'non-expert', 'user', '(i)', 'apply', 'user-friendly', 'data', 'mining', 'technique', 'big', 'data', 'sources,', '(ii)', 'share', 'result', 'Linked', 'Open', 'Data', '(LOD).', 'The', 'main', 'contribution', 'paper', 'approach', 'democratize', 'big', 'data', 'reuse', 'knowledge', 'gain', 'data', 'mining', 'process', 'semantically', 'annotate', 'LOD,', 'obtain', 'Linked', 'Open', 'Knowledge.', 'Our', 'work', 'base', 'model-driven', 'viewpoint', 'order', 'easily', 'deal', 'wide', 'diversity', 'open', 'data', 'formats.']\n",
      "abstract\\36.txt\n",
      "\n",
      "['This', 'paper', 'introduces', 'general', 'framework', 'support', 'data-driven', 'privacy-preserving', 'big', 'data', 'management', 'distribute', 'environments,', 'emerge', 'Cloud', 'settings.', 'The', 'propose', 'framework', 'view', 'alternative', 'classical', 'approach', 'privacy', 'big', 'data', 'ensure', 'via', 'security-inspired', 'protocol', 'check', 'several', '(protocol)', 'layer', 'order', 'achieve', 'desire', 'privacy.', 'Unfortunately,', 'injects', 'considerable', 'computational', 'overhead', 'overall', 'process,', 'thus', 'introduce', 'relevant', 'challenge', 'considered.', 'Our', 'approach', 'instead', 'try', 'recognize', '\"pedigree\"', 'suitable', 'summary', 'data', 'representative', 'compute', 'top', 'target', 'big', 'data', 'repositories,', 'hence', 'avoid', 'computational', 'overhead', 'due', 'protocol', 'checking.', 'We', 'also', 'provide', 'relevant', 'realization', 'framework', 'above,', 'so-called', 'Data-dRIven', 'aggregate-PROvenance', 'privacypreserving', 'big', 'Multidimensional', 'data', '(DRIPROM)', 'framework,', 'specifically', 'considers', 'multidimensional', 'data', 'case', 'interest.']\n",
      "abstract\\37.txt\n",
      "\n",
      "['Big', 'data', 'tsunami', 'hit', 'Malaysia', 'recently', 'awaken', 'industry', 'academy', 'community', 'aggressively', 'address', 'insight,', 'hindsight', 'foresight', 'challenge', 'ensure', 'Malaysia', 'among', 'top', 'world', 'player', 'big', 'data', 'information', 'economy', 'next', 'decade.', 'Rapid', 'development', 'Information', 'Communication', 'Technology', '(ICT)', 'era', 'significant', 'due', 'increase', 'number', 'user', 'access', 'data', 'keep', 'grow', 'time.', 'This', 'phenomenon', 'coin', 'big', 'data.', 'What', 'Big', 'data???', 'We', 'address', 'big', 'data', 'asset', 'need', 'unique', 'platform', 'deal', 'bizarre', 'behavior', 'datasets', 'whose', 'size', 'beyond', 'ability', 'typical', 'data', 'storage', 'manage,', 'mine', 'analyze', 'accordingly.', 'This', 'bizarre', 'behavior', 'require', 'three', 'main', 'personalities:', 'volume,', 'velocity,', 'variety', 'basically', 'need', 'new', 'architecture,', 'techniques,', 'algorithms,', 'analytics', 'uncover', 'golden', 'hidden', 'knowledge', 'information', 'obesity.', 'From', 'perspectives,', 'demonstrate', 'experience', 'set', 'Data', 'Science/Big', 'Data', 'platform,', 'algorithm', 'tool', 'align', 'big', 'data', 'plug', 'play', 'within', 'academic', 'environment', 'well', 'service', 'community', 'industries.']\n",
      "abstract\\38.txt\n",
      "\n",
      "['In', 'Big', 'Data', 'Era,', 'data', 'core', 'governmental,', 'institutional,', 'private', 'organization.', 'Efforts', 'gear', 'towards', 'extract', 'highly', 'valuable', 'insight', 'cannot', 'happen', 'data', 'poor', 'quality.', 'Therefore,', 'data', 'quality', '(DQ)', 'consider', 'key', 'element', 'Big', 'data', 'processing', 'phase.', 'In', 'stage,', 'low', 'quality', 'data', 'penetrate', 'Big', 'Data', 'value', 'chain.', 'This', 'paper,', 'address', 'data', 'quality', 'rule', 'discovery', '(DQR)', 'evaluation', 'quality', 'prior', 'Big', 'Data', 'pre-processing.', 'We', 'propose', 'DQR', 'discovery', 'model', 'enhance', 'accurately', 'target', 'pre-processing', 'activity', 'base', 'quality', 'requirements.', 'We', 'defined,', 'set', 'pre-processing', 'activity', 'associate', 'data', 'quality', 'dimension', \"(DQD's)\", 'automatize', 'DQR', 'generation', 'process.', 'Rules', 'optimization', 'apply', 'validate', 'rule', 'avoid', 'multi-passes', 'pre-processing', 'activity', 'eliminates', 'duplicate', 'rules.', 'Conducted', 'experiment', 'show', 'increase', 'quality', 'score', 'apply', 'discover', 'optimize', \"DQR's\", 'data.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\39.txt\n",
      "\n",
      "['Centers', 'Medicare', 'Medicaid', 'Services', '(CMS)', 'publishes', 'Medicare', 'Part', 'C', 'Star', 'Ratings', 'year', 'measure', 'quality', 'care', 'Medicare', 'Advantage', '(MA)', 'contracts.', 'One', 'key', 'measure', 'Complaints', 'Health', 'Plan,', 'capture', 'Complaints', 'Tracking', 'Module', '(CTM).', 'Complaints', 'result', 'CTM', 'rare', 'events:', 'MA', 'contract', '2-5', 'star', 'ratings,', 'number', 'complaint', 'every', '1,000', 'member', 'range', '.10', '1.84', 'last', '5', 'years.', 'Reducing', 'number', 'complaint', 'extremely', 'important', 'MA', 'plan', 'impact', 'CMS', 'reimbursement', 'MA', 'plans.', 'Forecasting', 'reduce', 'complaint', 'extremely', 'technically', 'challenge', 'task,', 'involves', 'ethic', 'consideration', \"patients'\", 'right', 'privacy.', 'In', 'research,', 'construct', 'big', 'data', 'analytics', 'framework', 'forecasting', 'rare', 'customer', 'complaints.', 'First,', 'built', 'big', 'data', 'ingestion', 'pipeline', 'Hadoop', 'platform:', 'a)', 'Ingest', 'MA', \"plan's\", 'customer', 'complaint', 'data', 'CTM', 'past', '3', 'years.', 'b)', 'Ingest', 'health', \"plan's\", 'call', 'center', 'data', 'MA', 'member', 'past', '3', 'years,', 'include', 'structure', 'data', 'unstructured', 'text', 'script', 'calls.', 'c)', 'Ingest', 'MA', \"members'\", 'medical', 'claims,', 'include', \"members'\", 'demographic', 'enrollment', 'history.', 'd)', 'Ingest', 'MA', \"members'\", 'pharmacy', 'claims.', 'e)', 'Integrate', 'unified', 'data', 'sources,', 'enrich', 'data', 'additional', 'engineer', 'feature', 'big', 'wide', 'table,', 'one', 'row', 'per', 'member', 'analysis', 'modeling.', 'Second,', 'design', 'unique', 'decision', 'tree', 'base', 'Large', 'Ensemble', 'Over-Sampling', '(LEOS)', 'algorithm,', 'mimic', 'random', 'forest', 'extreme', 'oversampling', 'target', 'class', 'increase', 'bias,', 'leverage', 'parallel', 'compute', 'Hadoop', 'cluster', 'generate', 'thousand', 'fix', 'size', 'training', 'data', 'sets,', 'dataset', 'training', 'decision', 'tree', 'similar', 'fix', 'tree', 'structure,', 'ensemble', 'them.', 'Third,', 'validate', 'framework', 'LEOS', 'learn', 'algorithm', 'real', 'data,', 'also', 'discuss', 'ethic', 'issue', 'encounter', 'handle', 'data', 'apply', 'finding', 'research.']\n",
      "abstract\\4.txt\n",
      "\n",
      "['Determination', 'model', 'complexity', 'challenge', 'issue', 'solve', 'computer', 'vision', 'problem', 'use', 'restrict', 'boltzmann', 'machine', '(RBMs).', 'Many', 'algorithm', 'feature', 'learn', 'depend', 'cross-validation', 'empirical', 'method', 'optimize', 'number', 'features.', 'In', 'work,', 'propose', 'learn', 'algorithm', 'find', 'optimal', 'model', 'complexity', 'RBMs', 'incrementing', 'hidden', 'layer.', 'The', 'propose', 'algorithm', 'compose', 'two', 'processes:', '1)', 'determine', 'incrementation', 'necessity', 'neuron', '2)', 'compute', 'number', 'additional', 'feature', 'increment.', 'Specifically,', 'propose', 'algorithm', 'us', 'normalize', 'reconstruction', 'error', 'order', 'determine', 'incrementation', 'necessity', 'prevent', 'unnecessary', 'increment', 'number', 'feature', 'training.', 'Our', 'experimental', 'result', 'demonstrate', 'propose', 'algorithm', 'converges', 'optimal', 'number', 'feature', 'single', 'layer', 'RBMs.', 'In', 'classification', 'results,', 'model', 'could', 'outperform', 'non-incremental', 'RBM.']\n",
      "abstract\\40.txt\n",
      "\n",
      "['Big', 'data', 'gathering', 'mining', 'pipeline', 'CRM', 'use', 'open-source']\n",
      "abstract\\40.txt\n",
      "\n",
      "['Customer', 'Relationship', 'Management', '(CRM)', 'currently', 'fast', 'grow', 'sector', 'enterprise', 'software,', 'estimate', 'increase', 'worldwide', '2017.', 'CRM', 'technology', 'increasingly', 'use', 'data', 'mining', 'primitive', 'across', 'multiple', 'applications.', 'At', 'time,', 'growth', 'big', 'data', 'lead', 'evolution', 'open', 'source', 'big', 'data', 'software', 'stack', '(primarily', 'power', 'Apache', 'software)', 'rival', 'traditional', 'enterprise', 'database', '(RDBMS)', 'stacks.', 'New', 'technology', 'Kafka,', 'Storm,', 'HBase', 'significantly', 'enrich', 'open', 'source', 'stack,', 'alongside', 'establish', 'technology', 'Hadoop', 'MapReduce', 'Mahout.', 'Today,', 'enterprise', 'choice', 'make', 'regard', 'stack', 'choose', 'power', 'big', 'data', 'applications.', 'However,', 'publish', 'study', 'literature', 'enterprise', 'big', 'data', 'pipeline', 'built', 'use', 'open', 'source', 'component', 'support', 'CRM.', 'Specific', 'question', 'enterprise', 'include:', 'data', 'process', 'analyze', 'pipelines?', 'What', 'building', 'block', 'pipelines?', 'How', 'long', 'step', 'processing', 'take?', 'In', 'work,', 'answer', 'question', 'large', 'scale', '(serving', '100M', 'customers)', 'industrial', 'CRM', 'pipeline', 'incorporates', 'data', 'mining,', 'serf', 'several', 'applications.', 'Our', 'pipeline', 'has,', 'broadly,', 'two', 'parts.', 'The', 'first', 'data', 'gathering', 'part', 'us', 'Kafka,', 'Storm,', 'HBase.', 'The', 'second', 'data', 'mining', 'part', 'us', 'Mahout', 'Hadoop', 'MapReduce.', 'We', 'also', 'provide', 'timing', 'common', 'task', 'second', 'part', 'data', 'preprocessing', 'machine', 'learning,', 'clustering,', 'reservoir', 'sampling,', 'frequent', 'itemset', 'extraction.']\n",
      "abstract\\41.txt\n",
      "\n",
      "['Big', 'data', 'penetrate', 'various', 'industry', 'business', 'functions,', 'become', 'important', 'factor', 'production', 'global', 'economy.', 'In', 'big', 'data', 'technology', 'system,', 'big', 'data', 'collection', 'basis.', 'The', 'storage,', 'analysis,', 'integration', 'visualization', 'unstructured', 'data', 'semi-structured', 'data', 'become', 'important', 'focus', 'big', 'data', 'innovation.', 'Traditional', 'structure', 'data', 'longer', 'core', 'big', 'data.', 'Based', 'life', 'cycle', 'theory,', 'use', 'new', 'digital', 'technology,', 'acquisition,', 'processing,', 'storage,', 'organization', 'copyright', 'protection,', 'cluster', 'high', 'concurrency', 'retrieval', 'dynamic', 'scheduling,', 'intelligent', 'digital', 'display,', 'coal', 'mine', 'industry', 'information', 'data', 'collect', 'integrated,', 'realize', 'centralize', 'management,', 'unified', 'retrieval', 'joint', 'exhibition', 'information', 'resources,', 'provide', 'technical', 'mean', 'reference', 'digital', 'construction', 'heterogeneous', 'coal', 'mine', 'information', 'data', 'mean', 'big', 'data', 'thinking.']\n",
      "abstract\\42.txt\n",
      "\n",
      "['Herein', 'present', 'novel', 'big-data', 'framework', 'healthcare', 'applications.', 'Healthcare', 'data', 'well', 'suit', 'bigdata', 'processing', 'analytics', 'variety,', 'veracity', 'volume', 'type', 'data.', 'In', 'recent', 'times,', 'many', 'area', 'within', 'healthcare', 'identify', 'directly', 'benefit', 'treatment.', 'However,', 'set', 'type', 'architecture', 'trivial.', 'We', 'present', 'novel', 'approach', 'building', 'big-data', 'framework', 'adapt', 'various', 'healthcare', 'application', 'relative', 'use,', 'make', 'one-stop', '“Big-Data-Healthcare-in-a-Box”.']\n",
      "abstract\\43.txt\n",
      "\n",
      "['Currently,', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'accumulate', 'huge', 'amount', 'data.', 'In', 'age', 'big', 'data,', 'data', 'integrate', 'various', 'system', 'face', 'big', 'data', 'application', 'problems.', 'This', 'paper', 'proposes', 'data', 'quality', 'assessment', 'system', 'method', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'base', 'big', 'data', 'data', 'provenance', 'ass', 'integrity,', 'redundancy,', 'accuracy,', 'timeliness,', 'intelligence', 'consistency', 'data', 'set', 'single', 'data.', 'Specific', 'assessment', 'rule', 'conforms', 'situation', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'devise', 'found', 'data', 'quality', 'problems.', 'Thus', 'provide', 'strong', 'data', 'support', 'big', 'data', 'application', 'power', 'quality.']\n",
      "abstract\\44.txt\n",
      "\n",
      "['This', 'paper', 'attempt', 'construct', 'analysis', 'model', 'city', 'price,', 'combine', 'big', 'data', 'system', 'information', 'city', 'price,', 'provide', 'reference', 'government', 'implement', 'policy', 'accurate', 'price', 'control.', 'This', 'paper', 'considers', 'analysis', 'system', 'city', 'price', 'include', 'decision-making', 'layer,', 'support', 'layer', 'show', 'layer', 'conceptual', 'level,', 'transmission', 'path', 'include', 'data', 'collection,', 'data', 'management,', 'data', 'mining,', 'decision', 'make', 'safety', 'protection.', 'come', 'construction', 'subsystem,', 'technological', 'tool', 'data', 'mining,', 'cloud', 'compute', 'visualization', 'used,', 'mainly', 'order', 'build', 'data', 'acquisition', 'subsystem,', 'data', 'management', 'subsystem,', 'data', 'analysis', 'subsystem,', 'data', 'transmission', 'subsystem', 'on,', 'provide', 'graphic', 'description', 'correspond', 'technological', 'path', 'time.']\n",
      "abstract\\45.txt\n",
      "\n",
      "['The', 'conventional', 'method', 'data', 'analytics', 'flight', 'safety', 'monitoring', 'met', 'many', 'bottlenecks.', 'This', 'paper', 'analyzes', 'insufficiency', 'preliminary', 'business', 'process', 'airline.', 'For', 'purpose', 'meeting', 'requirement', 'efficiency', 'accuracy', 'avoid', 'drawback', 'encounter', 'before,', 'architectural', 'framework', 'flight', 'safety', 'monitoring', 'platform', 'utilize', 'big', 'data', 'technology', 'propose', 'demonstrate', 'function', 'module', 'structure', 'logical', 'structure.', 'The', 'platform', 'implement', 'divide', 'system', 'five', 'subsystems,', 'namely', 'data', 'acquisition,', 'data', 'decoding,', 'data', 'storage,', 'data', 'analysis', 'visualization.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\46.txt\n",
      "\n",
      "['Big', 'Data', 'constitutes', 'opportunity', 'company', 'empower', 'analysis.', 'However,', 'moment', 'standard', 'way', 'approach', 'Big', 'Data', 'projects.', 'This,', 'couple', 'complex', 'nature', 'Big', 'Data,', 'cause', 'many', 'Big', 'Data', 'project', 'fail', 'rarely', 'obtain', 'expect', 'return', 'investment.', 'In', 'paper,', 'present', 'methodology', 'tackle', 'Big', 'Data', 'project', 'systematic', 'way,', 'avoid', 'aforementioned', 'problems.', 'To', 'end,', 'review', 'state', 'art,', 'identify', 'prominent', 'problem', 'surround', 'Big', 'Data', 'projects,', 'best', 'practice', 'methods.', 'Then,', 'define', 'methodology', 'describe', 'step', 'step', 'technique', 'could', 'apply', 'combine', 'order', 'tackle', 'problem', 'identify', 'increase', 'success', 'rate', 'Big', 'Data', 'projects.']\n",
      "abstract\\47.txt\n",
      "\n",
      "['In', 'August', '2015,', 'new', 'seafloor', 'observatory', 'deployed', 'Galway', 'Bay,', 'Ireland.', 'The', 'sensor', 'observatory', 'platform', 'connect', 'fibre-optic', 'cable', 'shore', 'station,', 'broadband', 'connection', 'allows', 'data', 'transfer', 'Marine', \"Institute's\", 'data', 'centre.', 'This', 'setup', 'involve', 'development', 'new', 'data', 'acquisition', 'system', 'take', 'advantage', 'open', 'source', 'stream', 'data', 'solution', 'developed', 'response', 'Big', 'Data', 'paradigm,', 'particular', 'Velocity', 'aspect.', 'This', 'activity', 'merges', 'concept', 'arena', 'Big', 'Data', 'Internet', 'Things', 'data', 'standardisation', 'normally', 'considered.', 'This', 'paper', 'considers', 'architecture', 'implement', 'stream', 'marine', 'data', 'instrument', 'end', 'user', 'offer', 'suggestion', 'standardise', 'data', 'streams.']\n",
      "abstract\\48.txt\n",
      "\n",
      "['We', 'collect', '79,012', 'article', '1916-2016', 'related', 'big', 'data', 'determine', 'topic', 'study', 'much', 'literature', 'focus', 'privacy', 'security-related', 'keywords.', 'The', 'analysis', 'demonstrate', 'big', 'data', 'paradigm', 'commenced', 'late', '2011', 'research', 'production', 'exponentially', 'rise', 'start', '2012,', 'approximate', 'Weibull', 'distribution', 'capture', '82%', 'variance', '(p<;.01).', 'We', 'found', '13', 'dominant', 'topic', 'capture', '49%', 'big', 'data', 'production', 'journal', '2011-2016', 'privacy', 'security', 'topic', 'account', '2%', 'trend', 'recently', 'drop', 'less', '1%', 'Thus,', 'argue', 'need', 'stimulate', 'big', 'data', 'privacy-security', 'research.']\n",
      "abstract\\49.txt\n",
      "\n",
      "['As', 'large', 'amount', 'data', 'generate', 'healthcare', 'industry,', 'big', 'data', 'technology', 'use', 'process', 'data.', 'Tobacco', 'smoking', 'significant', 'among', 'youth', 'United', 'States.', 'In', 'research,', 'use', 'big', 'data', 'technique', 'R', 'Tableau', 'explore', 'tobacco', 'smoking', 'trend', 'among', 'youth', 'United', 'States.', 'Results', 'indicate', 'number', 'youth', 'male', 'smoker', 'youth', 'female', 'smokers.', 'The', 'result', 'also', 'indicate', '51', 'percent', 'current', 'youth', 'smoker', 'want', 'quit', 'smoking.']\n",
      "abstract\\5.txt\n",
      "\n",
      "['Text', 'categorization', '(TC)', 'important', 'component', 'many', 'information', 'organization', 'information', 'management', 'tasks.', 'Two', 'key', 'issue', 'TC', 'feature', 'cod', 'classifier', 'design.', 'The', 'Euclidean', 'distance', 'usually', 'chosen', 'similarity', 'measure', 'K-nearest', 'neighbor', 'classification', 'algorithm.', 'All', 'feature', 'vector', 'different', 'function', 'describe', 'samples.', 'So', 'decide', 'different', 'function', 'every', 'feature', 'use', 'feature', 'weight', 'learning.', 'In', 'paper', 'text', 'categorization', 'via', 'K-nearest', 'neighbor', 'algorithm', 'base', 'feature', 'weight', 'learn', 'described.', 'The', 'numerical', 'experiment', 'prove', 'validity', 'learn', 'algorithm.']\n",
      "abstract\\50.txt\n",
      "\n",
      "['In', 'last', 'years,', 'grow', 'interest', 'use', 'Big', 'Data', 'model', 'support', 'advanced', 'data', 'analysis', 'functionalities.', 'Many', 'company', 'organization', 'lack', 'IT', 'expertise', 'adequate', 'budget', 'benefit', 'them.', 'In', 'order', 'fill', 'gap,', 'model-based', 'approach', 'Big', 'Data', 'Analytics-as-a-service', '(MBDAaaS)', 'used.', 'The', 'propose', 'model,', 'compose', 'declarative,', 'procedural', 'deployment', '(sub)', 'models,', 'use', 'select', 'deployable', 'set', 'service', 'base', 'set', 'user', 'preference', 'shape', 'Big', 'Data', 'Campaign', '(BDC).', 'The', 'deployment', 'BDC', 'require', 'selection', 'service', 'carry', 'basis', 'coherent', 'non', 'conflictual', 'user', 'preferences.', 'In', 'paper', 'propose', 'OWL', 'ontology', 'order', 'solve', 'issue.']\n",
      "abstract\\6.txt\n",
      "\n",
      "['This', 'work', 'proposes', 'intelligent', 'learn', 'diagnosis', 'system', 'support', 'Web-based', 'thematic', 'learn', 'model,', 'aim', 'cultivate', \"learners'\", 'ability', 'knowledge', 'integration', 'give', 'learner', 'opportunity', 'select', 'learn', 'topic', 'interested,', 'gain', 'knowledge', 'specific', 'topic', 'surf', 'Internet', 'search', 'related', 'learn', 'courseware', 'discuss', 'learn', 'colleagues.', 'Based', 'log', 'file', 'record', \"learners'\", 'past', 'online', 'learn', 'behavior,', 'intelligent', 'diagnosis', 'system', 'use', 'give', 'appropriate', 'learn', 'guidance', 'assist', 'learner', 'improve', 'study', 'behavior', 'grade', 'online', 'class', 'participation', 'instructor.', 'The', 'achievement', \"learners'\", 'final', 'report', 'also', 'predict', 'diagnosis', 'system', 'accurately.', 'Our', 'experimental', 'result', 'reveal', 'propose', 'learn', 'diagnosis', 'system', 'efficiently', 'help', 'learner', 'expand', 'knowledge', 'surf', 'cyberspace', 'Web-based', '\"theme-based', 'learning\"', 'model.']\n",
      "abstract\\7.txt\n",
      "\n",
      "['Semi-supervised', 'support', 'vector', 'machine', 'extension', 'standard', 'support', 'vector', 'machine', 'machine', 'learn', 'problem', 'real', 'life.', 'However,', 'exist', 'semi-supervised', 'support', 'vector', 'machine', 'algorithm', 'drawback', 'slow', 'training', 'speed,', 'low', 'accuracy,', 'etc.', 'This', 'paper', 'present', 'semi-supervised', 'support', 'vector', 'machine', 'learn', 'algorithm', 'base', 'active', 'learning,', 'train', 'early', 'learner', 'spot', 'labeled-data,', 'selects', 'best', 'training', 'sample', 'training', 'learn', 'active', 'learn', 'reduces', 'learn', 'cost', 'delete', 'non-', 'support', 'vector.', 'Simulative', 'experiment', 'show', 'algorithm', 'may', 'get', 'good', 'learn', 'effect', 'less', 'learn', 'cost.']\n",
      "abstract\\8.txt\n",
      "\n",
      "['Transfer', 'learn', 'aim', 'improve', 'target', 'learn', 'task', 'use', 'related', 'auxiliary', 'learn', 'task', 'data.', 'Most', 'current', 'transfer-learning', 'method', 'focus', 'scenario', 'auxiliary', 'target', 'learn', 'task', 'similar:', 'either', '(some', 'of)', 'auxiliary', 'data', 'directly', 'use', 'training', 'example', 'target', 'task', 'auxiliary', 'target', 'data', 'share', 'representation.', 'However,', 'many', 'case', 'connection', 'auxiliary', 'target', 'task', 'remote.', 'Only', 'feature', 'derive', 'auxiliary', 'data', 'may', 'helpful', 'target', 'learning.', 'We', 'call', 'scenario', 'deep', 'transfer-learning', 'scenario', 'introduce', 'novel', 'transfer-learning', 'method', 'deep', 'transfer.', 'Our', 'method', 'us', 'restrict', 'Boltzmann', 'machine', 'discover', 'set', 'hierarchical', 'feature', 'auxiliary', 'data.', 'We', 'select', 'feature', 'subset', 'helpful', 'target', 'learning,', 'use', 'selection', 'criterion', 'base', 'concept', 'kernel-target', 'alignment.', 'Finally,', 'target', 'data', 'augment', 'select', 'feature', 'training.', 'Our', 'experiment', 'result', 'show', 'transfer', 'method', 'effective.', 'It', 'improve', 'classification', 'accuracy', '10%,', 'even', 'connection', 'auxiliary', 'target', 'task', 'apparent.']\n",
      "abstract\\9.txt\n",
      "\n",
      "['Data', 'mining', 'CRM', 'aim', 'learn', 'available', 'knowledge', 'customer', 'relationship', 'machine', 'learn', 'statistical', 'method', 'instruct', 'strategic', 'behavior', 'obtain', 'profit.', 'In', 'recent', 'years,', 'Support', 'vector', 'machine', '(SVMs)', 'propose', 'power', 'tool', 'machine', 'lean', 'data', 'mining.', 'This', 'paper', 'applies', 'SVMs', 'resolve', 'practical', 'CRM', 'problem', 'company.', 'The', 'final', 'result', 'report', 'good', 'general', 'performance', 'SVMs', 'CRM', 'problem.']\n",
      "abstract\\a1.txt\n",
      "\n",
      "['In', 'paper', 'discus', 'various', 'machine', 'learn', 'approach', 'use', 'mining', 'data.', 'Further', 'distinguish', 'symbolic', 'sub-symbolic', 'data', 'mining', 'methods.', 'We', 'also', 'attempt', 'propose', 'hybrid', 'method', 'combination', 'Artificial', 'Neural', 'Network', '(ANN)', 'Cased', 'Based', 'Reasoning', '(CBR)', 'mining', 'data.']\n",
      "abstract\\a10.txt\n",
      "\n",
      "['In', 'paper,', 'present', 'framework', 'enables', 'medical', 'decision', 'make', 'presence', 'partial', 'information.', 'At', 'core', 'ontology-based', 'automate', 'reasoning,', 'machine', 'learn', 'technique', 'integrate', 'enhance', 'exist', 'patient', 'datasets', 'order', 'address', 'issue', 'miss', 'data.', 'Our', 'approach', 'support', 'interoperability', 'different', 'health', 'information', 'systems.', 'This', 'clarify', 'sample', 'implementation', 'combine', 'three', 'separate', 'datasets', '(patient', 'data,', 'drug-drug', 'interaction', 'drug', 'prescription', 'rules)', 'demonstrate', 'effectiveness', 'algorithm', 'produce', 'effective', 'medical', 'decisions.', 'In', 'short,', 'demonstrate', 'potential', 'machine', 'learn', 'support', 'task', 'critical', 'need', 'medical', 'professional', 'cop', 'miss', 'noisy', 'patient', 'data', 'enable', 'use', 'multiple', 'medical', 'datasets.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a11.txt\n",
      "\n",
      "['Support', 'vector', 'machine', '(SVM)', 'become', 'popular', 'tool', 'pattern', 'recognition', 'recent', 'year', 'outstanding', 'learn', 'performance.', 'When', 'deal', 'large-scale', 'learn', 'problems,', 'incremental', 'SVM', 'framework', 'generally', 'use', 'SVM', 'summarize', 'data', 'space', 'concise', 'way.', 'This', 'paper', 'proposes', 'training', 'algorithm', 'incremental', 'SVM', 'recombine', 'method.', 'Considering', 'difference', 'data', 'distribution', 'impact', 'new', 'training', 'data', 'history', 'data,', 'history', 'training', 'dataset', 'new', 'training', 'one', 'divide', 'independent', 'group', 'recombine', 'train', 'classifier.', 'In', 'fact,', 'method', 'implement', 'parallel', 'structure', 'action', 'divide', 'may', 'decrease', 'computation', 'complexity', 'training', 'SVM.', 'Meanwhile,', 'action', 'recombine', 'may', 'weaken', 'potential', 'impact', 'cause', 'difference', 'data', 'distribution.', 'The', 'experiment', 'result', 'text', 'dataset', 'show', 'training', 'algorithm', 'effective', 'classification', 'accuracy', 'propose', 'incremental', 'algorithm', 'superior', 'use', 'batch', 'SVM', 'model.']\n",
      "abstract\\a12.txt\n",
      "\n",
      "['There', '700,000', 'Rheumatoid', 'Arthritis', '(RA)', 'patient', 'Japan,', 'number', 'patient', 'increase', '30,000', 'annually.', 'The', 'early', 'detection', 'appropriate', 'treatment', 'accord', 'progression', 'RA', 'effective', 'improve', \"patient's\", 'prognosis.', 'The', 'modify', 'Total', 'Sharp', '(mTS)', 'score', 'widely', 'use', 'progression', 'evaluation', 'Rheumatoid', 'Arthritis.', 'The', 'mTS', 'score', 'assessment', 'hand', 'foot', 'X-ray', 'image', 'require', 'several', 'time', 'year,', 'take', 'long', 'time.', 'The', 'automatic', 'mTS', 'score', 'calculation', 'system', 'required.', 'This', 'paper', 'proposes', 'finger', 'joint', 'detection', 'method', 'mTS', 'score', 'estimation', 'method', 'use', 'support', 'vector', 'machine.', 'Experimental', 'result', '45', 'RA', \"patient's\", 'X-ray', 'image', 'show', 'propose', 'method', 'detects', 'finger', 'joint', 'accuracy', '81.4', '%,', 'estimate', 'erosion', 'JSN', 'score', 'accuracy', '50.9,', '64.3', '%,', 'respectively.']\n",
      "abstract\\a13.txt\n",
      "\n",
      "['As', 'increasingly', 'enterprise', 'deploy', 'cloud', 'file-sharing', 'services,', 'add', 'new', 'channel', 'potential', 'insider', 'threat', 'company', 'data', 'IPs.', 'In', 'paper,', 'introduce', 'two-stage', 'machine', 'learn', 'system', 'detect', 'anomalies.', 'In', 'first', 'stage,', 'project', 'access', 'log', 'cloud', 'file-sharing', 'service', 'onto', 'relationship', 'graph', 'use', 'three', 'complementary', 'graph-based', 'unsupervised', 'learn', 'methods:', 'OddBall,', 'PageRank', 'Local', 'Outlier', 'Factor', '(LOF)', 'generate', 'outlier', 'indicators.', 'In', 'second', 'stage,', 'ensemble', 'outlier', 'indicator', 'introduce', 'discrete', 'wavelet', 'transform', '(DWT)', 'method,', 'propose', 'procedure', 'use', 'wavelet', 'coefficient', 'Haar', 'wavelet', 'function', 'identify', 'outlier', 'insider', 'threat.', 'The', 'propose', 'system', 'deployed', 'real', 'business', 'environment,', 'demonstrate', 'effectiveness', 'select', 'case', 'studies.']\n",
      "abstract\\a14.txt\n",
      "\n",
      "['This', 'paper', 'address', 'recent', 'trend', 'machine', 'learn', 'method', 'automatic', 'classification', 'remote', 'sense', '(RS)', 'images.', 'In', 'particular,', 'focus', 'two', 'new', 'paradigms:', 'semisupervised', 'active', 'learning.', 'These', 'two', 'paradigm', 'allow', 'one', 'address', 'classification', 'problem', 'critical', 'condition', 'available', 'label', 'training', 'sample', 'limited.', 'These', 'operational', 'condition', 'usual', 'RS', 'problems,', 'due', 'high', 'cost', 'time', 'associate', 'collection', 'label', 'samples.', 'Semisupervised', 'active', 'learn', 'technique', 'allow', 'one', 'enrich', 'initial', 'training', 'set', 'information', 'improve', 'classification', 'accuracy', 'exploit', 'unlabeled', 'sample', 'require', 'additional', 'label', 'phase', 'user,', 'respectively.', 'The', 'two', 'aforementioned', 'strategy', 'theoretically', 'experimentally', 'analyze', 'consider', 'SVM-based', 'technique', 'order', 'highlight', 'advantage', 'disadvantage', 'strategies.']\n",
      "abstract\\a15.txt\n",
      "\n",
      "['Web', 'filter', 'base', \"user's\", 'demand', 'witness', 'boom', 'interest', 'due', 'development', 'Internet', 'In', 'research', 'community', 'dominant', 'approach', 'problem', 'base', 'machine', 'learn', 'algorithms.', 'Web', 'filter', 'inductive', 'process', 'automatically', 'build', 'filter', 'learn', 'set', 'pre-assigned', 'document', 'description', \"user's\", 'interest,', 'us', 'assign', 'unfiltered', 'Web', 'pages.', 'This', 'survey', 'compare', 'four', 'main', 'machine', 'learn', 'algorithm', '(decision', 'tree,', 'rule', 'induction,', 'Bayesian', 'algorithm', 'support', 'vector', 'machines)', 'Chinese', 'web', 'page', 'set', 'filter', 'effectiveness', 'computer', 'resource', 'consumed,', 'focus', 'influence', 'feature', 'set', 'size', 'training', 'set', 'size.', 'It', 'induces', 'support', 'vector', 'machine', 'earn', 'high', 'score', 'Chinese', 'Web', 'filter', 'applications.']\n",
      "abstract\\a16.txt\n",
      "\n",
      "['Imbalanced', 'distribution', 'mis-classified', 'cost', 'two', 'class', 'make', 'conventional', 'classification', 'method', 'suffered.', 'This', 'paper', 'propose', 'new', 'fast', 'parallel', 'classification', 'method', 'imbalanced', 'classes.', 'Considering', 'imbalanced', 'distributions,', 'approach', 'adopt', 'fast', 'simple', 'classifier', 'less', 'feature', 'input', 'work', 'parallel', 'complicate', 'one.', 'Most', 'sample', 'would', 'correctly', 'recognize', 'first', 'classifier,', 'second', 'relatively', 'slow', 'classifier', 'could', 'ended.', 'The', 'second', 'one', 'train', 'work', 'less', 'difficult', 'samples.', 'Experimental', 'result', 'machine', 'vision', 'quality', 'inspection', 'show', 'approach', 'could', 'effectively', 'improve', 'classification', 'speed', 'decrease', 'total', 'risk', 'imbalanced', 'classespsila', 'classification.']\n",
      "abstract\\a17.txt\n",
      "\n",
      "['Chinese', 'new', 'word', 'extraction', 'important', 'problem', 'Chinese', 'information', 'processing.', 'In', 'paper', 'new', 'word', 'extraction', 'method', 'base', 'machine', 'learn', 'proposed,', 'context', 'information,', 'word', 'construction', 'rule', 'statistic', 'information', 'combine', 'extract', 'new', 'words.', 'An', 'experiment,', 'base', 'two-character-nouns,', 'show', 'method', 'well', 'improve', 'efficiency', 'accuracy', 'extract', 'new', 'word']\n",
      "abstract\\a18.txt\n",
      "\n",
      "['Neural', 'network', 'hardware', 'implementation', 'reconcile', 'simple', 'hardware', 'topology', 'often', 'complex', 'neural', 'architectures.', 'Field', 'programmable', 'neural', 'array', '(FPNA)', 'define', 'that.', 'Their', 'computation', 'scheme', 'creates', 'numerous', 'virtual', 'neural', 'link', 'mean', 'limited', 'set', 'communication', 'links,', 'whatever', 'device,', 'arithmetic,', 'neural', 'structure.', 'Their', 'concrete', 'use', 'prove', 'allow', 'computation', 'power', 'standard', 'neural', 'model', 'reduce', 'set', 'neural', 'resource', 'easy', 'map', 'directly', 'digital', 'hardware.', 'A', 'simple', 'pattern', 'classification', 'problem', 'chosen', 'paper', 'show', 'FPNA', 'allow', 'replace', 'complex', 'standard', 'neural', 'architecture', 'hardware-friendly', 'neural', 'structures.', 'FPNA', 'apply', 'numerous', 'problem', 'similar', 'benefits.', 'They', 'apply', 'high-dimensional', 'real-world', 'applications,', 'multiband', 'speech', 'recognition.']\n",
      "abstract\\a19.txt\n",
      "\n",
      "['Recently,', 'neural', 'network', 'become', 'important', 'method', 'field', 'medical', 'diagnostics.', 'The', 'objective', 'work', 'diagnose', 'hepatitis', 'disease', 'use', 'different', 'neural', 'network', 'architectures.', 'Standard', 'feedforward', 'network', 'hybrid', 'network', 'investigated.', 'Results', 'obtain', 'show', 'especially', 'hybrid', 'network', 'successfully', 'use', 'diagnose', 'hepatitis.']\n",
      "abstract\\a2.txt\n",
      "\n",
      "['We', 'present', 'two', 'input', 'data', 'preprocessing', 'method', 'machine', 'learn', '(ML).', 'The', 'first', 'one', 'consists', 'extend', 'set', 'attribute', 'describe', 'object', 'input', 'data', 'table', 'new', 'attribute', 'second', 'one', 'consists', 'replace', 'attribute', 'new', 'attributes.', 'The', 'method', 'utilize', 'formal', 'concept', 'analysis', '(FCA)', 'boolean', 'factor', 'analysis,', 'recently', 'described', 'FCA,', 'new', 'attribute', 'define', 'so-called', 'factor', 'concept', 'compute', 'input', 'data', 'table.', 'The', 'method', 'demonstrate', 'decision', 'tree', 'induction.', 'The', 'experimental', 'evaluation', 'comparison', 'performance', 'decision', 'tree', 'induced', 'original', 'preprocessed', 'input', 'data', 'perform', 'standard', 'decision', 'tree', 'induction', 'algorithm', 'ID3', 'C4.5', 'several', 'benchmark', 'datasets.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a20.txt\n",
      "\n",
      "['Routing', 'optical,', 'especially', 'wavelength', 'division', 'multiplexing', 'networks,', 'hard', 'task.', 'This', 'paper', 'defines', 'new', 'rout', 'algorithm,', 'base', 'Hopfield', 'neural', 'network.', 'It', 'improvement', 'previous', 'research,', 'apply', 'optical', 'communication']\n",
      "abstract\\a21.txt\n",
      "\n",
      "['The', 'information', 'storage', 'mechanism', 'biological', 'neural', 'network', 'important', 'problem', 'neuroscience.', 'Our', 'observation', 'show', 'structure', 'hippocampus,', 'core', 'memory', 'brain,', 'similar', \"Hopfield's\", 'neural', 'network.', 'An', 'electronic', 'neuronic', 'model', 'construct', 'simulate', 'dynamic', 'process', 'hippocampal', 'LTP', 'process.', 'The', 'kinetic', 'process', 'post', 'synaptic', 'potential', 'synaptic-synaptic', 'interaction', 'equation', 'also', 'discussed.', 'We', 'propose', 'dual', 'cod', 'theory', 'biological', 'neural', 'information', 'assume', 'messy', 'fiber', 'synaptic', 'glomerulus', 'may', 'chief', 'storage', 'medium', 'neural', 'information.', 'A', 'geometrical', 'mapping', 'N', 'dimensional', 'unitron', 'construct', 'analyse', 'distribution', 'computation', 'energy', 'trace', 'dynamic', 'locus', 'memory', 'retrieve', 'process.']\n",
      "abstract\\a22.txt\n",
      "\n",
      "['We', 'report', 'result', 'computer', 'simulation', 'learn', 'process', 'temporal', 'series', 'artificial', 'neural', 'networks.', 'In', 'simulation,', 'use', 'feedforward', 'neural', 'network', 'model', '4-layers', 'study', 'capability', 'dynamical', 'learn', 'process', 'chaotic', 'time', 'series', 'produce', 'triangular', 'maps.', 'We', 'found', 'critical', 'time', '(t/sub', 'cr/)', 'learn', 'process', 'proceeds', 'abruptly.', 'We', 'also', 'found', 'critical', 'time', '(t/sub', 'cr/)', 'shorter,', 'large', 'initial', 'deviation', 'target', 'learning.', 'We', 'provide', 'detailed', 'discussion', 'learn', 'process', 'explain', 'interest', 'phenomena,', 'new', 'order', 'parameter', 'coherency', 'introduce', 'characterize', 'processes.']\n",
      "abstract\\a23.txt\n",
      "\n",
      "['In', 'paper,', 'hybrid', 'multilayer', 'feedforward', 'neural', 'network', 'hidden', 'unit', 'define', 'fuzzy', 'reference', 'points,', 'general', 'feedback', 'learn', 'method', 'presented.', 'This', 'model', 'use', 'DSS.', 'Results', 'experiment', 'process', 'identification', 'given.', 'The', 'propose', 'model', 'able', 'overcome', 'limitation', 'conventional', 'multilayer', 'feedforward', 'neural', 'network', 'apply', 'expert', 'systems.']\n",
      "abstract\\a24.txt\n",
      "\n",
      "['The', 'recurrent', 'correlation', 'neural', 'network', 'high-capacity', 'associative', 'memory', 'weight', 'function', 'satisfies', 'certain', 'condition.', 'But', 'always', 'cause', 'high', 'dynamic', 'neural', 'network', 'hardware', 'realization', 'difficult.', 'This', 'paper', 'give', 'relationship', 'capacity', 'dynamic', 'provide', 'general', 'principle', 'choice', 'weight', 'function', 'give', 'kind', 'weight', 'function.', 'It', 'high-capacity', 'avoids', 'high', 'dynamics.', 'Finally,', 'simulated', 'result', 'given.']\n",
      "abstract\\a25.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'new', 'branch', 'neural', 'networks,', 'call', '\"neurite', 'networks\",', 'neural', 'network', 'grows,', 'i.e.', 'embryological', 'component.', 'The', 'artificial', 'neurite', 'network', 'introduce', 'base', 'cellular', 'automaton', '(CA)', 'network', 'whose', 'branching', 'genetically', 'programmed', '(i.e.', 'grown', 'control', 'genetic', 'algorithm).', 'A', 'sequence', 'CA', 'signal', 'sent', 'middle', 'CA', '\"trail\".', 'When', 'signal', 'hit', 'end', 'trail,', 'make', 'trail', 'extend,', 'turn', 'left,', 'turn', 'right,', 'branch', 'left,', 'branch', 'right,', 'split,', 'etc.,', 'depend', 'upon', 'state', 'CA', 'signal.', 'These', 'signal', 'sequence', 'treat', 'chromosome', 'genetic', 'algorithm.', 'Once', 'CA', 'network', 'formed,', 'second', 'set', 'CA', 'state', 'transition', 'rule', 'switch', 'make', 'behave', 'like', 'neural', 'network.', 'The', 'fitness', 'CA', 'base', 'neural', 'network', 'measure', 'term', 'well', 'control', 'behavior', 'biological', 'robot.']\n",
      "abstract\\a26.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'add', 'filter', 'layer', 'dot', 'product', 'match', 'neural', 'network.', 'The', 'purpose', 'filter', 'layer', 'discard', 'unfavourable', 'choice', 'check', 'low', 'upper', 'bound', 'exemplar', 'test', 'pattern.', 'The', 'product', 'supervised,', 'fast', 'learn', 'filter', 'neural', 'network.', 'It', 'well', 'generalisation', 'capability', 'ordinary', 'dot', 'product', 'match', 'neural', 'network.', 'The', 'new', 'neural', 'network', 'test', 'speaker-independent', 'spoken', 'number', '(in', 'English)', 'recognition.', 'An', 'accuracy', '96.5%', 'report', 'test', 'data.', 'Without', 'filter', 'layer,', 'recognition', 'rate', 'fall', '94.0%.']\n",
      "abstract\\a27.txt\n",
      "\n",
      "['Discussing', 'new', 'architecture', 'high', 'performance', 'computer', 'base', 'transputers', 'dedicate', 'VLSI.', 'The', 'author', 'proposes', 'new', 'general', 'purpose', 'custom-made', 'digital', 'neurochip', 'flexible', 'implementation', 'multilayer', 'neural', 'network', 'programmable', 'bit', 'weight', 'input', 'signals.', 'The', 'neuroTRAM', 'consists', 'transputers,', 'memory', 'neurochips', 'neurocomputer', 'implementation.']\n",
      "abstract\\a28.txt\n",
      "\n",
      "['A', 'genetic', 'method', 'propose', 'optimize', 'random', 'neural', 'network', 'compose', 'asynchronous', 'thresholding', 'neural', 'units.', 'Each', 'unit', 'belongs', 'one', 'three', 'categories,', 'input', 'units,', 'hidden', 'unit', 'output', 'units,', 'kind', 'connection', 'among', 'unit', 'include', 'feedforward,', 'feedback', 'mutual', 'connection', 'allowable', 'except', 'connection', 'input', 'units.', 'Several', 'virtual', 'living', 'thing', 'whose', 'genotype', 'connection', 'among', 'neural', 'unit', 'randomly', 'generated,', 'generation', 'iteration', 'repeat', 'order', 'optimize', 'them.', 'In', 'generation', 'iteration,', 'individual', 'adequate', 'give', 'problem', 'make', 'child', 'inferior', 'one', 'remove', 'population.', 'Optimized', 'neural', 'network', 'obtain', 'evolve', 'individuals.', 'An', 'action', 'control', 'problem', 'computer', 'game', 'treat', 'application', 'method.']\n",
      "abstract\\a29.txt\n",
      "\n",
      "['The', 'traffic', 'transform', 'difficult', 'structure', 'point', 'design', 'manage', 'reason', 'increase', 'number', 'vehicle.', 'This', 'situation', 'discover', 'road', 'accident', 'problem,', 'influence', 'public', 'health', 'country', 'economy', 'do', 'study', 'solution', 'problem.', 'Large', 'calibrate', 'data', 'agglomeration', 'increase', 'reason', 'technological', 'improvement', 'data', 'storage', 'low', 'cost.', 'Arising', 'need', 'accession', 'information', 'large', 'calibrate', 'data', 'obtain', 'corner', 'stone', 'data', 'mining.', 'In', 'study,', 'assignment', 'compatible', 'machine', 'learn', 'classification', 'technique', 'road', 'accident', 'estimation', 'data', 'mining', 'intended.']\n",
      "abstract\\a3.txt\n",
      "\n",
      "['This', 'paper', 'present', 'exploratory', 'machine', 'learn', 'attack', 'base', 'deep', 'learn', 'infer', 'functionality', 'arbitrary', 'classifier', 'polling', 'black', 'box,', 'use', 'return', 'label', 'build', 'functionally', 'equivalent', 'machine.', 'Typically,', 'costly', 'time', 'consume', 'build', 'classifier,', 'require', 'collect', 'training', 'data', '(e.g.,', 'crowdsourcing),', 'select', 'suitable', 'machine', 'learn', 'algorithm', '(through', 'extensive', 'test', 'use', 'domain-specific', 'knowledge),', 'optimize', 'underlie', 'hyperparameters', '(applying', 'good', 'understand', \"classifier's\", 'structure).', 'In', 'addition,', 'information', 'typically', 'proprietary', 'protected.', 'With', 'propose', 'black-box', 'attack', 'approach,', 'adversary', 'use', 'deep', 'learn', 'reliably', 'infer', 'necessary', 'information', 'use', 'label', 'previously', 'obtain', 'classifier', 'attack,', 'build', 'functionally', 'equivalent', 'machine', 'learn', 'classifier', 'without', 'know', 'type,', 'structure', 'underlie', 'parameter', 'original', 'classifier.', 'Results', 'text', 'classification', 'application', 'demonstrate', 'deep', 'learn', 'infer', 'Naive', 'Bayes', 'SVM', 'classifier', 'high', 'accuracy', 'steal', 'functionalities.', 'This', 'new', 'attack', 'paradigm', 'deep', 'learn', 'introduces', 'additional', 'security', 'challenge', 'online', 'machine', 'learn', 'algorithm', 'raise', 'need', 'novel', 'mitigation', 'strategy', 'counteract', 'high', 'fidelity', 'inference', 'capability', 'deep', 'learning.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a30.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'In', 'area', 'brain,', 'numerous', 'neuron', 'constitute', 'elaborate', 'networks.', 'These', 'network', 'link', 'numerous', 'connections,', 'compose', 'large-scaled', 'neural', 'systems.', 'The', 'neural', 'system', 'generate', 'major', 'brain', 'function', 'movement,', 'cognition,', 'emotion,', 'memory-learning.', 'The', 'brain', 'extensively', 'study', 'anatomically,', 'physiologically', 'chemically,', 'knowledge', 'ever', 'grows', 'cover', 'every', 'detail', 'brain.', 'Important', 'principle', 'activity-dependent', 'synaptic', 'plasticity,', 'multilayered', 'integration', 'neuronal', 'networks,', 'modular', 'organization', 'brain', 'tissue', 'revealed.', 'Yet,', 'shortage', 'knowledge', 'obvious', 'one', 'try', 'reproduce', 'brain', 'function', 'models.', 'While', 'simple', 'perceptron', 'model,', 'adaptive', 'filter', 'model,', 'feedforward', 'adaptive', 'control', 'system', 'model', 'successfully', 'reproduce', 'function', 'cerebellum,', 'effort', 'model', 'part', 'brain', 'met', 'great', 'difficulties.', 'It', 'still', 'difficult', 'answer', 'fundamental', 'question', 'meant', 'intricate', 'structure', 'basal', 'ganglia?', 'How', 'hippocampal', 'circuit', 'serf', 'cognitive', 'memory', 'learning?', 'How', 'language', 'encode', 'within', 'neocortical', 'network?', 'Structures', 'motor,', 'cognitive', 'emotional', 'system', 'brain', 'dissect', 'extent,', 'yet', 'difficult', 'figure', 'volition', 'emerges,', 'sense', 'beauty,', 'truth', 'virtue', 'intuitively,', 'brain', 'consciousness', 'resides.', 'Complete', 'understand', 'brain', 'could', 'achieve', 'one', 'successfully', 'model', 'neural', 'network', 'system', 'reproduce', 'entire', 'aspect', 'brain', 'functions.']\n",
      "abstract\\a31.txt\n",
      "\n",
      "['The', 'work', 'described', 'paper', 'aim', 'develop', 'neural', 'architecture', 'easy', 'map', 'onto', 'FPGA,', 'thanks', 'simplify', 'topology', 'original', 'data', 'exchange', 'scheme,', 'without', 'significant', 'loss', 'approximation', 'capability.', 'It', 'achieve', 'thanks', 'definition', 'set', 'neural', 'model', 'call', 'field', 'programmable', 'neural', 'array', '(FPNA).', 'FPNA', 'may', 'lead', 'definition', 'neural', 'network', 'adapt', 'hardware', 'topological', 'constraints.', 'Different', 'neural', 'network', 'may', 'derive', 'give', 'FPNA.', 'They', 'call', 'field', 'programmed', 'neural', 'network', '(FPNN).', 'They', 'reconcile', 'high', 'connection', 'density', 'neural', 'architecture', 'need', 'limited', 'interconnection', 'scheme', 'hardware', 'implementations.', 'This', 'paper', 'focus', 'definition', 'implementation', 'FPNN', 'parallel', 'computation.', 'It', 'briefly', 'defines', 'FPNA-FPNN', 'concept.', 'It', 'introduces', 'parallel', 'form', 'FPNN', 'computation,', 'feedforward', 'recurrent', 'FPNN.', 'It', 'describes', 'FPGA-based', 'modular', 'implementation', 'base', 'asynchronous', 'blocks.', 'A', 'result', 'FPNN', 'application', 'briefly', 'discussed.']\n",
      "abstract\\a32.txt\n",
      "\n",
      "['Presents', 'inference', 'mechanism', 'logic', 'program', 'language', 'use', 'neural', 'network', 'flexible', 'suit', 'fine-grain', 'parallel', 'computing.', 'The', 'author', 'approach', 'radically', 'different', 'conventional', 'method', 'base', 'refutation', 'processes.', 'Programs', 'write', 'logic', 'program', 'language', 'transform', 'Hopfield-type', 'neural', 'network', 'relaxation', 'technique', 'apply', 'network', 'inference', 'solutions.', 'The', 'author', 'propose', 'algorithm', 'transform', 'logic', 'program', 'Hopfield-type', 'neural', 'network', 'implement', 'prototype', 'inference', 'system', 'base', 'mechanism.', 'The', 'author', 'test', 'system', 'preliminary', 'problems.', 'Preliminary', 'result', 'confirm', 'algorithm', 'correct.']\n",
      "abstract\\a33.txt\n",
      "\n",
      "['The', 'use', 'flash', 'device', 'analog', 'storage', 'analog', 'computation', 'result', 'highly', 'efficient', 'switched-capacitor', 'implementation', 'neural', 'networks.', 'The', 'standard', 'flash', 'device', 'suffers', 'severe', 'limitation', 'application', 'due', 'relatively', 'large', 'parasitic', 'overlap', 'capacitances.', 'This', 'paper', 'introduces', 'computational', 'concept,', 'circuit', 'architecture', 'explore', 'well', 'novel', 'flash-based', 'programmable', 'nonlinear', 'capacitor', 'much', 'improve', 'charge', 'domain', 'characteristic', 'application.', 'These', 'device', 'demonstrate', 'novel', 'circuit', 'consist', 'two', 'device', 'capable', 'compute', '5-bit', 'absolute-value-of-difference', 'energy', 'consumption', 'less', '1', 'pJ.<>']\n",
      "abstract\\a34.txt\n",
      "\n",
      "['Deep', 'Learning', 'artificial', 'intelligence', 'function', 'imitates', 'mechanism', 'human', 'mind', 'processing', 'record', 'develop', 'shape', 'use', 'selection', 'construction.', 'The', 'objective', 'paper', 'improve', 'performance', 'deep', 'learn', 'use', 'propose', 'algorithm', 'call', 'RFHTMC.', 'This', 'propose', 'algorithm', 'merge', 'version', 'Random', 'Forest', 'HTM', 'Cortical', 'Learning', 'Algorithm.', 'The', 'methodology', 'improve', 'performance', 'Deep', 'Learning', 'depends', 'concept', 'minimize', 'mean', 'absolute', 'percentage', 'error', 'indication', 'high', 'performance', 'forecast', 'procedure.', 'In', 'addition', 'overlap', 'duty', 'cycle', 'high', 'percentage', 'indication', 'speed', 'processing', 'operation', 'classifier.', 'The', 'outcome', 'depict', 'propose', 'set', 'rule', 'reduces', 'absolute', 'percent', 'error', 'use', 'half', 'value.', 'And', 'increase', 'percentage', 'overlap', 'duty', 'cycle', '15%.']\n",
      "abstract\\a35.txt\n",
      "\n",
      "['Recent', 'basic', 'study', 'reveal', 'novel', 'solution', 'fundamental', 'AI', 'problem', 'deeply', 'root', 'understand', 'natural', 'intelligence', 'maturity', 'suitable', 'mathematical', 'mean', 'rigorously', 'model', 'brain', 'machine', 'understandable', 'forms.', 'Learning', 'cognitive', 'process', 'knowledge', 'behavior', 'acquisition.', 'Learning', 'classify', 'five', 'category', 'know', 'object', 'identification,', 'cluster', 'classification,', 'functional', 'regression,', 'behavior', 'generation,', 'knowledge', 'acquisition.', 'The', 'late', 'discovery', 'knowledge', 'science', 'Wang', 'reveal', 'basic', 'unit', 'knowledge', 'binary', 'relation', '(bir)', 'bit', 'information', 'data.', 'A', 'fundamental', 'challenge', 'knowledge', 'learn', 'different', 'deep', 'recur', 'neural', 'network', 'technology', 'lead', 'emergence', 'field', 'cognitive', 'machine', 'learn', 'basis', 'recent', 'breakthrough', 'denotational', 'mathematics', 'mathematical', 'engineering.', 'This', 'keynote', 'lecture', 'present', 'late', 'advance', 'formal', 'brain', 'study', 'cognitive', 'system', 'deep', 'reason', 'deep', 'learning.', 'It', 'recognize', 'key', 'technology', 'enable', 'cognitive', 'robot', 'mimic', 'brain', 'rely', 'deep', 'learning,', 'also', 'deep', 'reason', 'think', 'towards', 'machinable', 'thought', 'cognitive', 'knowledge', 'base', 'built', 'cognitive', 'systems.', 'Fundamental', 'theory', 'novel', 'technology', 'implement', 'deep', 'think', 'robot', 'demonstrate', 'base', 'concept', 'algebra,', 'semantics', 'algebra', 'inference', 'algebra.']\n",
      "abstract\\a36.txt\n",
      "\n",
      "['Deep', 'Reinforcement', 'Learning', 'combination', 'Reinforcement', 'Learning', 'algorithm', 'Deep', 'neural', 'network,', 'recent', 'success', 'learn', 'complicate', 'unknown', 'environments.', 'The', 'train', 'model', 'Convolutional', 'Neural', 'Network', 'train', 'use', 'Q-Learning', 'Loss', 'value.', 'The', 'agent', 'take', 'observation,', 'i.e.', 'raw', 'pixel', 'image', 'reward', 'environment', 'step', 'input.', 'The', 'deep', 'Q-learning', 'algorithm', 'give', 'optimal', 'action', 'every', 'observation', 'reward', 'pair.', 'The', 'hyperparameters', 'Deep', 'Q-Network', 'remain', 'unchanged', 'environment.', 'TensorFIow,', 'open', 'source', 'machine', 'learn', 'numerical', 'computation', 'library', 'use', 'implement', 'deep', 'Q-Learning', 'algorithm', 'GPU.', 'The', 'distribute', 'TensorFIow', 'architecture', 'use', 'maximize', 'hardware', 'resource', 'utilization', 'reduce', 'training', 'time.', 'The', 'usage', 'Graphics', 'Processing', 'Unit', '(GPU)', 'distribute', 'environment', 'accelerate', 'training', 'deep', 'Q-network.', 'On', 'implement', 'deep', 'Q-learning', 'algorithm', 'many', 'environment', 'OpenAI', 'Gym,', 'agent', 'outperforms', 'decent', 'human', 'reference', 'player', 'day', 'training.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a37.txt\n",
      "\n",
      "['The', 'recent', 'development', 'learn', 'deep', 'representation', 'demonstrate', 'wide', 'application', 'traditional', 'vision', 'task', 'like', 'classification', 'detection.', 'However,', 'little', 'investigation', 'could', 'build', 'deep', 'learn', 'framework', 'weakly', 'supervise', 'setting.', 'In', 'paper,', 'attempt', 'model', 'deep', 'learn', 'weakly', 'supervise', 'learn', '(multiple', 'instance', 'learning)', 'framework.', 'In', 'setting,', 'image', 'follow', 'dual', 'multi-instance', 'assumption,', 'object', 'proposal', 'possible', 'text', 'annotation', 'regard', 'two', 'instance', 'sets.', 'We', 'thus', 'design', 'effective', 'system', 'exploit', 'MIL', 'property', 'deep', 'learn', 'strategy', 'two', 'ends;', 'also', 'try', 'jointly', 'learn', 'relationship', 'object', 'annotation', 'proposals.', 'We', 'conduct', 'extensive', 'experiment', 'prove', 'weakly', 'supervise', 'deep', 'learn', 'framework', 'achieves', 'convincing', 'performance', 'vision', 'task', 'include', 'classification', 'image', 'annotation,', 'also', 'extract', 'reasonable', 'region-keyword', 'pair', 'little', 'supervision,', 'widely', 'use', 'benchmark', 'like', 'PASCAL', 'VOC', 'MIT', 'Indoor', 'Scene', '67,', 'also', 'dataset', 'image-and', 'patch-level', 'annotations.']\n",
      "abstract\\a38.txt\n",
      "\n",
      "['The', 'late', 'generation', 'Deep', 'Convolutional', 'Neural', 'Networks', '(DCNN)', 'dramatically', 'advanced', 'challenge', 'computer', 'vision', 'tasks,', 'especially', 'object', 'detection', 'object', 'classification,', 'achieve', 'state-of-the-art', 'performance', 'several', 'computer', 'vision', 'task', 'include', 'text', 'recognition,', 'sign', 'recognition,', 'face', 'recognition', 'scene', 'understanding.', 'The', 'depth', 'supervise', 'network', 'enable', 'learn', 'deeper', 'hierarchical', 'representation', 'features.', 'In', 'parallel,', 'unsupervised', 'deep', 'learn', 'Convolutional', 'Deep', 'Belief', 'Network', '(CDBN)', 'also', 'achieve', 'state-of-the-art', 'many', 'computer', 'vision', 'tasks.', 'However,', 'limited', 'research', 'jointly', 'exploit', 'strength', 'two', 'approaches.', 'In', 'paper,', 'investigate', 'learn', 'capability', 'methods.', 'We', 'compare', 'output', 'individual', 'layer', 'show', 'many', 'learnt', 'filter', 'output', 'correspond', 'level', 'layer', 'almost', 'similar', 'approaches.', 'Stacking', 'DCNN', 'top', 'unsupervised', 'layer', 'replace', 'layer', 'DCNN', 'correspond', 'learnt', 'layer', 'CDBN', 'improve', 'recognition/classification', 'accuracy', 'training', 'computational', 'expense.', 'We', 'demonstrate', 'validity', 'proposal', 'ImageNet', 'dataset.']\n",
      "abstract\\a39.txt\n",
      "\n",
      "['A', 'recent', 'work', 'introduce', 'concept', 'deep', 'dictionary', 'learning.', 'In', 'deep', 'dictionary', 'learning,', 'first', 'level', 'proceeds', 'like', 'standard', 'dictionary', 'learning;', 'sub-sequent', 'layer', '(scaled)', 'output', 'coefficient', 'previous', 'layer', 'use', 'input', 'dictionary', 'learning.', 'This', 'unsupervised', 'deep', 'learn', 'approach.', 'The', 'feature', 'final', 'deepest', 'layer', 'employ', 'subsequent', 'analysis', 'classification.', 'The', 'seminal', 'paper', 'stack', 'denoising', 'autoencoders', 'show', 'robust', 'deep', 'model', 'learnt', 'noisy', 'data', 'use', 'training', 'stack', 'autoencoders', 'instead', 'clean', 'data.', 'We', 'adopt', 'idea', 'deep', 'dictionary', 'learn', 'framework;', 'instead', 'use', 'clean', 'data', 'augment', 'training', 'dataset', 'add', 'noise;', 'improves', 'robustness.', 'Experimental', 'evaluation', 'benchmark', 'deep', 'learn', 'datasets', 'real', 'world', 'problem', 'AD', 'classification', 'show', 'proposal', 'yield', 'considerable', 'improvement.']\n",
      "abstract\\a40.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'Recent', 'basic', 'study', 'reveal', 'AI', 'problem', 'deeply', 'root', 'understand', 'natural', 'intelligence', 'adoption', 'suitable', 'mathematical', 'mean', 'rigorously', 'model', 'brain', 'machine', 'understandable', 'forms.', 'Learning', 'cognitive', 'process', 'knowledge', 'behavior', 'acquisition.', 'Learning', 'classify', 'five', 'category', 'know', 'object', 'identification,', 'cluster', 'classification,', 'functional', 'regression,', 'behavior', 'generation,', 'knowledge', 'acquisition.', 'A', 'fundamental', 'challenge', 'knowledge', 'learn', 'different', 'deep', 'recur', 'neural', 'network', 'technology', 'lead', 'emergence', 'field', 'cognitive', 'machine', 'learn', 'basis', 'recent', 'breakthrough', 'denotational', 'mathematics', 'mathematical', 'engineering.', 'This', 'keynote', 'lecture', 'present', 'late', 'advance', 'formal', 'brain', 'study', 'cognitive', 'system', 'deep', 'reason', 'deep', 'learning.', 'It', 'recognize', 'key', 'technology', 'enable', 'cognitive', 'robot', 'mimic', 'brain', 'rely', 'deep', 'learning,', 'also', 'deep', 'reason', 'think', 'towards', 'machinable', 'thought', 'cognitive', 'knowledge', 'base', 'built', 'cognitive', 'systems.', 'A', 'fundamental', 'theory', 'novel', 'technology', 'implement', 'deep', 'think', 'robot', 'demonstrate', 'base', 'concept', 'algebra,', 'semantics', 'algebra,', 'inference', 'algebra.']\n",
      "abstract\\a41.txt\n",
      "\n",
      "['In', 'parallel', 'rapid', 'development', 'prospective', 'system', 'last', '20', 'years,', 'many', 'method', 'apply', 'field.', 'One', 'deep', 'learn', 'network', 'attract', 'interest', 'researcher', 'recent', 'years.', 'The', 'DBN', '(Deep', 'Belief', 'Network),', 'train', 'one', 'layer', 'time', 'greedily,', 'us', 'unsupervised', 'learn', 'layer', 'compose', 'RBMs', '(Restricted', 'Boltzman', 'Machine),', 'become', 'turn', 'point', 'area.', 'In', 'study,', 'deep', 'learn', 'method', 'apply', 'recommender', 'system', 'problem.', 'The', 'Python-based', 'deep', 'learn', 'library,', 'Keras,', 'use', 'exist', 'learn', 'algorithm', 'compared.']\n",
      "abstract\\a42.txt\n",
      "\n",
      "['Deep', 'Learning', 'appeal', 'learn', 'large', 'amount', 'unlabeled/unsupervised', 'data,', 'make', 'attractive', 'extract', 'meaningful', 'representation', 'pattern', 'big', 'data.', 'Deep', 'learning,', 'simplest', 'definition,', 'express', 'application', 'machine', 'learn', 'method', 'big', 'data.', 'In', 'study,', 'investigate', 'apply', 'hierarchical', 'deep', 'learn', 'model', 'problem', 'finance', 'prediction', 'classification.', 'The', 'Design', 'pricing', 'securities,', 'construction', 'portfolios,', 'risk', 'management', 'stock', 'market', 'forecasting', 'important', 'prediction', 'problem', 'finance.', 'These', 'kind', 'problem', 'include', 'large', 'data', 'set', 'complex', 'relationship', 'among', 'data', 'events.', 'It', 'difficult', 'sometimes', 'impossible', 'represent', 'complex', 'relationship', 'full', 'economic', 'model.', 'Deep', 'learn', 'methods,', 'represent', 'complex', 'relationship', 'among', 'data,', 'allows', 'production', 'useful', 'result', 'standard', 'method', 'finance.', 'In', 'study,', 'introduce', 'apply', 'deep', 'learn', 'method', 'stock', 'market', 'prediction', 'problem', 'obtain', 'successful', 'results.']\n",
      "abstract\\a43.txt\n",
      "\n",
      "['Machine', 'learning,', 'especially', 'neural', 'networks,', 'attract', 'attention', 'past', 'decades.', 'With', 'research', 'intelligent', 'algorithm', 'network', 'structures,', 'machine', 'learn', 'widely', 'use', 'data', 'mining,', 'computer', 'vision,', 'data', 'recognition', 'classification.', 'Because', 'target', 'data', 'nonlinear', 'complex,', 'research', 'need', 'extract', 'accurate', 'feature', 'space', 'data', 'space.', 'This', 'process', 'relies', 'machine', 'learn', 'perform', 'well', 'manual', 'rule', 'achieve', 'efficient', 'functions.', 'The', 'researcher', 'combine', 'kernel', 'approach', 'deep', 'neural', 'network', 'maintain', 'advantage', 'compensate', 'defects,', 'apply', 'depth', 'kernel', 'learn', 'improve', 'performance', 'algorithm.', 'In', 'paper,', 'present', 'overview', 'progress', 'application', 'deep', 'core', 'learning.', 'We', 'introduce', 'basic', 'theory', 'fusion', 'form', 'several', 'deep', 'core', 'learn', 'structure', 'improve', 'performance', 'performance', 'algorithm', 'practice.']\n",
      "abstract\\a44.txt\n",
      "\n",
      "['Recently,', 'deep', 'learn', 'emerge', 'state-of-the-art', 'approach', 'deliver', 'robust', 'highly', 'accurate', 'inference', 'many', 'domains,', 'include', 'Internet-of-Things', '(IoT).', 'Deep', 'learn', 'already', 'change', 'way', 'computer', 'embed', 'IoT', 'device', 'make', 'intelligent', 'decision', 'use', 'sensor', 'feed', 'real', 'world.', 'There', 'significant', 'effort', 'develop', 'light-weight', 'highly', 'efficient', 'deep', 'learn', 'inference', 'mechanism', 'resource-constrained', 'mobile', 'IoT', 'devices.', 'Some', 'approach', 'propose', 'hardware-based', 'accelerator,', 'approach', 'propose', 'reduce', 'amount', 'computation', 'deep', 'learn', 'model', 'use', 'various', 'model', 'compression', 'techniques.', 'Even', 'though', 'effort', 'demonstrate', 'significant', 'gain', 'performance', 'efficiency,', 'aware', 'Quality-of-Service', '(QoS)', 'requirement', 'various', 'IoT', 'applications,', 'and,', 'hence', 'manifest', 'unpredictable', \"'best-effort'\", 'performance', 'term', 'inference', 'latency,', 'power', 'consumption,', 'resource', 'usage,', 'etc.', 'In', 'IoT', 'device', 'temporal', 'constraints,', 'unpredictability', 'might', 'result', 'undesirable', 'effect', 'compromise', 'safety.', 'In', 'work,', 'present', 'novel', 'deep', 'learn', 'inference', 'runtime', 'called,', 'DeepRT.', 'Unlike', 'previous', 'inference', 'accelerators,', 'DeepRT', 'focus', 'support', 'predictable', 'inference', 'performance', 'temporally', 'spatially.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a45.txt\n",
      "\n",
      "['In', 'paper,', 'introduce', 'distribute', 'deep', 'learn', 'platform,', 'BAIPAS,', 'Big', 'Data', 'AI', 'base', 'Predication', 'Analysis', 'System.', 'In', 'case', 'deep', 'learn', 'use', 'big', 'data,', 'take', 'much', 'time', 'train', 'data.', 'To', 'reduce', 'training', 'time,', 'method', 'us', 'distribute', 'deep', 'learning.', 'When', 'big', 'data', 'exists', 'external', 'storage,', 'training', 'take', 'long', 'time', 'take', 'lot', 'network', 'I/O', 'time', 'data', 'load', 'deep', 'learn', 'operations.', 'We', 'propose', 'data', 'locality', 'management', 'way', 'reduce', 'training', 'time', 'big', 'data.', 'BAIPAS', 'distribute', 'deep', 'learn', 'platform', 'aim', 'provide', 'quick', 'learn', 'big', 'data,', 'easy', 'installation', 'monitoring', 'platform,', 'convenience', 'developer', 'deep', 'learn', 'models.', 'In', 'order', 'provide', 'fast', 'training', 'use', 'big', 'data,', 'data', 'distribute', 'store', 'worker-server', 'storage', 'use', 'data', 'locality', 'shuffling,', 'training', 'performed.', 'The', 'data', 'locality', 'manager', 'analyzes', 'training', 'data', 'state', 'information', 'worker', 'servers.', 'This', 'distributes', 'data', 'schedule', 'accord', 'available', 'storage', 'space', 'worker', 'server', 'learn', 'performance', 'worker', 'server.', 'However,', 'worker', 'server', 'conduct', 'deep', 'learn', 'use', 'distribute', 'training', 'data,', 'model', 'overfitting', 'may', 'occur', 'compare', 'method', 'learn', 'full', 'training', 'data', 'set.', 'To', 'solve', 'problem,', 'apply', 'shuffle', 'method', 'move', 'already', 'learn', 'data', 'another', 'worker', 'server', 'training', 'performed.', 'Thereby,', 'worker', 'server', 'contain', 'full', 'training', 'data', 'set.', 'BAIPAS', 'us', 'Kubernetes', 'Docker', 'provide', 'easy', 'installation', 'monitoring', 'platform.', 'It', 'also', 'provide', 'pre-processing', 'modules,', 'management', 'tools,', 'automation', 'cluster', 'creation,', 'resource', 'monitoring,', 'resources;', 'developer', 'easily', 'develop', 'deep', 'learn', 'models.']\n",
      "abstract\\a46.txt\n",
      "\n",
      "['SARSA,', 'one', 'kind', 'on-policy', 'reinforcement', 'learn', 'methods,', 'integrate', 'deep', 'learn', 'solve', 'video', 'game', 'control', 'problem', 'paper.', 'We', 'use', 'deep', 'convolutional', 'neural', 'network', 'estimate', 'state-action', 'value,', 'SARSA', 'learn', 'update', 'it.', 'Besides,', 'experience', 'replay', 'introduce', 'make', 'training', 'process', 'suitable', 'scalable', 'machine', 'learn', 'problems.', 'In', 'way,', 'new', 'deep', 'reinforcement', 'learn', 'method,', 'call', 'deep', 'SARSA', 'propose', 'solve', 'complicate', 'control', 'problem', 'imitate', 'human', 'play', 'video', 'games.', 'From', 'experiment', 'results,', 'conclude', 'deep', 'SARSA', 'learn', 'show', 'well', 'performance', 'aspect', 'deep', 'Q', 'learning.']\n",
      "abstract\\a47.txt\n",
      "\n",
      "['Deep', 'learn', 'propose', 'Hinton', 'et', 'al', 'new', 'learn', 'algorithm', 'multi-layer', 'neural', 'network,', 'also', 'new', 'study', 'field', 'machine', 'learning.', 'This', 'paper', 'describes', 'structure', 'advantage', 'shallow', 'learn', 'deep', 'learning,', 'analyzes', 'current', 'popular', 'learn', 'algorithm', 'detail.', 'Finally,', 'paper', 'analyzes', 'research', 'direction', 'future', 'prospect', 'deep', 'learning.']\n",
      "abstract\\a48.txt\n",
      "\n",
      "['A', 'promising', 'direction', 'deep', 'learn', 'research', 'learn', 'representation', 'simultaneously', 'discover', 'cluster', 'structure', 'unlabeled', 'data', 'optimize', 'discriminative', 'loss', 'function.', 'Contrary', 'supervise', 'deep', 'learning,', 'line', 'research', 'infancy', 'design', 'optimization', 'suitable', 'loss', 'function', 'aim', 'training', 'deep', 'neural', 'network', 'cluster', 'still', 'open', 'challenge.', 'In', 'paper,', 'propose', 'leverage', 'discriminative', 'power', 'information', 'theoretic', 'divergence', 'measures,', 'experienced', 'success', 'traditional', 'clustering,', 'develop', 'new', 'deep', 'cluster', 'network.', 'Our', 'propose', 'loss', 'function', 'incorporates', 'explicitly', 'geometry', 'output', 'space,', 'facilitates', 'fully', 'unsupervised', 'training', 'end-to-end.', 'Experiments', 'real', 'datasets', 'show', 'propose', 'algorithm', 'achieves', 'competitive', 'performance', 'respect', 'state-of-the-art', 'methods.']\n",
      "abstract\\a5.txt\n",
      "\n",
      "['The', 'traditional', 'SVM', 'support', 'incremental', 'learning.', 'And', 'traditional', 'training', 'method', 'SVM', 'work', 'amount', 'training', 'sample', 'large', 'put', 'RAM', 'computer.', 'In', 'order', 'solve', 'problem', 'improve', 'speed', 'training', 'SVM,', 'natural', 'characteristic', 'SV', 'analyze', 'paper.', 'An', 'incremental', 'learn', 'algorithm', '(I-SVM)', 'SVM', 'discard', 'part', 'history', 'sample', 'presented.', 'The', 'theoretical', 'analysis', 'experimental', 'result', 'show', 'algorithm', 'speed', 'training', 'process,', 'also', 'reduce', 'storage', 'cost,', 'classification', 'precision', 'also', 'guaranteed.']\n",
      "abstract\\a50.txt\n",
      "\n",
      "['Deep', 'architecture', 'convolution', 'structure', 'found', 'highly', 'effective', 'commonly', 'use', 'computer', 'vision.', 'With', 'introduction', 'Graphics', 'Processing', 'Unit', '(GPU)', 'general', 'purpose', 'issues,', 'increase', 'attention', 'towards', 'exploit', 'GPU', 'processing', 'power', 'deep', 'learn', 'algorithms.', 'Also,', 'large', 'amount', 'data', 'online', 'make', 'possible', 'train', 'deep', 'neural', 'network', 'efficiently.', 'The', 'aim', 'paper', 'perform', 'systematic', 'mapping', 'study,', 'order', 'investigate', 'exist', 'research', 'implementation', 'computer', 'vision', 'approach', 'base', 'deep', 'learn', 'algorithm', 'Convolutional', 'Neural', 'Networks', '(CNN).', 'We', 'select', 'total', '119', 'papers,', 'classify', 'accord', 'field', 'interest,', 'network', 'type,', 'learn', 'paradigm,', 'research', 'contribution', 'type.', 'Our', 'study', 'demonstrates', 'field', 'promising', 'area', 'research.', 'We', 'choose', 'human', 'pose', 'estimation', 'video', 'frame', 'possible', 'computer', 'vision', 'task', 'explore', 'research.', 'After', 'careful', 'study', 'propose', 'three', 'different', 'research', 'direction', 'related', 'to:', 'improve', 'exist', 'CNN', 'implementations,', 'use', 'Recurrent', 'Neural', 'Networks', '(RNNs)', 'human', 'pose', 'estimation', 'finally', 'rely', 'unsupervised', 'learn', 'paradigm', 'train', 'NNs.']\n",
      "abstract\\a51.txt\n",
      "\n",
      "['This', 'paper', 'discus', 'emergence', 'cooperative', 'coordinate', 'behavior', 'joint', 'concurrent', 'learn', 'agent', 'use', 'deep', 'Q-learning.', 'Multi-agent', 'system', '(MAS)', 'arise', 'variety', 'domains.', 'The', 'collective', 'effort', 'one', 'main', 'building', 'block', 'many', 'fundamental', 'system', 'exist', 'world,', 'thus,', 'sequential', 'decision', 'make', 'uncertainty', 'collaborative', 'work', 'one', 'important', 'challenge', 'issue', 'intelligent', 'cooperative', 'multiple', 'agents.', 'However,', 'decision', 'cooperation', 'highly', 'sophisticated', 'complicate', 'agent', 'may', 'certain', 'share', 'goal', 'individual', 'goal', 'achieve', 'behavior', 'inevitably', 'influence', 'other.', 'Therefore,', 'attempt', 'explore', 'whether', 'agent', 'use', 'deep', 'Q-networks', '(DQN)', 'learn', 'cooperative', 'behavior.', 'We', 'use', 'double', 'pong', 'game', 'example', 'investigate', 'learn', 'divide', 'work', 'iterate', 'game', 'executions.', 'In', 'approach,', 'agent', 'jointly', 'learn', 'divide', 'area', 'responsibility', 'agent', 'us', 'DQN', 'modify', 'behavior.', 'We', 'also', 'investigate', 'learn', 'behavior', 'change', 'accord', 'environmental', 'characteristic', 'include', 'reward', 'scheme', 'learn', 'techniques.', 'Our', 'experiment', 'indicate', 'effective', 'cooperative', 'behavior', 'balance', 'division', 'workload', 'emerge.', 'These', 'result', 'help', 'u', 'well', 'understand', 'agent', 'behave', 'interact', 'complex', 'environment', 'coherently', 'choose', 'individual', 'action', 'result', 'joint', 'action', 'optimal.']\n",
      "abstract\\a52.txt\n",
      "\n",
      "['Deep', 'Belief', 'Network', 'algorithm', 'among', 'deep', 'learning.', 'It', 'effective', 'method', 'solve', 'problem', 'neural', 'network', 'deep', 'layers,', 'low', 'velocity', 'overfitting', 'phenomenon', 'learning.', 'In', 'paper,', 'introduce', 'process', 'Deep', 'Belief', 'Network', 'use', 'Restricted', 'Boltzmann', 'Machines.', 'What', 'more,', 'combine', 'Deep', 'Belief', 'Network', 'together', 'softmax', 'classifier,', 'use', 'recognition', 'handwritten', 'numbers.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a53.txt\n",
      "\n",
      "['Hand', 'gesture', 'recognition', 'one', 'major', 'research', 'area', 'field', 'Human', 'computer', 'interaction', '(HCl).', 'This', 'paper', 'proposes', 'deep', 'reinforcement', 'learn', 'algorithm', 'recognize', 'human', 'arm', 'movement', 'pattern', 'use', 'IoT', 'sensor', 'device.', 'Recent', 'study', 'explore', 'supervise', 'learn', 'base', 'methods,', 'CNN', 'RNN', 'implement', 'HCl', 'device.', 'On', 'hand,', 'deep', 'reinforcement', 'learn', 'approach', 'also', 'investigated.', 'Algorithms', 'use', 'approach,', 'learn', 'pattern', 'sensor', 'use', 'reward', 'feedback', 'class', 'labels.', 'This', 'allows', 'user', 'control', 'IoT', 'device', 'produce', 'desire', 'arm', 'movement', 'pattern', 'without', 'create', 'labels.', 'In', 'paper,', 'performance', 'convolutional', 'neural', 'network', '(CNN)', 'DQN', 'model', 'compare', 'long', 'short-term', 'memory', '(LSTM)', 'model', 'DQN.', 'Results', 'show', 'CNN', 'base', 'DQN', 'model', 'stable', 'compare', 'LSTM', 'base', 'model,', 'yield', 'high', 'classification', 'accuracy', '98.33%', 'predict', 'arm', 'movement', 'patterns.']\n",
      "abstract\\a54.txt\n",
      "\n",
      "['This', 'paper', 'introduces', 'new', 'surveillance', 'platform', 'equip', 'multiple', 'parallel', 'deep', 'learn', 'frameworks.', 'The', 'deep', 'learn', 'framework', 'use', 'face', 'recognition', 'input', 'image', 'video', 'stream', 'CCTV', 'camera', 'security', 'applications.', 'Each', 'deep', 'learn', 'framework', 'accuracy', '(related', 'recognition', 'performance)', 'operation', 'time', '(related', 'system', 'stability)', 'tradeoff', 'relationship.', 'Based', 'system', 'architecture,', 'new', 'dynamic', 'control', 'algorithm', 'selects', 'one', 'deep', 'learn', 'framework', 'time-average', 'security-level', '(i.e.,', 'machine', 'learn', 'accuracy', 'recognition', 'classification)', 'maximization', 'consideration', 'system', 'stability.', 'The', 'performance', 'propose', 'algorithm', 'evaluate', 'also', 'verify', 'achieves', 'desire', 'performance.']\n",
      "abstract\\a55.txt\n",
      "\n",
      "['High-performance', 'I/O', 'essential', 'big-data', 'analyses.', 'Modern', 'storage', 'system', 'utilize', 'HDDs', 'SSDs', 'mainly', 'achieve', 'large', 'capacity', 'high', 'performance,', 'respectively.', 'Using', 'SSD', 'cache', 'access', 'HDDs', 'one', 'promising', 'method', 'improve', 'large-scale', 'I/O', 'performance', 'modern', 'computers.', 'In', 'addition,', 'M.2', 'increase', 'importance', 'high-performance', 'I/O', 'processing.', 'In', 'paper,', 'investigate', 'I/O', 'performance', 'storage', 'system', 'include', 'M.2', 'SSD', 'SSD', 'cache.', 'Our', 'experimental', 'result', 'show', 'big-data', 'processing', 'performance', 'improve', 'significantly', 'use', 'M.2', 'SSD', 'cache']\n",
      "abstract\\a56.txt\n",
      "\n",
      "['propose', 'two', 'new', 'method', 'accelerate', 'learn', 'task', 'use', 'Q-learning', 'algorithm.', 'We', 'focus', 'specifically', 'learn', 'task,', 'Credit', 'Assignment', '(CA)', 'problem.', 'A', 'Reinforcement', 'Algorithm', '(RL)', 'agent', 'perform', 'task', 'high', 'dimensional', 'state-space.', 'The', 'main', 'idea', 'paper', 'use', 'latent', 'variable', 'deep', 'autoencoders', 'provide,', 'make', 'well', 'reward', 'system.', 'We', 'show', 'use', 'new', 'reward', 'speed', 'learn', 'task', 'similar', 'circumstances.', 'The', 'task', 'chosen', 'algorithm', 'Push', 'Recovery', '(PR)', 'simulated', 'environment.']\n",
      "abstract\\a57.txt\n",
      "\n",
      "['Recently,', 'grow', 'interest', 'apply', 'deep', 'learn', 'game', 'AI', 'domain.', 'Among', 'them,', 'deep', 'reinforcement', 'learn', 'famous', 'game', 'AI', 'communities.', 'In', 'paper,', 'propose', 'use', 'redundant', 'output', 'order', 'adapt', 'training', 'progress', 'deep', 'reinforcement', 'learning.', 'We', 'compare', 'method', 'general', 'Îµ-greedy', 'ViZDoom', 'platform.', 'Since', 'AI', 'player', 'select', 'action', 'base', 'visual', 'input', 'platform,', 'suitable', 'deep', 'reinforcement', 'learn', 'research.', 'Experimental', 'result', 'show', 'propose', 'method', 'archive', 'competitive', 'performance', 'Îµ-greedy', 'without', 'parameter', 'tuning.']\n",
      "abstract\\a58.txt\n",
      "\n",
      "['Summary', 'form', 'given,', 'follows.', 'The', 'author', 'describes', 'recent', 'advance', 'hardware', 'implementation', 'neural', 'networks,', 'give', 'expectation', 'future', 'aspect', 'neural', 'network', 'technology.<>']\n",
      "abstract\\a59.txt\n",
      "\n",
      "['Proposes', 'extend', 'bidirectional', 'associative', 'memory', '(BAM)', 'neural', 'network', 'model', 'auto-', 'hetero-associative', 'memory.', 'The', 'theoretical', 'proof', 'neural', 'network', \"model's\", 'stability', 'given.', 'Experiments', 'show', 'neural', 'network', 'model', 'much', 'powerful', 'M-P', 'model,', 'discrete', 'Hopfield', 'neural', 'network,', 'continuous', 'Hopfield', 'neural', 'network,', 'discrete', 'bidirectional', 'associative', 'memory', 'neural', 'network,', 'continuous', 'adaptive', 'bidirectional', 'associative', 'memory', 'neural', 'network,', 'backpropagation', 'neural', 'network', 'optimal', 'design', 'nonlinear', 'continuous', 'neural', 'network.', 'Experimental', 'result', 'also', 'show', 'that,', 'auto-associative', 'memory,', 'power', 'model', 'loop', 'neural', 'network', 'model', 'auto-associative', 'memory.']\n",
      "abstract\\a6.txt\n",
      "\n",
      "['The', 'theory', 'machine', 'learn', 'metric', 'space', 'new', 'research', 'topic', 'drawn', 'much', 'attention', 'recent', 'years.', 'The', 'theoretical', 'foundation', 'topic', 'question', 'condition', 'two', 'sample', 'set', 'separate', 'space.', 'In', 'paper,', 'motivate', 'develop', 'new', 'support', 'vector', 'machine', '(SVM)', 'fuzzy', 'number', 'space,', 'present', 'necessary', 'sufficient', 'condition', 'separate', 'two', 'finite', 'class', 'sample', 'hyper-plane', 'n-dimensional', 'fuzzy', 'number', 'space.', 'We', 'also', 'present', 'attainable', 'expression', 'maximal', 'margin', 'separate', 'hyper-planes', 'include', 'case', 'class', 'infinite', 'sample', 'n-dimensional', 'fuzzy', 'number', 'space.', 'These', 'result', 'generalize', 'improve', 'correspond', 'conclusion', 'theory', 'SVM', 'Hilbert', 'space', 'fuzzy', 'number', 'space.']\n",
      "abstract\\a60.txt\n",
      "\n",
      "['FEN', '(fuzzy', 'expert', 'network)', 'new', 'network', 'architecture', 'neural', 'object', 'fuzzy', 'modeling.', 'The', 'neural', 'object', 'process', 'information', 'node', 'function', 'different', 'typical', 'sigmoidal', 'node', 'processor', 'analog', 'perceptron.', 'By', 'connect', 'type', 'node', 'processor', 'event', 'driven', 'acyclic', '(feedforward)', 'neural', 'network,', 'FEN', 'represent', 'fuzzy', 'model', 'self', 'adjustment.', 'Weights', 'network', 'imply', 'fuzzy', 'parameter', 'adjust', 'restriction', 'layer', 'topology', 'learning.', 'FEN', 'offer', 'automate', 'tune', 'input-output', 'data', 'membership', 'function', 'performance', 'fuzzy', 'model', 'depends.', 'And', 'especially', 'use', 'enhance', 'idea', 'dynamic', 'backward', 'error', 'assignment', 'learning,', 'FEN', 'effective', 'tune', 'parameter', 'nonsmooth', 'membership', 'functions,', 'example,', 'symmetric', 'triangular', 'function', 'antecedent', 'part.', 'Results', 'test', 'FEN', 'present', 'demonstrate', 'learn', 'performance', 'adaptability.']\n",
      "abstract\\a61.txt\n",
      "\n",
      "['In', 'paper,', 'describe', 'VLSI', 'implementation', 'modify', 'backpropagation', 'learn', 'T-Model', 'neural', 'networks.', 'A', 'digitally-controlled', 'synapse', 'circuit', 'adaptation', 'rule', 'circuit', 'R-2R', 'ladder', 'network,', 'simple', 'control', 'logic', 'circuit', 'UP/DOWN', 'counter', 'implement', 'realize', 'modify', 'backpropagation', 'error', 'technique.', 'We', 'also', 'present', 'adaptive', 'learn', 'use', 'digitally-controlled', 'synapse', 'T-Model', 'network', 'several', 'example', 'order', 'study', 'learn', 'capability', 'analog', 'T-Model', 'neural', 'hardware.', 'These', 'experiment', 'show', 'T-Model', 'adaptive', 'neural', 'network', 'use', 'modify', 'backpropagation', 'perform', 'learn', 'procedure', 'quite', 'well.']\n",
      "abstract\\a62.txt\n",
      "\n",
      "['Subthreshold', 'analog', 'circuit', 'MOS', 'implementation', 'artificial', 'neural', 'network', 'present', 'on-chip', 'learn', 'capability.', 'Each', 'synapse', 'circuit', 'consist', 'storage', 'capacitor', '3', 'analog', 'multiplier,', 'i.e.', 'one', 'signal', 'feedforward,', 'one', 'outer-product', 'synaptic', 'weight', 'adjustments,', 'one', 'error', 'backpropagation.', 'While', '3', 'multiplier', 'use', 'error', 'backpropagation', 'learning,', 'first', '2', 'multiplier', 'use', 'Hebbian', 'learning.', 'Each', 'neuron', 'circuit', 'compose', 'sigmoid', 'circuit', 'sigmoid', 'derivative', 'circuit,', 'show', 'near', 'ideal', 'sigmoid', 'characteristic', 'provide', 'external', 'gain-control', 'capability.', 'All', 'circuit', 'incorporate', 'modular', 'architecture,', 'design', 'increase', 'number', 'neuron', 'layer', 'multiple', 'chips.', 'Also,', 'subthreshold', 'operation', 'provide', 'low', 'power', 'consumption', 'large', 'scale', 'implementation.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a63.txt\n",
      "\n",
      "['Summary', 'form', 'given,', 'follows.', 'A', 'Hopfield', 'model', 'neural', 'network', 'useful', 'form', 'parallel', 'computer.', 'Such', 'neural', 'network', 'may', 'capable', 'arrive', 'problem', 'solution', 'much', 'speed', 'conventional,', 'sequential', 'approaches.', 'This', 'concept', 'apply', 'problem', 'generate', 'control', 'bit', 'multistage', 'interconnection', 'network.', 'A', 'Hopfield', 'model', 'neural', 'network', 'design', 'capable', 'rout', 'set', 'messages.', 'This', 'neural', 'network', 'solution', 'especially', 'useful', 'interconnection', 'network', 'self-routing', 'interconnection', 'network', 'irregular', 'structure.', 'Furthermore,', 'neural', 'network', 'rout', 'scheme', 'fault-tolerant.', 'Results', 'obtain', 'generate', 'route', '4*4', 'Benes', 'interconnection', 'network.<>']\n",
      "abstract\\a64.txt\n",
      "\n",
      "['A', 'disturbance-rejection', 'neural', 'network', 'control', 'scheme', 'present', 'control', 'unknown', 'nonlinear', 'plant.', 'In', 'scheme,', 'multilayer', 'neural', 'network', 'employ', 'learn', 'inverse', 'dynamic', 'unknown', 'plant', 'act', 'feedforward', 'controller', 'control', 'plant.', 'The', 'effect', 'disturbance', 'output', 'suppress', 'use', 'parallel', 'closed-loop', 'control', 'system.', 'The', 'design', 'technique', 'compensator', 'closed-loop', 'system', 'discussed.', 'Simulation', 'result', 'show', 'present', 'control', 'scheme', 'work', 'well', 'presence', 'disturbances.']\n",
      "abstract\\a65.txt\n",
      "\n",
      "['A', 'method', 'use', 'artificial', 'neural', 'network', 'stabilize', 'large', 'flexible', 'space', 'structure', 'presented.', 'The', 'neural', 'controller', 'learns', 'dynamic', 'structure', 'control', 'construct', 'control', 'signal', 'stabilize', 'structural', 'vibrations.', 'The', 'network', 'consists', 'three', 'layer', 'feedforward', 'network;', 'input', 'layer', 'receives', 'displacement', 'velocity', 'information', 'sensor', 'locate', 'various', 'point', 'structure,', 'output', 'layer', 'generates', 'control', 'signal', 'apply', 'structure', 'suitable', 'actuators.', 'Sequential', 'update', 'network', 'weight', 'continues,', 'force', 'structure', 'follow', 'trajectory', 'eventually', 'lead', 'complete', 'stabilization.', 'Simulation', 'result', 'stabilization', 'flexible', 'beam', 'presented.']\n",
      "abstract\\a66.txt\n",
      "\n",
      "['In', 'paper,', 'propose', 'approximate', 'equivalence', 'neural', 'network', 'model', 'fast', 'learn', 'speed', 'well', 'good', 'function', 'approximation', 'capability,', 'new', 'objective', 'function,', 'satisfies', 'H/sup', '/spl', 'infin//', 'induced', 'norm', 'solve', 'worst-case', 'identification', 'control', 'nonlinear', 'problems.', 'The', 'approximate', 'equivalence', 'neural', 'network', 'capability', 'universal', 'approximator,', 'also', 'faster', 'learn', 'speed', 'conventional', 'feedforward/recurrent', 'neural', 'networks.', 'Based', 'approximate', 'transformable', 'technique,', 'relationship', 'single-layered', 'neural', 'network', 'multilayered', 'perceptrons', 'neural', 'network', 'derived.', 'It', 'show', 'approximate', 'equivalence', 'neural', 'network', 'represent', 'functional', 'link', 'network', 'base', 'Chebyshev', 'polynomials.', 'We', 'also', 'derive', 'new', 'learn', 'algorithm', 'infinity', 'norm', 'transfer', 'function', 'input', 'output', 'prescribed', 'level.', 'It', 'turn', 'approximate', 'equivalence', 'neural', 'network', 'extend', 'worst-case', 'problem,', 'identification', 'control', 'nonlinear', 'problems.']\n",
      "abstract\\a67.txt\n",
      "\n",
      "['It', 'necessary', 'introduce', 'many', 'parameter', 'describe', 'structure', 'input', 'signal', 'pattern', 'recognition', 'system', 'construction', 'open-loop', 'structure', 'multilayer', 'neural', 'network', 'order', 'provide', 'maximum', 'probability', 'correct', 'recognition', 'practice.', 'Availability', 'great', 'number', 'parameters,', 'viz.', 'hundred', 'thousands,', 'rous', 'difficulty', 'learn', 'technical', 'implementation', 'multilayer', 'neural', 'network.', 'Essence', 'introduction', 'continual', 'property', 'multilayer', 'neural', 'network', 'characteristic', 'include', 'following:', 'vector', '{x/sub', 'i/,', 'i=1,', '...,', 'I}', 'replaces', 'function', 'x(i)', 'continued', 'argument,', 'i.e.', 'transition', 'continuum', 'characteristic', 'value.', 'Transition', 'attribute', 'continuum', 'continuum', 'neuron', 'layer', 'consider', 'concrete', 'example', 'neural', 'network', 'structures.']\n",
      "abstract\\a68.txt\n",
      "\n",
      "['Modern', 'electronic', 'warfare', 'system', 'must', 'judge', 'threat', 'degree', 'come', 'radio', 'emitter', 'correctly', 'order', 'counter', 'limited', 'jamming', 'resource', 'effectively.', 'This', 'article', 'put', 'forward', 'new', 'strategy', 'judge', 'radio', 'emitter', 'threat', 'degree', '(RETD)', 'base', 'machine', 'learning.', 'It', 'firstly', 'get', 'membership', 'degree', 'input', 'data.', 'Then', 'input', 'data', 'classified.', 'A', 'train', 'fuzzy', 'neural', 'network', '(FNN)', 'approach', 'ability', 'give', 'threat', 'degree.', 'The', 'RETD', 'judgment', 'rule', 'could', 'mine', 'network.', 'The', 'correctness', 'effectiveness', 'prove', 'experiment.']\n",
      "abstract\\a69.txt\n",
      "\n",
      "['Total', 'knee', 'arthroplasty', '(TKA)', 'one', 'common', 'knee', 'surgeries.', 'Because', 'type', 'TKA', 'implant,', 'hard', 'select', 'appropriate', 'type', 'TKA', 'implant', 'individual', 'patient.', 'For', 'sake', 'pre-operative', 'planning,', 'study', 'present', 'novel', 'approach,', 'predicts', 'post-operative', 'implant', 'knee', 'function', 'individuals.', 'It', 'base', 'clinical', 'big', 'data', 'analysis.', 'The', 'big', 'data', 'compose', 'set', 'pre-operative', 'knee', 'mobility', 'function', 'post-operative', 'knee', 'function.', 'The', 'method', 'construct', 'post-operative', 'knee', 'function', 'prediction', 'model', 'mean', 'machine', 'learn', 'approach.', 'It', 'extract', 'feature', 'use', 'principal', 'component', 'analysis,', 'construct', 'mapping', 'function', 'pre-operative', 'feature', 'space', 'post-operative', 'feature', 'space.', 'The', 'method', 'validate', 'apply', 'prediction', 'post-operative', 'anterior-posterior', 'translation', '52', 'TKA', 'operate', 'knees.', 'Leave-one-out', 'cross', 'validation', 'test', 'reveal', 'prediction', 'performance', 'mean', 'correlation', 'coefficient', '0.79', 'mean', 'root-mean-squared-error', '3.44', 'mm.']\n",
      "abstract\\a7.txt\n",
      "\n",
      "['Based', 'statistical', 'learn', 'theory', '(SLT),', 'support', 'vector', 'machine', '(SVM),', 'new', 'kind', 'machine', 'learn', 'method', 'use', 'classification', 'regression.', 'SVM', 'consider', 'two', 'layer', 'learn', 'machine', 'since', 'map', 'original', 'space', 'high', 'dimensional', 'feature', 'space,', 'i.e.,', 'input', 'layer', 'high', 'dimensional', 'feature', 'space', 'layer.', 'If', 'high', 'dimensional', 'feature', 'space', 'layer', 'consider', 'new', \"problem's\", 'input', 'layer', 'new', 'problem', 'also', 'solve', 'SVM,', 'new', 'problem', 'solve', 'SVMs', 'name', 'multi-layer', 'SVM', '(MLSVM).', 'MLSVM', 'compose', 'input', 'layer', 'least', 'one', 'layer', 'high', 'dimensional', 'feature', 'space', 'layer.', 'In', 'paper,', 'm-th', 'order', 'ordinary', 'differential', 'equation', 'solve', 'MLSVM', 'regression.', 'Experimental', 'result', 'indicate', 'MLSVM', 'effectively', 'solve', 'problem', 'ordinary', 'differential', 'equations.', 'Thus,', 'MLSVM', 'exhibit', 'great', 'potential', 'solve', 'complex', 'problem']\n",
      "abstract\\a70.txt\n",
      "\n",
      "['Executing', 'Big', 'Data', 'workload', 'upon', 'High', 'Performance', 'Computing', '(HPC)', 'infrastractures', 'become', 'attractive', 'way', 'improve', 'performances.', 'However,', 'collocation', 'HPC', 'Big', 'Data', 'workload', 'easy', 'task,', 'mainly', 'core', \"concepts'\", 'differences.', 'This', 'paper', 'focus', 'challenge', 'related', 'schedule', 'Big', 'Data', 'HPC', 'workload', 'compute', 'platform.', 'In', 'classic', 'HPC', 'workloads,', 'rigidity', 'job', 'tends', 'create', 'hole', 'schedule:', 'use', 'idle', 'resource', 'dynamic', 'pool', 'Big', 'Data', 'workloads.', 'We', 'propose', 'new', 'idea', 'base', 'Resource', 'Job', 'Management', \"System's\", '(RJMS)', 'configuration,', 'make', 'HPC', 'Big', 'Data', 'system', 'communicate', 'simple', 'prolog/epilog', 'mechanism.', 'It', 'leverage', 'built-in', 'resilience', 'Big', 'Data', 'frameworks,', 'minimize', 'disturbance', 'HPC', 'workloads.', 'We', 'present', 'first', 'study', 'approach,', 'use', 'production', 'RJMS', 'middleware', 'OAR', 'Hadoop', 'YARN', 'HPC', 'Big', 'Data', 'ecosystem', 'respectively.', 'Our', 'new', 'technique', 'evaluate', 'real', 'experiment', 'upon', 'Grid5000', 'platform.', 'Our', 'experiment', 'validate', 'assumption', 'show', 'promising', 'results.', 'The', 'system', 'capable', 'run', 'HPC', 'workload', '70%', 'cluster', 'utilization,', 'Big', 'Data', 'workload', 'fill', 'schedule', 'hole', 'reach', 'full', '100%', 'utilization.', 'We', 'observe', 'penalty', 'mean', 'wait', 'time', 'HPC', 'job', 'less', '17%', 'Big', 'Data', 'effectiveness', '68%', 'average.']\n",
      "abstract\\a71.txt\n",
      "\n",
      "['Due', 'limited', 'technical', 'social', 'resources,', 'many', 'physician', 'practice', 'fall', 'short', 'accurate', 'blood', 'pressure', 'measurement', 'carry', 'large-scale', 'hypertension', 'research', 'projects.', 'The', 'accuracy', 'standard', 'data', 'acquisition', 'important', 'data', 'source', 'diverse', 'medical', 'big', 'data', 'research.', 'This', 'paper', 'proposes', 'Massive', 'Online', 'Open', 'Course', '(MOOC)', 'appropriate', 'approach', 'teach', 'volunteer', 'necessary', 'knowledge', 'skill', 'blood', 'pressure', 'measurement', 'hypertension', 'research.', 'It', 'introduces', 'new', 'citizen', 'science', '\"paradigm\"', 'support', 'big', 'data', 'research', 'hypertension.', 'MOOC', 'new', 'type', 'online', 'course', 'provide', 'combination', 'short', 'video', 'lectures,', 'frequent', 'comprehension', 'quiz', 'active', 'participation', 'discussion', 'forum.', 'The', 'well-trained', 'data', 'collector', 'MOOC', 'grant', 'collect', 'publish', 'data', 'hypertension', 'research.', 'The', 'process', 'medical', 'big', 'data', 'research', 'base', 'MOOC', 'introduced.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a72.txt\n",
      "\n",
      "['A', 'USAF', 'sponsor', 'MITRE', 'research', 'team', 'undertook', 'four', 'separate,', 'domain-specific', 'case', 'study', 'Big', 'Data', 'applications.', 'Those', 'case', 'study', 'initial', 'investigation', 'question', 'whether', 'data', 'quality', 'issue', 'encounter', 'Big', 'Data', 'collection', 'substantially', 'different', 'cause,', 'manifestation,', 'detection', 'data', 'quality', 'issue', 'encounter', 'traditionally', 'size', 'data', 'collections.', 'The', 'study', 'address', 'several', 'factor', 'affect', 'Big', 'Data', 'Quality', 'multiple', 'levels,', 'include', 'collection,', 'processing,', 'storage.', 'Though', 'unexpected,', 'key', 'finding', 'study', 'reinforce', 'primary', 'factor', 'affect', 'Big', 'Data', 'reside', 'limitation', 'complexity', 'involve', 'handle', 'Big', 'Data', 'maintain', 'integrity.', 'These', 'concern', 'high', 'magnitude', 'provenance', 'data,', 'processing,', 'tool', 'use', 'prepare,', 'manipulate,', 'store', 'data.', 'Data', 'quality', 'extremely', 'important', 'data', 'analytics', 'problems.', 'From', \"study's\", 'findings,', '\"truth', 'Big', 'Data\"', 'fundamentally', 'new', 'DQ', 'issue', 'Big', 'Data', 'analytics', 'projects.', 'Some', 'DQ', 'issue', 'exhibit', 'return-s-to-scale', 'effects,', 'become', 'less', 'pronounce', 'Big', 'Data', 'analytics,', 'though.', 'Big', 'Data', 'Quality', 'varies', 'one', 'type', 'Big', 'Data', 'another', 'one', 'Big', 'Data', 'technology', 'another.']\n",
      "abstract\\a73.txt\n",
      "\n",
      "['With', 'advent', 'Big', 'Data', 'technologies,', 'organization', 'efficiently', 'store', 'analyze', 'data', 'ever', 'before.', 'However,', 'extract', 'maximal', 'value', 'data', 'challenge', 'many', 'reasons.', 'For', 'example,', 'datasets', 'often', 'store', 'use', 'human-understandable', 'terms,', 'make', 'difficult', 'large', 'set', 'user', 'benefit', 'them.', 'Further,', 'give', 'different', 'type', 'data', 'may', 'best', 'store', 'use', 'different', 'technologies,', 'datasets', 'closely', 'related', 'may', 'store', 'separately', 'explicit', 'linkage.', 'Finally,', 'even', 'within', 'individual', 'data', 'stores,', 'often', 'inconsistency', 'data', 'representations,', 'whether', 'introduce', 'time', 'due', 'different', 'data', 'producers.', 'These', 'challenge', 'compound', 'frequent', 'addition', 'data,', 'include', 'new', 'raw', 'data', 'well', 'result', 'produce', 'large-scale', 'analytics.', 'Thus,', 'even', 'within', 'single', 'Big', 'Data', 'environment,', 'often', 'case', 'multiple', 'rich', 'datasets', 'exist', 'without', 'mean', 'access', 'unified', 'cohesive', 'way,', 'often', 'lead', 'lose', 'value.', 'This', 'paper', 'describes', 'development', 'Big', 'Data', 'management', 'infrastructure', 'semantic', 'technology', 'core', 'provide', 'unified', 'data', 'access', 'layer', 'consistent', 'approach', 'analytic', 'execution.', 'Semantic', 'technology', 'use', 'create', 'domain', 'model', 'describe', 'mutually', 'relevant', 'datasets', 'relationship', 'them,', 'graphical', 'user', 'interface', 'transparently', 'query', 'across', 'datasets', 'use', 'domain-model', 'terms.', 'This', 'prototype', 'system', 'built', 'GE', 'Power', \"Water's\", 'Power', 'Generation', 'Products', 'Engineering', 'Division,', 'produce', '50TB', 'gas', 'turbine', 'component', 'prototype', 'test', 'data', 'date.', 'The', 'system', 'expect', 'result', 'significant', 'saving', 'productivity', 'expenditure.']\n",
      "abstract\\a74.txt\n",
      "\n",
      "['The', 'propose', 'paper', 'present', 'novel', 'scheme', 'perform', 'precise', 'extraction', 'knowledge', 'complex', 'massive', 'stream', 'live', 'data', 'scene', 'crowd', 'place.', 'The', 'prime', 'contribution', 'propose', 'system', 'perform', 'enough', 'processing', 'raw', 'unstructured', 'distribute', 'data', 'multiple', 'location', 'processing', 'distribute', 'storage', 'mining', 'do', 'lesser', 'processing', 'time', 'high', 'degree', 'accuracy.', 'An', 'experimental', 'research', 'methodology', 'adopt', 'capture', 'signal', 'use', 'Logitech', 'HD', 'C920', 'process', 'Intel', 'Xeon', 'E5540', 'processor', '2', 'GPbs', 'connectivity.', 'The', 'raw', 'data', 'subject', 'pre-processing,', 'segmentation,', 'scene', 'profiling,', 'order', 'get', 'convolve', 'data', 'store', 'distributive', 'manner', 'use', 'Hadoop', 'mine', 'use', 'MapReduce.', 'The', 'comparative', 'study', 'outcome', 'show', 'lesser', 'processing', 'time', 'high', 'accuracy', 'compare', 'exist', 'relevant', 'analytics.']\n",
      "abstract\\a75.txt\n",
      "\n",
      "['The', 'enormous', 'volume', 'data', 'create', 'maintain', 'industries,', 'research', 'institution', 'verge', 'outgrow', 'infrastructure.', 'The', 'advancement', \"organization's\", 'work', 'flow', 'include', 'data', 'storage,', 'data', 'management,', 'data', 'maintenance,', 'data', 'integration,', 'data', 'interoperability.', 'Among', 'levels,', 'data', 'integration', 'data', 'interoperability', 'two', 'major', 'focus', 'area', 'organization', 'tend', 'implement', 'advancement', 'workflow.', 'Overall,', 'data', 'integration', 'data', 'interoperability', 'influence', \"organization's\", 'performance.', 'The', 'data', 'integration', 'data', 'interoperability', 'complex', 'challenge', 'organization', 'deploy', 'big', 'data', 'architecture', 'due', 'heterogeneous', 'nature', 'data', 'use', 'them.', 'Therefore,', 'require', 'comprehensive', 'approach', 'negotiate', 'challenge', 'integration', 'interoperability.', 'This', 'paper', 'focus', 'challenge', 'data', 'integration', 'data', 'interoperability', 'big', 'data.']\n",
      "abstract\\a76.txt\n",
      "\n",
      "['Data', 'sharing,', 'hot', 'issue', 'scholarly', 'communication,', 'regard', 'generate', 'big', 'data', 'little', 'data', 'little', 'science.', 'In', 'article,', 'conceptual', 'framework', 'research', 'support', 'platform', 'university', 'proposed,', 'survey', 'two', 'case', 'representative', 'subject-based', 'data', 'archive', 'Japan;', 'Data', 'Integration', 'Analysis', 'System', 'Program', '(DIAS)', 'Inter-university', 'Upper', 'atmosphere', 'Global', 'Observation', 'Network', '(IUGONET).']\n",
      "abstract\\a77.txt\n",
      "\n",
      "['Advancement', 'field', 'compute', 'remote', 'handheld', 'device', 'make', 'process', 'collect', 'geospatial', 'data', 'easy.', 'Most', 'time', 'researcher', 'scientist', 'easy', 'access', 'data', 'well.', 'However,', 'process', 'extract', 'processing', 'large', 'volume', 'data', 'several', 'source', 'time', 'consume', 'difficult.', 'In', 'case', 'scientist', 'rely', 'expensive', 'proprietary', 'software', '[1].', 'This', 'paper', 'discus', 'Computational', 'Scientists', 'Oak', 'Ridge', 'National', 'Laboratory', 'extracting,', 'normalizing,', 'processing', 'million', 'geospatial', 'data', 'point', 'multiple', 'data', 'source', 'integrate', 'common', 'data', 'format', 'help', 'user', 'find', 'access', 'data', 'use', 'flexible', 'visualization-based', 'user', 'interface.']\n",
      "abstract\\a78.txt\n",
      "\n",
      "['According', 'problem', 'efficient', 'datasets', 'cannot', 'quickly', 'obtain', 'social', 'medium', 'big', 'data', 'social', 'network', 'process', 'focus', 'mining', 'analysis.', 'An', 'effective', 'selection', 'method', 'cluster', 'mining', 'spacetime', 'large', 'data', 'proposed.', 'The', 'effective', 'selection', 'method', 'cluster', 'mining', 'divide', 'spatiotemporal', 'large', 'data', 'dimension', 'space,', 'time', 'attribute.', 'Then', 'exploratory', 'spatial', 'data', 'analysis(ESDA)', 'obtain', 'subset', 'get', 'datasets', 'potential', 'cluster', 'mining', 'quickly.', 'propose', 'method', 'verify', 'use', 'Weibo', 'check-in', 'data', 'Wuhan', '2011', '2015', 'mine', 'commercial', 'hotspots.', 'The', 'experimental', 'result', 'show', 'method', 'quickly', 'effectively', 'excavate', 'datasets', 'Weibo', 'check-in', 'data', 'reflect', 'distribution', 'Wuhan', 'business', 'circle,', 'excavate', 'datasets', 'characteristic', 'high', 'clustering,', 'small', 'volume,', 'high', 'precision.', 'The', 'effective', 'selection', 'method', 'cluster', 'mining', 'spatiotemporal', 'data', 'provide', 'fast', 'effective', 'method', 'idea', 'process', 'crowd', 'source', 'geographic', 'data', 'today.']\n",
      "abstract\\a79.txt\n",
      "\n",
      "['With', 'advent', 'big', 'data,', 'data', 'generated,', 'collected,', 'transformed,', 'process', 'analyze', 'unprecedented', 'scale.', 'Since', 'data', 'create', 'fast', 'velocity', 'large', 'variety,', 'quality', 'big', 'data', 'far', 'perfect.', 'Recent', 'study', 'show', 'poor', 'quality', 'bring', 'serious', 'erroneous', 'data', 'cost', 'result', 'big', 'data', 'analysis.', 'Data', 'validation', 'important', 'process', 'recognize', 'improve', 'data', 'quality.', 'In', 'paper,', 'case', 'study', 'relevant', 'big', 'data', 'quality', 'design', 'study', 'original', 'big', 'data', 'quality,', 'data', 'quality', 'dimension,', 'data', 'validation', 'process', 'tools.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a8.txt\n",
      "\n",
      "['A', 'new', 'method', 'early', 'fault', 'diagnosis', 'manufacturing', 'system', 'base', 'machine', 'learn', 'presented.', 'It', 'necessary', 'manufacturing', 'enterprise', 'detect', 'state', 'production', 'process', 'real', 'time,', 'order', 'find', 'early', 'fault', 'machines,', 'loss', 'production', 'failure', 'investment', 'facility', 'maintenance', 'minimized.', 'This', 'paper', 'proposes', 'new', 'fault', 'diagnosis', 'model,', 'extract', 'multi-dimension', 'feature', 'detect', 'signal', 'supervise', 'different', 'feature', 'signal', 'simultaneously.', 'Based', 'model,', 'method', 'inductive', 'learn', 'adopt', 'obtain', 'statistical', 'boundary', 'vector', 'signal', 'automatically,', 'normal', 'feature', 'space', 'built,', 'accord', 'abnormal', 'signal', 'detected,', 'consequently', 'fault', 'complicate', 'system', 'found', 'easily.', 'Furthermore,', 'condition', 'without', 'exist', 'fault', 'samples,', 'precise', 'result', 'fault', 'diagnosis', 'also', 'achieve', 'real', 'time.', 'The', 'theoretical', 'analysis', 'simulation', 'example', 'demonstrate', 'effectiveness', 'method.']\n",
      "abstract\\a80.txt\n",
      "\n",
      "['The', 'Atmospheric', 'Radiation', 'Measurement', '(ARM)', 'Climate', 'Research', 'Facility', '(www.arm.gov)', 'provide', 'atmospheric', 'observation', 'diverse', 'climatic', 'regime', 'around', 'world.', 'Currently,', 'ARM', 'archive', '22', 'million', 'user', 'assessable', 'data', 'files,', 'primarily', 'store', 'NetCDF', 'file', 'format,', 'total', 'data', 'volume', 'close', 'one', 'Petabyte.', 'In', 'paper,', 'discus', 'ARM', 'currently', 'storing,', 'distributing,', 'catalog', 'visualize', 'large', 'volume', 'multi-dimensional', 'climate', 'observation', 'model', 'data', 'also', 'describe', 'future', 'plan.']\n",
      "abstract\\a81.txt\n",
      "\n",
      "['The', 'advent', 'social', 'network', 'Internet-of-Things', 'result', 'unprecedented', 'capability', 'collecting,', 'share', 'analyze', 'massive', 'amount', 'data.', 'From', 'security', 'perspective,', 'Big', 'Data', 'may', 'seriously', 'weaken', 'confidentiality,', 'technique', 'improve', 'Big', 'Data', 'analytics', 'performance-including', 'early', 'fusion', 'heterogeneous', 'data', 'source', 'increase', 'hidden', 'redundancy', 'data', 'representation,', 'generate', 'ill-protected', 'copies.', 'This', 'gray', 'area', 'redundancy', 'trigger', 'new', 'disclosure', 'threat', 'challenge', 'traditional', 'technique', 'protect', 'privacy', 'confidentiality.', 'This', 'position', 'paper', 'start', 'propose', 'definition', 'Big', 'Data', 'Leak', 'threat', '(as', 'oppose', 'one', 'data', 'breach)', 'role', 'component', 'disclosure', 'risk.', 'Then,', 'discus', 'paradigm', 'Known,', 'Detect,', 'Contain', 'Recover', 'could', 'use', 'establish', 'Big', 'Data', 'security', 'practice', 'contain', 'disclosure', 'risk', 'connect', 'Big', 'Data', 'analytics.']\n",
      "abstract\\a82.txt\n",
      "\n",
      "['This', 'paper', 'test', 'whether', 'accurate', 'sale', 'forecast', 'Nike', 'possible', 'Facebook', 'data', 'event', 'related', 'Nike', 'affect', 'activity', \"Nike's\", 'Facebook', 'pages.', 'The', 'paper', 'draw', 'AIDA', 'sale', 'framework', '(Awareness,', 'Interest,', 'Desire,', 'Action)', 'domain', 'marketing', 'employ', 'method', 'social', 'set', 'analysis', 'domain', 'computational', 'social', 'science', 'model', 'sale', 'Big', 'Social', 'Data.', 'The', 'dataset', 'consists', '(a)', 'selection', \"Nike's\", 'Facebook', 'page', 'number', 'likes,', 'comments,', 'post', 'etc.', 'register', 'page', 'per', 'day', '(b)', 'business', 'data', 'term', 'quarterly', 'global', 'sale', 'figure', 'publish', \"Nike's\", 'financial', 'reports.', 'An', 'event', 'study', 'also', 'conduct', 'use', 'Social', 'Set', 'Visualizer', '(SoSeVi).', 'The', 'finding', 'suggest', 'Facebook', 'data', 'informational', 'value.', 'Some', 'simple', 'regression', 'model', 'high', 'forecasting', 'accuracy.', 'The', 'multiple', 'regression', 'low', 'forecasting', 'accuracy', 'cause', 'analysis', 'barrier', 'due', 'data', 'set', 'characteristic', 'perfect', 'multicollinearity.', 'The', 'event', 'study', 'found', 'abnormal', 'activity', 'around', 'several', 'Nike', 'specific', 'event', 'inference', 'activity', 'spikes,', 'whether', 'purely', 'event-related', 'coincidences,', 'determine', 'detailed', 'case-by-case', 'text', 'analysis.', 'Our', 'finding', 'help', 'ass', 'informational', 'value', 'Big', 'Social', 'Data', \"company's\", 'marketing', 'strategy,', 'sale', 'operation', 'supply', 'chain.']\n",
      "abstract\\a83.txt\n",
      "\n",
      "['Many', 'exist', 'data', 'mining', 'algorithm', 'search', 'interest', 'pattern', 'transactional', 'database', 'precise', 'data.', 'However,', 'situation', 'data', 'uncertain.', 'Items', 'transaction', 'probabilistic', 'database', 'uncertain', 'data', 'usually', 'associate', 'existential', 'probabilities,', 'express', 'likelihood', 'item', 'present', 'transaction.', 'When', 'compare', 'mining', 'precise', 'data,', 'search', 'space', 'mining', 'uncertain', 'data', 'much', 'large', 'due', 'presence', 'existential', 'probabilities.', 'This', 'problem', 'worsen', 'move', 'era', 'Big', 'data.', 'Furthermore,', 'many', 'real-life', 'applications,', 'user', 'may', 'interested', 'tiny', 'portion', 'large', 'search', 'space', 'Big', 'data', 'mining.', 'Without', 'provide', 'opportunity', 'user', 'express', 'interest', 'pattern', 'mined,', 'many', 'exist', 'data', 'mining', 'algorithm', 'return', 'numerous', 'pattern', '--', 'interesting.', 'In', 'paper,', 'propose', 'algorithm', '(i)', 'allows', 'user', 'express', 'interest', 'term', 'constraint', '(ii)', 'us', 'MapReduce', 'model', 'mine', 'uncertain', 'Big', 'data', 'frequent', 'pattern', 'satisfy', 'user-specified', 'constraints.', 'By', 'exploit', 'property', 'constraints,', 'algorithm', 'greatly', 'reduces', 'search', 'space', 'Big', 'data', 'mining', 'uncertain', 'data,', 'return', 'pattern', 'interest', 'user', 'Big', 'data', 'analytics.']\n",
      "abstract\\a84.txt\n",
      "\n",
      "['The', 'primary', 'objective', 'paper', 'present', 'detailed', 'analysis', 'various', 'platform', 'suitable', 'Big', 'Data', 'processing.', 'In', 'paper,', 'various', 'software', 'framework', 'available', 'Big', 'Data', 'analytics', 'survey', 'in-detail', 'assessment', 'strength', 'weakness', 'discussed.', 'In', 'addition', 'this,', 'widely', 'use', 'data', 'mining', 'algorithm', 'discuss', 'adaptation', 'Big', 'Data', 'analysis', 'w.r.t', 'suitability', 'handle', 'real-world', 'application', 'problems.', 'Future', 'trend', 'Big', 'Data', 'processing', 'analytics', 'predict', 'effective', 'implementation', 'well', 'establish', 'widely', 'use', 'data', 'mining', 'algorithm', 'consider', 'strength', 'software', 'framework', 'platform', 'available.', 'Hybrid', 'approach', '(integration', 'two', 'platforms)', 'may', 'appropriate', 'specific', 'data', 'mining', 'algorithm', 'highly', 'adaptable', 'well', 'perform', 'real-time', 'processing.']\n",
      "abstract\\a85.txt\n",
      "\n",
      "['In', 'area', 'big', 'data,', 'people', 'new', 'perspective', 'counter-terrorism', 'research.', 'In', 'paper,', 'carry', 'systematic', 'research', 'application', 'big', 'data', 'counter-terrorism', 'field', 'use', 'quantitative', 'analysis', 'method.', 'And', 'demonstrate', 'effect', 'big', 'data', 'counter-terrorism', 'research', 'data', 'collection', 'preprocessing,', 'data', 'mining', 'analysis,', 'monitoring', 'warn', 'three', 'aspects.', 'After', 'that,', 'use', 'data', 'The', 'Times', 'The', 'New', 'York', 'Times', 'WUC', '2012', 'analysis', 'argument.', 'Finally,', 'concludes', 'deficiency', 'research', 'territory', 'counter-terrorism', 'use', 'big', 'data', 'problem', 'worth', 'study', 'future.']\n",
      "abstract\\a86.txt\n",
      "\n",
      "['Large', 'amount', 'data', 'generate', 'every', 'day', 'create', 'new', 'challenge', 'opportunity', 'lead', 'extraordinary', 'new', 'knowledge', 'discovery', 'many', 'application', 'domain', 'range', 'science', 'engineering', 'business.', 'One', 'main', 'challenge', 'era', 'Big', 'Data', 'efficiently', 'manage', 'analyse', 'scale', 'data.', 'This', 'challenge', 'due', 'size', 'data,', 'also', 'due', 'heterogeneous', 'nature', 'geographic', 'location.', 'In', 'sense,', 'cloud', 'become', 'increasingly', 'popular', 'infrastructure', 'enable', 'large-scale', 'data', 'intensive', 'scientific', 'business', 'applications.', 'Cloud', 'provide', 'suitable', 'environment', 'processing', 'Big', 'Data', 'application', 'process', 'large', 'volume', 'data', 'parallel', 'processing', 'data.', 'Due', 'geographical', 'distribution', 'data', 'different', 'variety', 'data', 'advantage', 'use', 'federate', 'Inter-Cloud', 'environment', 'move', 'large', 'volume', 'data', 'avoided.', 'Workflows', 'use', 'allocate', 'schedule', 'execution', 'Big', 'Data', 'application', 'optimize', 'manner.', 'In', 'paper', 'present', 'need', 'execution', 'Big', 'Data', 'Application', 'workflow', 'Cloud', 'Inter-Cloud', 'environments.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a87.txt\n",
      "\n",
      "['Artificial', 'intelligence,', 'particularly', 'machine', 'learning,', 'use', 'many', 'way', 'research', 'community', 'turn', 'variety', 'diverse', 'even', 'heterogeneous', 'data', 'source', 'high', 'quality', 'fact', 'knowledge,', 'provide', 'premier', 'capability', 'accurate', 'pattern', 'discovery.', 'However,', 'apply', 'machine', 'learn', 'strategy', 'big', 'complex', 'datasets', 'computationally', 'expensive,', 'consumes', 'large', 'amount', 'logical', 'physical', 'resources,', 'data', 'file', 'space,', 'CPU,', 'memory.', 'A', 'sophisticated', 'platform', 'efficient', 'big', 'data', 'analytics', 'become', 'important', 'day', 'data', 'amount', 'generate', 'daily', 'basis', 'exceeds', 'quintillion', 'bytes.', 'Apache', 'Spark', 'MLlib', 'one', 'prominent', 'platform', 'big', 'data', 'analysis', 'offer', 'set', 'excellent', 'functionality', 'different', 'machine', 'learn', 'task', 'range', 'regression,', 'classification,', 'dimension', 'reduction', 'cluster', 'rule', 'extraction.', 'In', 'contribution,', 'explore,', 'computational', 'perspective,', 'expand', 'body', 'Apache', 'Spark', 'MLlib', '2.0', 'open-source,', 'distributed,', 'scalable,', 'platform', 'independent', 'machine', 'learn', 'library.', 'Specifically,', 'perform', 'several', 'real', 'world', 'machine', 'learn', 'experiment', 'examine', 'qualitative', 'quantitative', 'attribute', 'platform.', 'Furthermore,', 'highlight', 'current', 'trend', 'big', 'data', 'machine', 'learn', 'research', 'provide', 'insight', 'future', 'work.']\n",
      "abstract\\a88.txt\n",
      "\n",
      "['Big', 'Data', 'contains', 'massive', 'information,', 'generate', 'heterogeneous,', 'autonomous', 'source', 'distribute', 'anonymous', 'platforms.', 'Since,', 'raise', 'extreme', 'challenge', 'organization', 'store', 'process', 'data.', 'Conventional', 'pathway', 'store', 'process', 'happen', 'collection', 'manual', 'step', 'consume', 'various', 'resources.', 'An', 'automate', 'real-time', 'online', 'analytical', 'process', 'cognitive', 'solution.', 'Therefore', 'need', 'state', 'art', 'approach', 'overcome', 'barrier', 'concern', 'currently', 'face', 'Big', 'Data', 'industry.', 'In', 'paper', 'propose', 'novel', 'architecture', 'automate', 'data', 'analytics', 'process', 'use', 'Nested', 'Automatic', 'Service', 'Composition', '(NASC)', 'CRoss', 'Industry', 'Standard', 'Platform', 'Data', 'Mining', '(CRISP-DM)', 'main', 'base', 'technology', 'solution.', 'NASC', 'well', 'define', 'scalable', 'technology', 'automate', 'multi-disciplined', 'problem', 'domains.', 'Since', 'CRISP-DM', 'also', 'well-known', 'data', 'science', 'process', 'use', 'innovative', 'accumulator', 'multi-dimensional', 'data', 'sets.', 'CRISP-DM', 'mapped', 'Big', 'Data', 'analytical', 'process', 'NASC', 'automate', 'CRISP-DM', 'process', 'intelligent', 'innovative', 'way.']\n",
      "abstract\\a9.txt\n",
      "\n",
      "['The', 'support', 'vector', 'machine', 'new', 'statistical', 'learn', 'algorithm', 'developed', 'recent', 'years.', 'They', 'advantage', 'many', 'region', 'like', 'pattern', 'recognition.', 'The', 'kernel', 'function', 'important', 'classification', 'ability.', 'This', 'paper', 'present', 'crossbreed', 'genetic', 'algorithm', 'base', 'method', 'choose', 'kernel', 'function', 'parameters.', 'The', 'crossbreed', 'genetic', 'algorithm', 'us', 'two', 'fitness', 'function', 'produce', 'accord', 'two', 'criterion', \"SVM's\", 'performance.', 'The', 'experiment', 'prove', 'algorithm', 'find', 'effectively', 'optimal', 'kernel', 'function', 'parameters,', 'helpful', 'increase', 'support', 'vector', \"machines'\", 'performance', 'fact.']\n"
     ]
    }
   ],
   "source": [
    "words_dir = 'abstract'\n",
    "tags_directory = 'tags'\n",
    "Words, all_words, all_words_heading = read_words(words_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "4147\n"
     ]
    }
   ],
   "source": [
    "cou, Tags = read_tags(tags_directory)\n",
    "#df = pd.DataFrame(Tags)\n",
    "Words = np.array(Words)\n",
    "# exploring frequency of all words not in heading\n",
    "import nltk\n",
    "freq = nltk.FreqDist(all_words + all_words_heading)\n",
    "common = freq.most_common(3000)\n",
    "common = list(common)\n",
    "\n",
    "features = []\n",
    "features += [w[0] for w in common]\n",
    "features += [w for w in all_words_heading if w not in common]\n",
    "print(len(common))\n",
    "print(len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hilbert spaces</th>\n",
       "      <th>Fuzzy control</th>\n",
       "      <th>ï»¿Handheld computers</th>\n",
       "      <th>Benes interconnection network</th>\n",
       "      <th>Predictive models</th>\n",
       "      <th>output units</th>\n",
       "      <th>Artificial Neural Networ (ANN)</th>\n",
       "      <th>flexible structures</th>\n",
       "      <th>data analytics problems</th>\n",
       "      <th>accident risk determination</th>\n",
       "      <th>...</th>\n",
       "      <th>Application software</th>\n",
       "      <th>Optical computing</th>\n",
       "      <th>Accelerometers</th>\n",
       "      <th>maximal margin classification</th>\n",
       "      <th>data sharing</th>\n",
       "      <th>discriminative loss function optimization</th>\n",
       "      <th>Business</th>\n",
       "      <th>video frames</th>\n",
       "      <th>Semantics</th>\n",
       "      <th>deep neural network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 1774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hilbert spaces  Fuzzy control  ï»¿Handheld computers  \\\n",
       "0                 0              0                      0   \n",
       "1                 0              0                      0   \n",
       "2                 0              0                      0   \n",
       "3                 0              0                      0   \n",
       "4                 0              0                      0   \n",
       "5                 0              0                      0   \n",
       "6                 0              0                      0   \n",
       "7                 0              0                      0   \n",
       "8                 0              0                      0   \n",
       "9                 0              0                      0   \n",
       "10                0              0                      0   \n",
       "11                0              0                      0   \n",
       "12                0              0                      0   \n",
       "13                0              0                      0   \n",
       "14                0              0                      0   \n",
       "15                0              0                      0   \n",
       "16                0              0                      0   \n",
       "17                0              0                      0   \n",
       "18                0              0                      0   \n",
       "19                0              0                      0   \n",
       "20                0              0                      0   \n",
       "21                0              0                      0   \n",
       "22                0              0                      0   \n",
       "23                0              0                      0   \n",
       "24                0              0                      0   \n",
       "25                0              0                      0   \n",
       "26                0              0                      0   \n",
       "27                0              0                      0   \n",
       "28                0              0                      0   \n",
       "29                0              0                      0   \n",
       "..              ...            ...                    ...   \n",
       "106               0              0                      0   \n",
       "107               0              0                      0   \n",
       "108               0              0                      0   \n",
       "109               0              0                      0   \n",
       "110               0              0                      0   \n",
       "111               0              0                      0   \n",
       "112               0              0                      0   \n",
       "113               0              0                      0   \n",
       "114               0              0                      0   \n",
       "115               0              0                      0   \n",
       "116               0              0                      0   \n",
       "117               0              0                      0   \n",
       "118               0              0                      0   \n",
       "119               0              0                      0   \n",
       "120               0              0                      0   \n",
       "121               0              0                      0   \n",
       "122               0              0                      0   \n",
       "123               0              0                      0   \n",
       "124               0              0                      0   \n",
       "125               0              0                      0   \n",
       "126               0              0                      0   \n",
       "127               0              0                      0   \n",
       "128               0              0                      0   \n",
       "129               0              0                      0   \n",
       "130               0              0                      0   \n",
       "131               0              0                      0   \n",
       "132               0              0                      0   \n",
       "133               0              0                      0   \n",
       "134               0              0                      0   \n",
       "135               0              0                      0   \n",
       "\n",
       "     Benes interconnection network\\n   Predictive models   output units  \\\n",
       "0                                  0                    1             0   \n",
       "1                                  0                    0             0   \n",
       "2                                  0                    1             0   \n",
       "3                                  0                    0             0   \n",
       "4                                  0                    0             0   \n",
       "5                                  0                    0             0   \n",
       "6                                  0                    0             0   \n",
       "7                                  0                    0             0   \n",
       "8                                  0                    0             0   \n",
       "9                                  0                    0             0   \n",
       "10                                 0                    0             0   \n",
       "11                                 0                    0             0   \n",
       "12                                 0                    0             0   \n",
       "13                                 0                    0             0   \n",
       "14                                 0                    0             0   \n",
       "15                                 0                    0             0   \n",
       "16                                 0                    0             0   \n",
       "17                                 0                    0             0   \n",
       "18                                 0                    0             0   \n",
       "19                                 0                    0             0   \n",
       "20                                 0                    0             0   \n",
       "21                                 0                    0             0   \n",
       "22                                 0                    0             0   \n",
       "23                                 0                    0             0   \n",
       "24                                 0                    0             0   \n",
       "25                                 0                    0             0   \n",
       "26                                 0                    0             0   \n",
       "27                                 0                    0             0   \n",
       "28                                 0                    0             0   \n",
       "29                                 0                    0             0   \n",
       "..                               ...                  ...           ...   \n",
       "106                                0                    0             0   \n",
       "107                                1                    0             0   \n",
       "108                                0                    0             0   \n",
       "109                                0                    0             0   \n",
       "110                                0                    0             0   \n",
       "111                                0                    0             0   \n",
       "112                                0                    0             0   \n",
       "113                                0                    0             0   \n",
       "114                                0                    0             0   \n",
       "115                                0                    0             0   \n",
       "116                                0                    0             0   \n",
       "117                                0                    0             0   \n",
       "118                                0                    0             0   \n",
       "119                                0                    0             0   \n",
       "120                                0                    0             0   \n",
       "121                                0                    0             0   \n",
       "122                                0                    0             0   \n",
       "123                                0                    0             0   \n",
       "124                                0                    0             0   \n",
       "125                                0                    0             0   \n",
       "126                                0                    0             0   \n",
       "127                                0                    0             0   \n",
       "128                                0                    0             0   \n",
       "129                                0                    0             0   \n",
       "130                                0                    0             0   \n",
       "131                                0                    0             0   \n",
       "132                                0                    0             0   \n",
       "133                                0                    0             0   \n",
       "134                                0                    0             0   \n",
       "135                                0                    0             0   \n",
       "\n",
       "     Artificial Neural Networ (ANN)  flexible structures  \\\n",
       "0                                 0                    0   \n",
       "1                                 0                    0   \n",
       "2                                 0                    0   \n",
       "3                                 0                    0   \n",
       "4                                 0                    0   \n",
       "5                                 0                    0   \n",
       "6                                 0                    0   \n",
       "7                                 0                    0   \n",
       "8                                 0                    0   \n",
       "9                                 0                    0   \n",
       "10                                0                    0   \n",
       "11                                0                    0   \n",
       "12                                0                    0   \n",
       "13                                0                    0   \n",
       "14                                0                    0   \n",
       "15                                0                    0   \n",
       "16                                0                    0   \n",
       "17                                0                    0   \n",
       "18                                0                    0   \n",
       "19                                0                    0   \n",
       "20                                0                    0   \n",
       "21                                0                    0   \n",
       "22                                0                    0   \n",
       "23                                0                    0   \n",
       "24                                0                    0   \n",
       "25                                0                    0   \n",
       "26                                0                    0   \n",
       "27                                0                    0   \n",
       "28                                0                    0   \n",
       "29                                0                    0   \n",
       "..                              ...                  ...   \n",
       "106                               0                    0   \n",
       "107                               0                    0   \n",
       "108                               0                    0   \n",
       "109                               0                    1   \n",
       "110                               0                    0   \n",
       "111                               0                    0   \n",
       "112                               0                    0   \n",
       "113                               0                    0   \n",
       "114                               0                    0   \n",
       "115                               0                    0   \n",
       "116                               0                    0   \n",
       "117                               0                    0   \n",
       "118                               0                    0   \n",
       "119                               0                    0   \n",
       "120                               0                    0   \n",
       "121                               0                    0   \n",
       "122                               0                    0   \n",
       "123                               0                    0   \n",
       "124                               0                    0   \n",
       "125                               0                    0   \n",
       "126                               0                    0   \n",
       "127                               0                    0   \n",
       "128                               0                    0   \n",
       "129                               0                    0   \n",
       "130                               0                    0   \n",
       "131                               0                    0   \n",
       "132                               0                    0   \n",
       "133                               0                    0   \n",
       "134                               0                    0   \n",
       "135                               0                    0   \n",
       "\n",
       "     data analytics problems  accident risk determination  \\\n",
       "0                          0                            0   \n",
       "1                          0                            0   \n",
       "2                          0                            0   \n",
       "3                          0                            0   \n",
       "4                          0                            0   \n",
       "5                          0                            0   \n",
       "6                          0                            0   \n",
       "7                          0                            0   \n",
       "8                          0                            0   \n",
       "9                          0                            0   \n",
       "10                         0                            0   \n",
       "11                         0                            0   \n",
       "12                         0                            0   \n",
       "13                         0                            0   \n",
       "14                         0                            0   \n",
       "15                         0                            0   \n",
       "16                         0                            0   \n",
       "17                         0                            0   \n",
       "18                         0                            0   \n",
       "19                         0                            0   \n",
       "20                         0                            0   \n",
       "21                         0                            0   \n",
       "22                         0                            0   \n",
       "23                         0                            0   \n",
       "24                         0                            0   \n",
       "25                         0                            0   \n",
       "26                         0                            0   \n",
       "27                         0                            0   \n",
       "28                         0                            0   \n",
       "29                         0                            0   \n",
       "..                       ...                          ...   \n",
       "106                        0                            0   \n",
       "107                        0                            0   \n",
       "108                        0                            0   \n",
       "109                        0                            0   \n",
       "110                        0                            0   \n",
       "111                        0                            0   \n",
       "112                        0                            0   \n",
       "113                        0                            0   \n",
       "114                        0                            0   \n",
       "115                        0                            0   \n",
       "116                        0                            0   \n",
       "117                        1                            0   \n",
       "118                        0                            0   \n",
       "119                        0                            0   \n",
       "120                        0                            0   \n",
       "121                        0                            0   \n",
       "122                        0                            0   \n",
       "123                        0                            0   \n",
       "124                        0                            0   \n",
       "125                        0                            0   \n",
       "126                        0                            0   \n",
       "127                        0                            0   \n",
       "128                        0                            0   \n",
       "129                        0                            0   \n",
       "130                        0                            0   \n",
       "131                        0                            0   \n",
       "132                        0                            0   \n",
       "133                        0                            0   \n",
       "134                        0                            0   \n",
       "135                        0                            0   \n",
       "\n",
       "            ...           Application software  Optical computing  \\\n",
       "0           ...                              0                  0   \n",
       "1           ...                              0                  0   \n",
       "2           ...                              0                  0   \n",
       "3           ...                              0                  0   \n",
       "4           ...                              0                  0   \n",
       "5           ...                              0                  0   \n",
       "6           ...                              0                  0   \n",
       "7           ...                              0                  0   \n",
       "8           ...                              0                  0   \n",
       "9           ...                              0                  0   \n",
       "10          ...                              0                  0   \n",
       "11          ...                              0                  0   \n",
       "12          ...                              0                  0   \n",
       "13          ...                              0                  0   \n",
       "14          ...                              0                  0   \n",
       "15          ...                              0                  0   \n",
       "16          ...                              0                  0   \n",
       "17          ...                              0                  0   \n",
       "18          ...                              0                  0   \n",
       "19          ...                              0                  0   \n",
       "20          ...                              0                  0   \n",
       "21          ...                              0                  0   \n",
       "22          ...                              0                  0   \n",
       "23          ...                              0                  0   \n",
       "24          ...                              0                  0   \n",
       "25          ...                              0                  0   \n",
       "26          ...                              0                  0   \n",
       "27          ...                              0                  0   \n",
       "28          ...                              0                  0   \n",
       "29          ...                              0                  0   \n",
       "..          ...                            ...                ...   \n",
       "106         ...                              0                  0   \n",
       "107         ...                              0                  0   \n",
       "108         ...                              0                  0   \n",
       "109         ...                              0                  0   \n",
       "110         ...                              0                  0   \n",
       "111         ...                              0                  0   \n",
       "112         ...                              0                  0   \n",
       "113         ...                              0                  0   \n",
       "114         ...                              0                  0   \n",
       "115         ...                              0                  0   \n",
       "116         ...                              0                  0   \n",
       "117         ...                              0                  0   \n",
       "118         ...                              0                  0   \n",
       "119         ...                              0                  0   \n",
       "120         ...                              0                  0   \n",
       "121         ...                              0                  0   \n",
       "122         ...                              0                  0   \n",
       "123         ...                              0                  0   \n",
       "124         ...                              0                  0   \n",
       "125         ...                              0                  0   \n",
       "126         ...                              0                  0   \n",
       "127         ...                              0                  0   \n",
       "128         ...                              0                  0   \n",
       "129         ...                              0                  0   \n",
       "130         ...                              0                  0   \n",
       "131         ...                              0                  0   \n",
       "132         ...                              0                  0   \n",
       "133         ...                              0                  0   \n",
       "134         ...                              0                  0   \n",
       "135         ...                              0                  0   \n",
       "\n",
       "     Accelerometers  maximal margin classification  data sharing  \\\n",
       "0                 0                              0             0   \n",
       "1                 0                              0             0   \n",
       "2                 0                              0             0   \n",
       "3                 0                              0             0   \n",
       "4                 0                              0             0   \n",
       "5                 0                              0             0   \n",
       "6                 0                              0             0   \n",
       "7                 0                              0             0   \n",
       "8                 0                              0             0   \n",
       "9                 0                              0             0   \n",
       "10                0                              0             0   \n",
       "11                0                              0             0   \n",
       "12                0                              0             0   \n",
       "13                0                              0             0   \n",
       "14                0                              0             0   \n",
       "15                0                              0             0   \n",
       "16                0                              0             0   \n",
       "17                0                              0             0   \n",
       "18                0                              0             0   \n",
       "19                0                              0             0   \n",
       "20                0                              0             0   \n",
       "21                0                              0             0   \n",
       "22                0                              0             0   \n",
       "23                0                              0             0   \n",
       "24                0                              0             0   \n",
       "25                0                              0             0   \n",
       "26                0                              0             0   \n",
       "27                0                              0             0   \n",
       "28                0                              0             0   \n",
       "29                0                              0             0   \n",
       "..              ...                            ...           ...   \n",
       "106               0                              0             0   \n",
       "107               0                              0             0   \n",
       "108               0                              0             0   \n",
       "109               0                              0             0   \n",
       "110               0                              0             0   \n",
       "111               0                              0             0   \n",
       "112               0                              0             0   \n",
       "113               0                              0             0   \n",
       "114               0                              0             0   \n",
       "115               0                              0             0   \n",
       "116               0                              0             0   \n",
       "117               0                              0             0   \n",
       "118               0                              0             0   \n",
       "119               0                              0             0   \n",
       "120               0                              0             0   \n",
       "121               0                              0             1   \n",
       "122               0                              0             0   \n",
       "123               0                              0             0   \n",
       "124               0                              0             0   \n",
       "125               0                              0             0   \n",
       "126               0                              0             0   \n",
       "127               0                              0             0   \n",
       "128               0                              0             0   \n",
       "129               0                              0             0   \n",
       "130               0                              0             0   \n",
       "131               0                              0             0   \n",
       "132               0                              0             0   \n",
       "133               0                              0             0   \n",
       "134               0                              0             0   \n",
       "135               0                              0             0   \n",
       "\n",
       "     discriminative loss function optimization   Business  video frames  \\\n",
       "0                                            0          0             0   \n",
       "1                                            0          0             0   \n",
       "2                                            0          0             0   \n",
       "3                                            0          0             0   \n",
       "4                                            0          0             0   \n",
       "5                                            0          0             0   \n",
       "6                                            0          0             0   \n",
       "7                                            0          0             0   \n",
       "8                                            0          0             0   \n",
       "9                                            0          0             0   \n",
       "10                                           0          0             0   \n",
       "11                                           0          0             0   \n",
       "12                                           0          0             0   \n",
       "13                                           0          0             0   \n",
       "14                                           0          0             0   \n",
       "15                                           0          0             0   \n",
       "16                                           0          0             0   \n",
       "17                                           0          0             0   \n",
       "18                                           0          0             0   \n",
       "19                                           0          0             0   \n",
       "20                                           0          0             0   \n",
       "21                                           0          0             0   \n",
       "22                                           0          0             0   \n",
       "23                                           0          0             0   \n",
       "24                                           0          0             0   \n",
       "25                                           0          0             0   \n",
       "26                                           0          0             0   \n",
       "27                                           0          0             0   \n",
       "28                                           0          0             0   \n",
       "29                                           0          0             0   \n",
       "..                                         ...        ...           ...   \n",
       "106                                          0          0             0   \n",
       "107                                          0          0             0   \n",
       "108                                          0          0             0   \n",
       "109                                          0          0             0   \n",
       "110                                          0          0             0   \n",
       "111                                          0          0             0   \n",
       "112                                          0          0             0   \n",
       "113                                          0          0             0   \n",
       "114                                          0          0             0   \n",
       "115                                          0          0             0   \n",
       "116                                          0          0             0   \n",
       "117                                          0          0             0   \n",
       "118                                          0          0             0   \n",
       "119                                          0          0             0   \n",
       "120                                          0          0             0   \n",
       "121                                          0          0             0   \n",
       "122                                          0          0             0   \n",
       "123                                          0          0             0   \n",
       "124                                          0          0             0   \n",
       "125                                          0          0             0   \n",
       "126                                          0          0             0   \n",
       "127                                          0          0             0   \n",
       "128                                          0          0             0   \n",
       "129                                          0          0             0   \n",
       "130                                          0          0             0   \n",
       "131                                          0          0             0   \n",
       "132                                          0          0             0   \n",
       "133                                          0          0             0   \n",
       "134                                          0          0             0   \n",
       "135                                          0          0             0   \n",
       "\n",
       "     Semantics   deep neural network  \n",
       "0             0                    0  \n",
       "1             0                    0  \n",
       "2             0                    0  \n",
       "3             0                    0  \n",
       "4             0                    0  \n",
       "5             0                    0  \n",
       "6             0                    0  \n",
       "7             0                    0  \n",
       "8             0                    0  \n",
       "9             0                    0  \n",
       "10            0                    0  \n",
       "11            0                    0  \n",
       "12            0                    0  \n",
       "13            0                    0  \n",
       "14            0                    0  \n",
       "15            0                    0  \n",
       "16            0                    0  \n",
       "17            1                    0  \n",
       "18            0                    0  \n",
       "19            0                    0  \n",
       "20            0                    0  \n",
       "21            0                    0  \n",
       "22            0                    0  \n",
       "23            0                    0  \n",
       "24            0                    0  \n",
       "25            0                    0  \n",
       "26            0                    0  \n",
       "27            0                    0  \n",
       "28            0                    0  \n",
       "29            0                    0  \n",
       "..          ...                  ...  \n",
       "106           0                    0  \n",
       "107           0                    0  \n",
       "108           0                    0  \n",
       "109           0                    0  \n",
       "110           0                    0  \n",
       "111           0                    0  \n",
       "112           0                    0  \n",
       "113           0                    0  \n",
       "114           0                    0  \n",
       "115           0                    0  \n",
       "116           0                    0  \n",
       "117           0                    0  \n",
       "118           0                    0  \n",
       "119           0                    0  \n",
       "120           0                    0  \n",
       "121           0                    0  \n",
       "122           0                    0  \n",
       "123           0                    0  \n",
       "124           0                    0  \n",
       "125           0                    0  \n",
       "126           0                    0  \n",
       "127           0                    0  \n",
       "128           0                    0  \n",
       "129           0                    0  \n",
       "130           0                    0  \n",
       "131           0                    0  \n",
       "132           0                    0  \n",
       "133           0                    0  \n",
       "134           0                    0  \n",
       "135           0                    0  \n",
       "\n",
       "[136 rows x 1774 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 5. 0. ... 0. 0. 0.]\n",
      " [4. 7. 3. ... 0. 0. 0.]\n",
      " [6. 3. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [7. 5. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 4. ... 3. 3. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "variable_code, ctr = read_files(words_dir, tags_directory)\n",
    "columns = list(Tags)\n",
    "rows = list(range(ctr))\n",
    "dataFrame = np.zeros((len(rows), len(columns)))\n",
    "#df = tag_updater(dataFrame, variable_code, columns)\n",
    "\n",
    "df = pd.DataFrame(data = dataFrame, index = rows, columns = columns, dtype='int64')\n",
    "# print(variable_code)\n",
    "Y = tag_updater(df, variable_code)\n",
    "#print(df.at[1, ' Machine learning '])\n",
    "# for x in df['Computers']:\n",
    "#     print(x)\n",
    "\n",
    "display(Y)\n",
    "Y.fillna(0, inplace=True)\n",
    "\n",
    "X = extract_features(Words, features)\n",
    "X_train = pd.DataFrame(data = X, index = rows, columns = features, dtype='int64')\n",
    "\n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train, Y)\n",
    "# predict\n",
    "#predictions = classifier.predict(X_train)\n",
    "#print(predictions.toarray())\n",
    "#print(accuracy_score(Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "words_dir = 'testing'\n",
    "Words, waste1, waste2 = read_words(words_dir)\n",
    "X = extract_features(Words, features)\n",
    "rows = list(range(1))\n",
    "X_test = pd.DataFrame(data = X, columns = features, dtype='int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learn</th>\n",
       "      <th>The</th>\n",
       "      <th>use</th>\n",
       "      <th>neural</th>\n",
       "      <th>big</th>\n",
       "      <th>machine</th>\n",
       "      <th>Data</th>\n",
       "      <th>deep</th>\n",
       "      <th>network</th>\n",
       "      <th>...</th>\n",
       "      <th>Composition</th>\n",
       "      <th>ï»¿A</th>\n",
       "      <th>method</th>\n",
       "      <th>choose</th>\n",
       "      <th>kernel</th>\n",
       "      <th>function</th>\n",
       "      <th>parameters</th>\n",
       "      <th>support</th>\n",
       "      <th>vector</th>\n",
       "      <th>machines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learn  The  use  neural  big  machine  Data  deep  network    ...     \\\n",
       "0     0      0    0    0       0    0        0     0     0        0    ...      \n",
       "\n",
       "   Composition  ï»¿A  method  choose  kernel  function  parameters  support  \\\n",
       "0            0     0       0       0       0         0           0        0   \n",
       "\n",
       "   vector  machines  \n",
       "0       0         0  \n",
       "\n",
       "[1 rows x 4147 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1774 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Column format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(predictions)\n",
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csc.csc_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "print(type(predictions))\n",
    "a = predictions.nonzero()\n",
    "#a.row[a.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(self):\n",
    "    A = self.tocoo()\n",
    "    nz_mask = A.data != 0\n",
    "    return (list(A.col[nz_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1774)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "1774\n"
     ]
    }
   ],
   "source": [
    "print((predictions.shape[0], len(columns)))\n",
    "dataFrame5 = np.zeros((predictions.shape[0], len(columns)))\n",
    "ct = 0\n",
    "for i in predictions:\n",
    "    b = find_index(i)\n",
    "    for j in b:\n",
    "        dataFrame5[ct,j] +=1\n",
    "    ct+=1\n",
    "print(dataFrame5)\n",
    "for i in dataFrame5:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hilbert spaces</th>\n",
       "      <th>Fuzzy control</th>\n",
       "      <th>ï»¿Handheld computers</th>\n",
       "      <th>Benes interconnection network</th>\n",
       "      <th>Predictive models</th>\n",
       "      <th>output units</th>\n",
       "      <th>Artificial Neural Networ (ANN)</th>\n",
       "      <th>flexible structures</th>\n",
       "      <th>data analytics problems</th>\n",
       "      <th>accident risk determination</th>\n",
       "      <th>...</th>\n",
       "      <th>Application software</th>\n",
       "      <th>Optical computing</th>\n",
       "      <th>Accelerometers</th>\n",
       "      <th>maximal margin classification</th>\n",
       "      <th>data sharing</th>\n",
       "      <th>discriminative loss function optimization</th>\n",
       "      <th>Business</th>\n",
       "      <th>video frames</th>\n",
       "      <th>Semantics</th>\n",
       "      <th>deep neural network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hilbert spaces  Fuzzy control  ï»¿Handheld computers  \\\n",
       "0               0              0                      0   \n",
       "\n",
       "   Benes interconnection network\\n   Predictive models   output units  \\\n",
       "0                                0                    0             0   \n",
       "\n",
       "   Artificial Neural Networ (ANN)  flexible structures  \\\n",
       "0                               0                    0   \n",
       "\n",
       "   data analytics problems  accident risk determination         ...           \\\n",
       "0                        0                            0         ...            \n",
       "\n",
       "   Application software  Optical computing  Accelerometers  \\\n",
       "0                     0                  0               0   \n",
       "\n",
       "   maximal margin classification  data sharing  \\\n",
       "0                              0             0   \n",
       "\n",
       "   discriminative loss function optimization   Business  video frames  \\\n",
       "0                                          0          0             0   \n",
       "\n",
       "   Semantics   deep neural network  \n",
       "0           0                    0  \n",
       "\n",
       "[1 rows x 1774 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(dataFrame))\n",
    "\n",
    "converting = pd.DataFrame(data = dataFrame5, columns = columns, dtype='int64')\n",
    "display(converting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_predicted_skills.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------TECHNICAL SKILLS REQUIRED-----------------------------\n",
      " Machine learning algorithms \n",
      " Computer science \n",
      " Classification algorithms \n",
      " Training data \n",
      " Learning systems \n",
      " Educational institutions \n",
      " Support vector machines \n",
      " Support vector machine classification \n",
      " Machine learning \n",
      " Data models \n",
      "[' Machine learning algorithms ', ' Computer science ', ' Classification algorithms ', ' Training data ', ' Learning systems ', ' Educational institutions ', ' Support vector machines ', ' Support vector machine classification ', ' Machine learning ', ' Data models ']\n"
     ]
    }
   ],
   "source": [
    "we_have = []\n",
    "print('------------------------TECHNICAL SKILLS REQUIRED-----------------------------')\n",
    "for i in b:\n",
    "    print(columns[i])\n",
    "    we_have.append(columns[i])\n",
    "    \n",
    "#we_have.append('artificial intelligence')\n",
    "#we_have.append('Machine learning algorithms')\n",
    "#we_have.append('Support vector machines')\n",
    "#we_have.append('Kernel')\n",
    "\n",
    "print(we_have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is keyword extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next comes the wiki reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identification and evaluation of market opportunities', 'opportunity management', 'identifying and seizing fast breaking opportunities', 'evaluation of commercial opportunities'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def load_skill_set():\n",
    "\n",
    "    skill_dict = dict()\n",
    "    pick_file = open(\"final_skill_dict.pickle\", \"rb\")\n",
    "    skill_dict = pickle.load(pick_file)\n",
    "    pick_file.close()\n",
    "    return skill_dict\n",
    "\n",
    "\n",
    "skill_dict = load_skill_set()\n",
    "\n",
    "\n",
    "def get_skills(skill_dic,topic):\n",
    "\n",
    "    # print(\"getting skill set for \",topic)\n",
    "    skill_set = set()\n",
    "    for word in topic.split(' '):\n",
    "        # print(\"for word=\",word)\n",
    "        if word.strip().isalpha():\n",
    "            word = word.strip().lower()\n",
    "            wordnet_pos = get_wordnet_pos(nltk.pos_tag([word])[0][1])\n",
    "            if wordnet_pos == '':\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "            else:\n",
    "                word = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "\n",
    "            try:\n",
    "                curr_skill_set = skill_dic[word]\n",
    "                # print(\"skill set=\",curr_skill_set)\n",
    "                if len(skill_set) == 0:\n",
    "                    skill_set = curr_skill_set\n",
    "                else:\n",
    "                    skill_set = skill_set.intersection(curr_skill_set)\n",
    "\n",
    "                #print(\"intersection=\",skill_set)\n",
    "            except KeyError as e:\n",
    "                print(\"no skill set found\",e)\n",
    "\n",
    "    return skill_set\n",
    "\n",
    "\n",
    "print(get_skills(skill_dict,'opportunity'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_page(topic):\n",
    "    domain = \"https://en.wikipedia.org\"\n",
    "    html = urllib.request.urlopen(\"https://en.wikipedia.org/w/index.php?search=\"+topic.replace(' ','+')+\"&title=Special%3ASearch&go=Go\")\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    first_result = soup.find(attrs={\"data-serp-pos\": \"0\"})\n",
    "    if first_result is None:\n",
    "        print('page-found')\n",
    "        return soup\n",
    "    href = first_result.get('href')\n",
    "    print('opening first-result')\n",
    "    html = urllib.request.urlopen(domain+href)\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_first_para(topic):\n",
    "    soup = get_page(topic)\n",
    "    text_section = soup.find(attrs={'class': 'mw-parser-output'})\n",
    "    text = ''\n",
    "    for child in text_section.children:\n",
    "        # print('for tag', child.name, child)\n",
    "        try:\n",
    "            if child is not None:\n",
    "                if child.name == 'p':\n",
    "                    text += child.text.lower()\n",
    "                elif child.name == 'div' and 'toc' in child['class']:\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(\"exception\", e)\n",
    "    return text\n",
    "\n",
    "vo_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning algorithms \n",
      " Computer science \n",
      " Classification algorithms \n",
      " Training data \n",
      " Learning systems \n",
      " Educational institutions \n",
      " Support vector machines \n",
      " Support vector machine classification \n",
      " Machine learning \n",
      " Data models \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# cleaning we _have \n",
    "dore = []\n",
    "for x in we_have:\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    #First parameter is the replacement, second parameter is your input string\n",
    "    #regex.sub('', x)\n",
    "    dore.append(re.sub(\"[^a-zA-Z_ ]*\", \"\", x))\n",
    "\n",
    "for y in dore:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tech2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(dore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning algorithms \n",
      "page-found\n",
      "the following outline is provided as an overview of and topical guide to machine learning. machine learning is a subfield of soft computing within computer science that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] in 1959, arthur samuel defined machine learning as a \"field of study that gives computers the ability to learn without being explicitly programmed\".[2] machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[3] such algorithms operate by building a model from an example training set of input observations in order to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.\n",
      "subfields of machine learning\n",
      "cross-disciplinary fields involving machine learning\n",
      "applications of machine learning\n",
      "machine learning hardware\n",
      "machine learning tools   (list)\n",
      "machine learning framework\n",
      "proprietary machine learning frameworks\n",
      "open source machine learning frameworks\n",
      "machine learning library   \n",
      "machine learning algorithm\n",
      "machine learning method   (list)\n",
      "dimensionality reduction\n",
      "ensemble learning\n",
      "meta learning\n",
      "reinforcement learning\n",
      "supervised learning\n",
      "bayesian statistics\n",
      "decision tree algorithm\n",
      "linear classifier\n",
      "unsupervised learning\n",
      "artificial neural network\n",
      "association rule learning\n",
      "hierarchical clustering\n",
      "cluster analysis\n",
      "anomaly detection\n",
      "semi-supervised learning\n",
      "deep learning\n",
      "history of machine learning\n",
      "machine learning projects\n",
      "machine learning organizations\n",
      "books about machine learning\n",
      "\n",
      "no skill set found 'follow'\n",
      "no skill set found 'outline'\n",
      "no skill set found 'overview'\n",
      "no skill set found 'topical'\n",
      "no skill set found 'guide'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'subfield'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'within'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'evolve'\n",
      "no skill set found 'recognition'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'arthur'\n",
      "no skill set found 'samuel'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'field'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'explicitly'\n",
      "no skill set found 'programmed'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'explores'\n",
      "no skill set found 'construction'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'operate'\n",
      "no skill set found 'input'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'express'\n",
      "no skill set found 'output'\n",
      "no skill set found 'rather'\n",
      "no skill set found 'follow'\n",
      "no skill set found 'strictly'\n",
      "no skill set found 'static'\n",
      "no skill set found 'instruction'\n",
      "no skill set found 'subfields'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'field'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'application'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'list'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'proprietary'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'library'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'list'\n",
      "no skill set found 'dimensionality'\n",
      "no skill set found 'ensemble'\n",
      "no skill set found 'meta'\n",
      "no skill set found 'reinforcement'\n",
      "no skill set found 'bayesian'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'linear'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'neural'\n",
      "no skill set found 'rule'\n",
      "no skill set found 'hierarchical'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'anomaly'\n",
      "no skill set found 'detection'\n",
      "no skill set found 'deep'\n",
      "no skill set found 'history'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'book'\n",
      "no skill set found 'machine'\n",
      " Computer science \n",
      "page-found\n",
      "\n",
      "computer science is the study of processes that interact with data and that can be represented as data in the form of programs. it enables the use of algorithms to manipulate, store, and communicate digital information. a computer scientist studies the theory of computation and the practice of designing software systems.[1]\n",
      "its fields can be divided into theoretical and practical disciplines. computational complexity theory is highly abstract, while computer graphics emphasizes real-world applications. programming language theory considers approaches to the description of computational processes, while computer programming itself involves the use of programming languages and complex systems. human–computer interaction considers the challenges in making computers useful, usable, and accessible.\n",
      "the earliest foundations of what would become computer science predate the invention of the modern digital computer. machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.\n",
      "wilhelm schickard designed and constructed the first working mechanical calculator in 1623.[4] in 1673, gottfried leibniz demonstrated a digital mechanical calculator, called the stepped reckoner.[5] he may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. in 1820, thomas de colmar launched the mechanical calculator industry[note 1] when he released his simplified arithmometer, which was the first calculating machine strong enough and reliable enough to be used daily in an office environment. charles babbage started the design of the first automatic mechanical calculator, his difference engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his analytical engine.[6] he started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\".[7] \"a crucial step was the adoption of a punched card system derived from the jacquard loom\"[7] making it infinitely programmable.[note 2] in 1843, during the translation of a french article on the analytical engine, ada lovelace wrote, in one of the many notes she included, an algorithm to compute the bernoulli numbers, which is considered to be the first computer program.[8] around 1885, herman hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of ibm. in 1937, one hundred years after babbage's impossible dream, howard aiken convinced ibm, which was making all kinds of punched card equipment and was also in the calculator business[9] to develop his giant programmable calculator, the ascc/harvard mark i, based on babbage's analytical engine, which itself used cards and a central computing unit. when the machine was finished, some hailed it as \"babbage's dream come true\".[10]\n",
      "during the 1940s, as new and more powerful computing machines were developed, the term computer came to refer to the machines rather than their human predecessors.[11] as it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. in 1945, ibm founded the watson scientific computing laboratory at columbia university in new york city. the renovated fraternity house on manhattan's west side was ibm's first laboratory devoted to pure science. the lab is the forerunner of ibm's research division, which today operates research facilities around the world. [12] ultimately, the close relationship between ibm and the university was instrumental in the emergence of a new scientific discipline, with columbia offering one of the first academic-credit courses in computer science in 1946. [13] computer science began to be established as a distinct academic discipline in the 1950s and early 1960s.[14][15] the world's first computer science degree program, the cambridge diploma in computer science, began at the university of cambridge computer laboratory in 1953. the first computer science degree program in the united states was formed at purdue university in 1962.[16] since practical computers became available, many applications of computing have become distinct areas of study in their own rights.\n",
      "although many initially believed it was impossible that computers themselves could actually be a scientific field of study, in the late fifties it gradually became accepted among the greater academic population.[17][18] it is the now well-known ibm brand that formed part of the computer science revolution during this time. ibm (short for international business machines) released the ibm 704[19] and later the ibm 709[20] computers, which were widely used during the exploration period of such devices. \"still, working with the ibm [computer] was frustrating […] if you had misplaced as much as one letter in one instruction, the program would crash, and you would have to start the whole process over again\".[17] during the late 1950s, the computer science discipline was very much in its developmental stages, and such issues were commonplace.[18]\n",
      "time has seen significant improvements in the usability and effectiveness of computing technology.[21] modern society has seen a significant shift in the users of computer technology, from usage only by experts and professionals, to a near-ubiquitous user base. initially, computers were quite costly, and some degree of humanitarian aid was needed for efficient use—in part from professional computer operators. as computer adoption became more widespread and affordable, less human assistance was needed for common usage.\n",
      "despite its short history as a formal academic discipline, computer science has made a number of fundamental contributions to science and society—in fact, along with electronics, it is a founding science of the current epoch of human history called the information age and a driver of the information revolution, seen as the third major leap in human technological progress after the industrial revolution (1750–1850 ce) and the agricultural revolution (8000–5000 bc).\n",
      "these contributions include:\n",
      "although first proposed in 1956,[18] the term \"computer science\" appears in a 1959 article in communications of the acm,[30]\n",
      "in which louis fein argues for the creation of a graduate school in computer sciences analogous to the creation of harvard business school in 1921,[31] justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.[30]\n",
      "his efforts, and those of others such as numerical analyst george forsythe, were rewarded: universities went on to create such programs, starting with purdue in 1962.[32] despite its name, a significant amount of computer science does not involve the study of computers themselves. because of this, several alternative names have been proposed.[33] certain departments of major universities prefer the term computing science, to emphasize precisely that difference. danish scientist peter naur suggested the term datalogy,[34] to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. the first scientific institution to use the term was the department of datalogy at the university of copenhagen, founded in 1969, with peter naur being the first professor in datalogy. the term is used mainly in the scandinavian countries. an alternative term, also proposed by naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.\n",
      "also, in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the communications of the acm—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist.[35] three months later in the same journal, comptologist was suggested, followed next year by hypologist.[36] the term computics has also been suggested.[37] in europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in italian) or \"information and mathematics\" are often used, e.g. informatique (french), informatik (german), informatica (italian, dutch), informática (spanish, portuguese), informatika (slavic languages and hungarian) or pliroforiki (πληροφορική, which means informatics) in greek. similar words have also been adopted in the uk (as in the school of informatics of the university of edinburgh).[38]\n",
      "\"in the u.s., however, informatics is linked with applied computing, or computing in the context of another domain.\"[39]\n",
      "a folkloric quotation, often attributed to—but almost certainly not first formulated by—edsger dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\"[note 3] the design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. for example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. however, there has been much cross-fertilization of ideas between the various computer-related disciplines. computer science research also often intersects other disciplines, such as philosophy, cognitive science, linguistics, mathematics, physics, biology, statistics, and logic.\n",
      "computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science.[14] early computer science was strongly influenced by the work of mathematicians such as kurt gödel, alan turing, rózsa péter and alonzo church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.[18]\n",
      "the relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined.[40] david parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.[41]\n",
      "the academic, political, and funding aspects of computer science tend to depend on whether a department formed with a mathematical emphasis or with an engineering emphasis. computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. both types of departments tend to make efforts to bridge the field educationally if not across all research.\n",
      "a number of computer scientists have argued for the distinction of three separate paradigms in computer science. peter wegner argued that those paradigms are science, technology, and mathematics.[42] peter denning's working group argued that they are theory, abstraction (modeling), and design.[43] amnon h. eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).[44]\n",
      "as a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.[45][46]\n",
      "csab, formerly called computing sciences accreditation board—which is made up of representatives of the association for computing machinery (acm), and the ieee computer society (ieee cs)[47]—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. in addition to these four areas, csab also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.[45]\n",
      "theoretical computer science is mathematical and abstract in spirit, but it derives its motivation from practical and everyday computation. its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies. all studies related to mathematical, logic and formal concepts and methods could be considered as theoretical computer science, provided that the motivation is clearly drawn from the field of computing.\n",
      "data structures and algorithms are the study of commonly used computational methods and their computational efficiency.\n",
      "according to peter denning, the fundamental question underlying computer science is, \"what can be (efficiently) automated?\"[14] theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. in an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. the second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.\n",
      "the famous p = np? problem, one of the millennium prize problems,[48] is an open problem in the theory of computation.\n",
      "information theory is related to the quantification of information. this was developed by claude shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.[49]\n",
      "coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. codes are studied for the purpose of designing efficient and reliable data transmission methods.\n",
      "programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. it falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. it is an active research area, with numerous dedicated academic journals.\n",
      "formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. the use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. they form an important theoretical underpinning for software engineering, especially where safety or security is involved. formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. for industrial use, tool support is required. however, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.\n",
      "computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. it focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory.[50] the field often involves disciplines of computer engineering and electrical engineering, selecting and interconnecting hardware components to create computers that meet functional, performance, and cost goals.\n",
      "computer performance analysis is the study of work flowing through computers with the general goals of improving throughput, controlling response time, using resources efficiently, eliminating bottlenecks, and predicting performance under anticipated peak loads.[51]\n",
      "benchmarks provide a method of comparing the performance of various subsystems across different chip/system architectures.\n",
      "concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. a number of mathematical models have been developed for general concurrent computation including petri nets, process calculi and the parallel random access machine model. a distributed system extends the idea of concurrency onto multiple computers connected through a network. computers within the same distributed system have their own private memory, and information is often exchanged among themselves to achieve a common goal.\n",
      "this branch of computer science aims to manage networks between computers worldwide.\n",
      "computer security is a branch of computer technology with an objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. cryptography is the practice and study of hiding (encryption) and therefore deciphering (decryption) information. modern cryptography is largely related to computer science, for many encryption and decryption algorithms are based on their computational complexity.\n",
      "a database is intended to organize, store, and retrieve large amounts of data easily. digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages.\n",
      "computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. the study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.\n",
      "research that develops theories, principles, and guidelines for user interface designers, so they can create satisfactory user experiences with desktop, laptop, and mobile devices.\n",
      "scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. in practical use, it is typically the application of computer simulation and other forms of computation to problems in various scientific disciplines.\n",
      "artificial intelligence (ai) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. from its origins in cybernetics and in the dartmouth conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. ai is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. the starting point in the late 1940s was alan turing's question \"can computers think?\", and the question remains effectively unanswered, although the turing test is still used to assess computer output on the scale of human intelligence. but the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.\n",
      "software engineering is the study of designing, implementing, and modifying software in order to ensure it is of high quality, affordable, maintainable, and fast to build. it is a systematic approach to software design, involving the application of engineering practices to software. software engineering deals with the organizing and analyzing of software—it doesn't just deal with the creation or manufacture of new software, but its internal maintenance and arrangement.\n",
      "the philosopher of computing bill rapaport noted three great insights of computer science:[52]\n",
      "programming languages can be used to accomplish different tasks in different ways. common programming paradigms include:\n",
      "many languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.[53]\n",
      "conferences are important events for computer science research. during these conferences, researchers from the public and private sectors present their recent work and meet. unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications.[54][55] one proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.[56]\n",
      "computer science, known by its near synonyms, computing, computer studies, information technology (it) and information and computing technology (ict), has been taught in uk schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students.[57] in 1981, the bbc produced a micro-computer and classroom network and computer studies became common for gce o level students (11–16-year-old), and computer science to a level students. its importance was recognised, and it became a compulsory part of the national curriculum, for key stage 3 & 4. in september 2014 it became an entitlement for all 7,000,000 pupils over the age of 4.[58]\n",
      "in the us, with 14,000 school districts deciding the curriculum, provision was fractured.[59] according to a 2010 report by the association for computing machinery (acm) and computer science teachers association (csta), only 14 out of 50 states have adopted significant education standards for high school computer science.[60]\n",
      "institute of electrical and electronics engineers (ieee) produces over 30% of the world's literature in the electrical and electronics engineering and computer science fields, publishing well over 100 peer-reviewed journals.\n",
      "israel, new zealand, and south korea have included computer science in their national secondary education curricula,[61][62] and several others are following.[63]\n",
      "in many countries, there is a significant gender gap in computer science education. in 2012, only 20 percent of computer science degrees in the united states were awarded to women.[64] the gender gap is also a problem in other western countries.[65] the gap is smaller, or nonexistent, in some parts of the world. in 2011, women earned half of the computer science degrees in malaysia.[66] in 2001, 55 percent of computer science graduates in guyana were women.[65]\n",
      "bibliography and academic search engines\n",
      "professional organizations\n",
      "misc\n",
      "\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'interact'\n",
      "no skill set found 'represent'\n",
      "no skill set found 'form'\n",
      "no skill set found 'enables'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'manipulate'\n",
      "no skill set found 'store'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'scientist'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'field'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'complexity'\n",
      "no skill set found 'highly'\n",
      "no skill set found 'abstract'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'computer'\n",
      "no skill set found 'emphasizes'\n",
      "no skill set found 'application'\n",
      "no skill set found 'considers'\n",
      "no skill set found 'description'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'involves'\n",
      "no skill set found 'interaction'\n",
      "no skill set found 'considers'\n",
      "no skill set found 'challenge'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'usable'\n",
      "no skill set found 'accessible'\n",
      "no skill set found 'early'\n",
      "no skill set found 'foundation'\n",
      "no skill set found 'would'\n",
      "no skill set found 'become'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'predate'\n",
      "no skill set found 'invention'\n",
      "no skill set found 'modern'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'calculate'\n",
      "no skill set found 'fix'\n",
      "no skill set found 'numerical'\n",
      "no skill set found 'abacus'\n",
      "no skill set found 'exist'\n",
      "no skill set found 'since'\n",
      "no skill set found 'antiquity'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'multiplication'\n",
      "no skill set found 'division'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'exist'\n",
      "no skill set found 'since'\n",
      "no skill set found 'antiquity'\n",
      "no skill set found 'even'\n",
      "no skill set found 'sophisticated'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'equipment'\n",
      "no skill set found 'wilhelm'\n",
      "no skill set found 'schickard'\n",
      "no skill set found 'construct'\n",
      "no skill set found 'mechanical'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'gottfried'\n",
      "no skill set found 'leibniz'\n",
      "no skill set found 'mechanical'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'step'\n",
      "no skill set found 'reckoner'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'scientist'\n",
      "no skill set found 'theorist'\n",
      "no skill set found 'among'\n",
      "no skill set found 'document'\n",
      "no skill set found 'binary'\n",
      "no skill set found 'number'\n",
      "no skill set found 'thomas'\n",
      "no skill set found 'colmar'\n",
      "no skill set found 'mechanical'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'note'\n",
      "no skill set found 'release'\n",
      "no skill set found 'arithmometer'\n",
      "no skill set found 'calculate'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'enough'\n",
      "no skill set found 'reliable'\n",
      "no skill set found 'enough'\n",
      "no skill set found 'daily'\n",
      "no skill set found 'charles'\n",
      "no skill set found 'babbage'\n",
      "no skill set found 'start'\n",
      "no skill set found 'automatic'\n",
      "no skill set found 'mechanical'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'difference'\n",
      "no skill set found 'engine'\n",
      "no skill set found 'eventually'\n",
      "no skill set found 'programmable'\n",
      "no skill set found 'mechanical'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'analytical'\n",
      "no skill set found 'engine'\n",
      "no skill set found 'start'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'less'\n",
      "no skill set found 'year'\n",
      "no skill set found 'sketch'\n",
      "no skill set found 'many'\n",
      "no skill set found 'salient'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'modern'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'crucial'\n",
      "no skill set found 'step'\n",
      "no skill set found 'adoption'\n",
      "no skill set found 'punch'\n",
      "no skill set found 'card'\n",
      "no skill set found 'derive'\n",
      "no skill set found 'jacquard'\n",
      "no skill set found 'loom'\n",
      "no skill set found 'infinitely'\n",
      "no skill set found 'programmable'\n",
      "no skill set found 'note'\n",
      "no skill set found 'translation'\n",
      "no skill set found 'french'\n",
      "no skill set found 'article'\n",
      "no skill set found 'analytical'\n",
      "no skill set found 'engine'\n",
      "no skill set found 'lovelace'\n",
      "no skill set found 'many'\n",
      "no skill set found 'note'\n",
      "no skill set found 'include'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'bernoulli'\n",
      "no skill set found 'number'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'herman'\n",
      "no skill set found 'hollerith'\n",
      "no skill set found 'invent'\n",
      "no skill set found 'tabulator'\n",
      "no skill set found 'punch'\n",
      "no skill set found 'card'\n",
      "no skill set found 'eventually'\n",
      "no skill set found 'become'\n",
      "no skill set found 'part'\n",
      "no skill set found 'hundred'\n",
      "no skill set found 'year'\n",
      "no skill set found 'babbage'\n",
      "no skill set found 'impossible'\n",
      "no skill set found 'dream'\n",
      "no skill set found 'howard'\n",
      "no skill set found 'aiken'\n",
      "no skill set found 'convince'\n",
      "no skill set found 'kind'\n",
      "no skill set found 'punch'\n",
      "no skill set found 'card'\n",
      "no skill set found 'equipment'\n",
      "no skill set found 'also'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'giant'\n",
      "no skill set found 'programmable'\n",
      "no skill set found 'calculator'\n",
      "no skill set found 'mark'\n",
      "no skill set found 'babbage'\n",
      "no skill set found 'analytical'\n",
      "no skill set found 'engine'\n",
      "no skill set found 'card'\n",
      "no skill set found 'central'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'unit'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'finish'\n",
      "no skill set found 'hail'\n",
      "no skill set found 'babbage'\n",
      "no skill set found 'dream'\n",
      "no skill set found 'come'\n",
      "no skill set found 'true'\n",
      "no skill set found 'powerful'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'developed'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'come'\n",
      "no skill set found 'refer'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'rather'\n",
      "no skill set found 'predecessor'\n",
      "no skill set found 'become'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'could'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'calculation'\n",
      "no skill set found 'field'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'broaden'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'general'\n",
      "no skill set found 'found'\n",
      "no skill set found 'watson'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'laboratory'\n",
      "no skill set found 'columbia'\n",
      "no skill set found 'university'\n",
      "no skill set found 'york'\n",
      "no skill set found 'city'\n",
      "no skill set found 'renovate'\n",
      "no skill set found 'fraternity'\n",
      "no skill set found 'house'\n",
      "no skill set found 'manhattan'\n",
      "no skill set found 'west'\n",
      "no skill set found 'side'\n",
      "no skill set found 'laboratory'\n",
      "no skill set found 'devote'\n",
      "no skill set found 'pure'\n",
      "no skill set found 'science'\n",
      "no skill set found 'forerunner'\n",
      "no skill set found 'division'\n",
      "no skill set found 'today'\n",
      "no skill set found 'operates'\n",
      "no skill set found 'facility'\n",
      "no skill set found 'world'\n",
      "no skill set found 'ultimately'\n",
      "no skill set found 'close'\n",
      "no skill set found 'university'\n",
      "no skill set found 'instrumental'\n",
      "no skill set found 'emergence'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'columbia'\n",
      "no skill set found 'offering'\n",
      "no skill set found 'course'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'begin'\n",
      "no skill set found 'distinct'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'early'\n",
      "no skill set found 'world'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'degree'\n",
      "no skill set found 'cambridge'\n",
      "no skill set found 'diploma'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'begin'\n",
      "no skill set found 'university'\n",
      "no skill set found 'cambridge'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'laboratory'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'degree'\n",
      "no skill set found 'united'\n",
      "no skill set found 'form'\n",
      "no skill set found 'purdue'\n",
      "no skill set found 'university'\n",
      "no skill set found 'since'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'become'\n",
      "no skill set found 'available'\n",
      "no skill set found 'many'\n",
      "no skill set found 'application'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'become'\n",
      "no skill set found 'distinct'\n",
      "no skill set found 'right'\n",
      "no skill set found 'although'\n",
      "no skill set found 'many'\n",
      "no skill set found 'initially'\n",
      "no skill set found 'believe'\n",
      "no skill set found 'impossible'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'could'\n",
      "no skill set found 'actually'\n",
      "no skill set found 'field'\n",
      "no skill set found 'late'\n",
      "no skill set found 'fifty'\n",
      "no skill set found 'gradually'\n",
      "no skill set found 'become'\n",
      "no skill set found 'accepted'\n",
      "no skill set found 'among'\n",
      "no skill set found 'great'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'population'\n",
      "no skill set found 'form'\n",
      "no skill set found 'part'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'revolution'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'release'\n",
      "no skill set found 'later'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'widely'\n",
      "no skill set found 'exploration'\n",
      "no skill set found 'period'\n",
      "no skill set found 'device'\n",
      "no skill set found 'still'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'frustrate'\n",
      "no skill set found 'misplace'\n",
      "no skill set found 'much'\n",
      "no skill set found 'letter'\n",
      "no skill set found 'instruction'\n",
      "no skill set found 'would'\n",
      "no skill set found 'crash'\n",
      "no skill set found 'would'\n",
      "no skill set found 'start'\n",
      "no skill set found 'whole'\n",
      "no skill set found 'late'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'much'\n",
      "no skill set found 'developmental'\n",
      "no skill set found 'commonplace'\n",
      "no skill set found 'significant'\n",
      "no skill set found 'usability'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'modern'\n",
      "no skill set found 'society'\n",
      "no skill set found 'significant'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'computer'\n",
      "no skill set found 'usage'\n",
      "no skill set found 'expert'\n",
      "no skill set found 'initially'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'quite'\n",
      "no skill set found 'costly'\n",
      "no skill set found 'degree'\n",
      "no skill set found 'humanitarian'\n",
      "no skill set found 'efficient'\n",
      "no skill set found 'part'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'operator'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'adoption'\n",
      "no skill set found 'become'\n",
      "no skill set found 'widespread'\n",
      "no skill set found 'affordable'\n",
      "no skill set found 'less'\n",
      "no skill set found 'assistance'\n",
      "no skill set found 'usage'\n",
      "no skill set found 'despite'\n",
      "no skill set found 'history'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'number'\n",
      "no skill set found 'contribution'\n",
      "no skill set found 'science'\n",
      "no skill set found 'fact'\n",
      "no skill set found 'along'\n",
      "no skill set found 'electronics'\n",
      "no skill set found 'found'\n",
      "no skill set found 'science'\n",
      "no skill set found 'epoch'\n",
      "no skill set found 'history'\n",
      "no skill set found 'driver'\n",
      "no skill set found 'revolution'\n",
      "no skill set found 'third'\n",
      "no skill set found 'major'\n",
      "no skill set found 'leap'\n",
      "no skill set found 'technological'\n",
      "no skill set found 'progress'\n",
      "no skill set found 'industrial'\n",
      "no skill set found 'revolution'\n",
      "no skill set found 'agricultural'\n",
      "no skill set found 'revolution'\n",
      "no skill set found 'contribution'\n",
      "no skill set found 'include'\n",
      "no skill set found 'although'\n",
      "no skill set found 'propose'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'appear'\n",
      "no skill set found 'article'\n",
      "no skill set found 'louis'\n",
      "no skill set found 'fein'\n",
      "no skill set found 'argues'\n",
      "no skill set found 'graduate'\n",
      "no skill set found 'school'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'analogous'\n",
      "no skill set found 'harvard'\n",
      "no skill set found 'school'\n",
      "no skill set found 'justify'\n",
      "no skill set found 'argue'\n",
      "no skill set found 'like'\n",
      "no skill set found 'science'\n",
      "no skill set found 'subject'\n",
      "no skill set found 'interdisciplinary'\n",
      "no skill set found 'nature'\n",
      "no skill set found 'characteristic'\n",
      "no skill set found 'typical'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'effort'\n",
      "no skill set found 'numerical'\n",
      "no skill set found 'analyst'\n",
      "no skill set found 'george'\n",
      "no skill set found 'forsythe'\n",
      "no skill set found 'university'\n",
      "no skill set found 'go'\n",
      "no skill set found 'start'\n",
      "no skill set found 'purdue'\n",
      "no skill set found 'despite'\n",
      "no skill set found 'significant'\n",
      "no skill set found 'amount'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'several'\n",
      "no skill set found 'propose'\n",
      "no skill set found 'certain'\n",
      "no skill set found 'department'\n",
      "no skill set found 'major'\n",
      "no skill set found 'university'\n",
      "no skill set found 'prefer'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'science'\n",
      "no skill set found 'emphasize'\n",
      "no skill set found 'precisely'\n",
      "no skill set found 'difference'\n",
      "no skill set found 'danish'\n",
      "no skill set found 'scientist'\n",
      "no skill set found 'peter'\n",
      "no skill set found 'naur'\n",
      "no skill set found 'suggest'\n",
      "no skill set found 'datalogy'\n",
      "no skill set found 'reflect'\n",
      "no skill set found 'fact'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'revolves'\n",
      "no skill set found 'treatment'\n",
      "no skill set found 'necessarily'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'institution'\n",
      "no skill set found 'department'\n",
      "no skill set found 'datalogy'\n",
      "no skill set found 'university'\n",
      "no skill set found 'copenhagen'\n",
      "no skill set found 'found'\n",
      "no skill set found 'peter'\n",
      "no skill set found 'naur'\n",
      "no skill set found 'professor'\n",
      "no skill set found 'datalogy'\n",
      "no skill set found 'mainly'\n",
      "no skill set found 'scandinavian'\n",
      "no skill set found 'country'\n",
      "no skill set found 'also'\n",
      "no skill set found 'propose'\n",
      "no skill set found 'naur'\n",
      "no skill set found 'science'\n",
      "no skill set found 'field'\n",
      "no skill set found 'include'\n",
      "no skill set found 'database'\n",
      "no skill set found 'also'\n",
      "no skill set found 'early'\n",
      "no skill set found 'day'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'number'\n",
      "no skill set found 'practitioner'\n",
      "no skill set found 'field'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'suggest'\n",
      "no skill set found 'turologist'\n",
      "no skill set found 'epistemologist'\n",
      "no skill set found 'three'\n",
      "no skill set found 'month'\n",
      "no skill set found 'later'\n",
      "no skill set found 'journal'\n",
      "no skill set found 'comptologist'\n",
      "no skill set found 'suggest'\n",
      "no skill set found 'follow'\n",
      "no skill set found 'next'\n",
      "no skill set found 'year'\n",
      "no skill set found 'hypologist'\n",
      "no skill set found 'computics'\n",
      "no skill set found 'also'\n",
      "no skill set found 'suggest'\n",
      "no skill set found 'europe'\n",
      "no skill set found 'derive'\n",
      "no skill set found 'translation'\n",
      "no skill set found 'automatic'\n",
      "no skill set found 'informazione'\n",
      "no skill set found 'automatica'\n",
      "no skill set found 'italian'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'often'\n",
      "no skill set found 'informatique'\n",
      "no skill set found 'french'\n",
      "no skill set found 'informatik'\n",
      "no skill set found 'german'\n",
      "no skill set found 'informatica'\n",
      "no skill set found 'italian'\n",
      "no skill set found 'dutch'\n",
      "no skill set found 'informática'\n",
      "no skill set found 'spanish'\n",
      "no skill set found 'portuguese'\n",
      "no skill set found 'informatika'\n",
      "no skill set found 'slavic'\n",
      "no skill set found 'hungarian'\n",
      "no skill set found 'pliroforiki'\n",
      "no skill set found 'πληροφορική'\n",
      "no skill set found 'mean'\n",
      "no skill set found 'informatics'\n",
      "no skill set found 'greek'\n",
      "no skill set found 'similar'\n",
      "no skill set found 'also'\n",
      "no skill set found 'adopt'\n",
      "no skill set found 'school'\n",
      "no skill set found 'informatics'\n",
      "no skill set found 'university'\n",
      "no skill set found 'edinburgh'\n",
      "no skill set found 'however'\n",
      "no skill set found 'informatics'\n",
      "no skill set found 'link'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'context'\n",
      "no skill set found 'another'\n",
      "no skill set found 'domain'\n",
      "no skill set found 'folkloric'\n",
      "no skill set found 'quotation'\n",
      "no skill set found 'often'\n",
      "no skill set found 'attribute'\n",
      "no skill set found 'almost'\n",
      "no skill set found 'certainly'\n",
      "no skill set found 'formulate'\n",
      "no skill set found 'dijkstra'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'astronomy'\n",
      "no skill set found 'telescope'\n",
      "no skill set found 'note'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'generally'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'province'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'usually'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'part'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'often'\n",
      "no skill set found 'however'\n",
      "no skill set found 'much'\n",
      "no skill set found 'various'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'also'\n",
      "no skill set found 'often'\n",
      "no skill set found 'intersects'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'philosophy'\n",
      "no skill set found 'cognitive'\n",
      "no skill set found 'science'\n",
      "no skill set found 'linguistics'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'physic'\n",
      "no skill set found 'biology'\n",
      "no skill set found 'logic'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'much'\n",
      "no skill set found 'closer'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'many'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'observer'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'science'\n",
      "no skill set found 'early'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'strongly'\n",
      "no skill set found 'mathematician'\n",
      "no skill set found 'kurt'\n",
      "no skill set found 'gödel'\n",
      "no skill set found 'alan'\n",
      "no skill set found 'turing'\n",
      "no skill set found 'rózsa'\n",
      "no skill set found 'péter'\n",
      "no skill set found 'alonzo'\n",
      "no skill set found 'church'\n",
      "no skill set found 'continue'\n",
      "no skill set found 'interchange'\n",
      "no skill set found 'field'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'logic'\n",
      "no skill set found 'domain'\n",
      "no skill set found 'algebra'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'contentious'\n",
      "no skill set found 'muddy'\n",
      "no skill set found 'mean'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'david'\n",
      "no skill set found 'parnas'\n",
      "no skill set found 'science'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'claimed'\n",
      "no skill set found 'principal'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'computation'\n",
      "no skill set found 'general'\n",
      "no skill set found 'principal'\n",
      "no skill set found 'specific'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'complementary'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'tend'\n",
      "no skill set found 'depend'\n",
      "no skill set found 'whether'\n",
      "no skill set found 'department'\n",
      "no skill set found 'form'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'department'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'numerical'\n",
      "no skill set found 'orientation'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'science'\n",
      "no skill set found 'type'\n",
      "no skill set found 'department'\n",
      "no skill set found 'tend'\n",
      "no skill set found 'effort'\n",
      "no skill set found 'bridge'\n",
      "no skill set found 'field'\n",
      "no skill set found 'educationally'\n",
      "no skill set found 'number'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'scientist'\n",
      "no skill set found 'argue'\n",
      "no skill set found 'distinction'\n",
      "no skill set found 'three'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'peter'\n",
      "no skill set found 'wegner'\n",
      "no skill set found 'argue'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'science'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'peter'\n",
      "no skill set found 'denning'\n",
      "no skill set found 'argue'\n",
      "no skill set found 'abstraction'\n",
      "no skill set found 'amnon'\n",
      "no skill set found 'eden'\n",
      "no skill set found 'described'\n",
      "no skill set found 'rationalist'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'treat'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'branch'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'prevalent'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'mainly'\n",
      "no skill set found 'employ'\n",
      "no skill set found 'deductive'\n",
      "no skill set found 'technocratic'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'might'\n",
      "no skill set found 'found'\n",
      "no skill set found 'prominently'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'artifact'\n",
      "no skill set found 'empirical'\n",
      "no skill set found 'natural'\n",
      "no skill set found 'science'\n",
      "no skill set found 'identifiable'\n",
      "no skill set found 'branch'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'span'\n",
      "no skill set found 'topic'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'limit'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'csab'\n",
      "no skill set found 'formerly'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'science'\n",
      "no skill set found 'accreditation'\n",
      "no skill set found 'representative'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'machinery'\n",
      "no skill set found 'ieee'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'society'\n",
      "no skill set found 'ieee'\n",
      "no skill set found 'four'\n",
      "no skill set found 'considers'\n",
      "no skill set found 'crucial'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'element'\n",
      "no skill set found 'addition'\n",
      "no skill set found 'four'\n",
      "no skill set found 'csab'\n",
      "no skill set found 'also'\n",
      "no skill set found 'identifies'\n",
      "no skill set found 'field'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'database'\n",
      "no skill set found 'parallel'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'interaction'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'operating'\n",
      "no skill set found 'numerical'\n",
      "no skill set found 'symbolic'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'important'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'abstract'\n",
      "no skill set found 'spirit'\n",
      "no skill set found 'derives'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'everyday'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'nature'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'efficient'\n",
      "no skill set found 'related'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'logic'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'could'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'clearly'\n",
      "no skill set found 'drawn'\n",
      "no skill set found 'field'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'commonly'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'accord'\n",
      "no skill set found 'peter'\n",
      "no skill set found 'denning'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'efficiently'\n",
      "no skill set found 'automate'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'amount'\n",
      "no skill set found 'require'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'effort'\n",
      "no skill set found 'computability'\n",
      "no skill set found 'examines'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'solvable'\n",
      "no skill set found 'various'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'second'\n",
      "no skill set found 'address'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'complexity'\n",
      "no skill set found 'associate'\n",
      "no skill set found 'different'\n",
      "no skill set found 'multitude'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'famous'\n",
      "no skill set found 'millennium'\n",
      "no skill set found 'prize'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'related'\n",
      "no skill set found 'quantification'\n",
      "no skill set found 'developed'\n",
      "no skill set found 'claude'\n",
      "no skill set found 'shannon'\n",
      "no skill set found 'limit'\n",
      "no skill set found 'signal'\n",
      "no skill set found 'processing'\n",
      "no skill set found 'compress'\n",
      "no skill set found 'reliably'\n",
      "no skill set found 'store'\n",
      "no skill set found 'cod'\n",
      "no skill set found 'code'\n",
      "no skill set found 'convert'\n",
      "no skill set found 'form'\n",
      "no skill set found 'another'\n",
      "no skill set found 'fitness'\n",
      "no skill set found 'specific'\n",
      "no skill set found 'application'\n",
      "no skill set found 'code'\n",
      "no skill set found 'compression'\n",
      "no skill set found 'cryptography'\n",
      "no skill set found 'error'\n",
      "no skill set found 'detection'\n",
      "no skill set found 'correction'\n",
      "no skill set found 'recently'\n",
      "no skill set found 'also'\n",
      "no skill set found 'cod'\n",
      "no skill set found 'code'\n",
      "no skill set found 'purpose'\n",
      "no skill set found 'efficient'\n",
      "no skill set found 'reliable'\n",
      "no skill set found 'transmission'\n",
      "no skill set found 'branch'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'implementation'\n",
      "no skill set found 'characterization'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'individual'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'fall'\n",
      "no skill set found 'within'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'depend'\n",
      "no skill set found 'affect'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'linguistics'\n",
      "no skill set found 'numerous'\n",
      "no skill set found 'dedicate'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'journal'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'particular'\n",
      "no skill set found 'kind'\n",
      "no skill set found 'mathematically'\n",
      "no skill set found 'specification'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'appropriate'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'contribute'\n",
      "no skill set found 'reliability'\n",
      "no skill set found 'robustness'\n",
      "no skill set found 'form'\n",
      "no skill set found 'important'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'underpin'\n",
      "no skill set found 'especially'\n",
      "no skill set found 'safety'\n",
      "no skill set found 'security'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'adjunct'\n",
      "no skill set found 'since'\n",
      "no skill set found 'help'\n",
      "no skill set found 'error'\n",
      "no skill set found 'also'\n",
      "no skill set found 'industrial'\n",
      "no skill set found 'support'\n",
      "no skill set found 'require'\n",
      "no skill set found 'however'\n",
      "no skill set found 'formal'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'mean'\n",
      "no skill set found 'usually'\n",
      "no skill set found 'safety'\n",
      "no skill set found 'security'\n",
      "no skill set found 'utmost'\n",
      "no skill set found 'importance'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'described'\n",
      "no skill set found 'application'\n",
      "no skill set found 'fairly'\n",
      "no skill set found 'broad'\n",
      "no skill set found 'variety'\n",
      "no skill set found 'theoretical'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'particular'\n",
      "no skill set found 'logic'\n",
      "no skill set found 'calculus'\n",
      "no skill set found 'formal'\n",
      "no skill set found 'automaton'\n",
      "no skill set found 'semantics'\n",
      "no skill set found 'also'\n",
      "no skill set found 'type'\n",
      "no skill set found 'algebraic'\n",
      "no skill set found 'type'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'specification'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'largely'\n",
      "no skill set found 'central'\n",
      "no skill set found 'processing'\n",
      "no skill set found 'unit'\n",
      "no skill set found 'performs'\n",
      "no skill set found 'internally'\n",
      "no skill set found 'access'\n",
      "no skill set found 'address'\n",
      "no skill set found 'memory'\n",
      "no skill set found 'field'\n",
      "no skill set found 'often'\n",
      "no skill set found 'involves'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'electrical'\n",
      "no skill set found 'select'\n",
      "no skill set found 'interconnect'\n",
      "no skill set found 'hardware'\n",
      "no skill set found 'component'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'meet'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'general'\n",
      "no skill set found 'throughput'\n",
      "no skill set found 'efficiently'\n",
      "no skill set found 'eliminate'\n",
      "no skill set found 'bottleneck'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'anticipate'\n",
      "no skill set found 'peak'\n",
      "no skill set found 'load'\n",
      "no skill set found 'benchmark'\n",
      "no skill set found 'compare'\n",
      "no skill set found 'various'\n",
      "no skill set found 'subsystem'\n",
      "no skill set found 'different'\n",
      "no skill set found 'concurrency'\n",
      "no skill set found 'several'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'execute'\n",
      "no skill set found 'simultaneously'\n",
      "no skill set found 'potentially'\n",
      "no skill set found 'interact'\n",
      "no skill set found 'number'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'developed'\n",
      "no skill set found 'general'\n",
      "no skill set found 'concurrent'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'include'\n",
      "no skill set found 'petri'\n",
      "no skill set found 'net'\n",
      "no skill set found 'calculus'\n",
      "no skill set found 'parallel'\n",
      "no skill set found 'random'\n",
      "no skill set found 'access'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'extends'\n",
      "no skill set found 'concurrency'\n",
      "no skill set found 'onto'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'connect'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'within'\n",
      "no skill set found 'private'\n",
      "no skill set found 'memory'\n",
      "no skill set found 'often'\n",
      "no skill set found 'exchange'\n",
      "no skill set found 'among'\n",
      "no skill set found 'branch'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'aim'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'worldwide'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'security'\n",
      "no skill set found 'branch'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'unauthorized'\n",
      "no skill set found 'access'\n",
      "no skill set found 'disruption'\n",
      "no skill set found 'modification'\n",
      "no skill set found 'accessibility'\n",
      "no skill set found 'usability'\n",
      "no skill set found 'intend'\n",
      "no skill set found 'cryptography'\n",
      "no skill set found 'hiding'\n",
      "no skill set found 'encryption'\n",
      "no skill set found 'therefore'\n",
      "no skill set found 'decipher'\n",
      "no skill set found 'decryption'\n",
      "no skill set found 'modern'\n",
      "no skill set found 'cryptography'\n",
      "no skill set found 'largely'\n",
      "no skill set found 'related'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'many'\n",
      "no skill set found 'encryption'\n",
      "no skill set found 'decryption'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'complexity'\n",
      "no skill set found 'database'\n",
      "no skill set found 'intend'\n",
      "no skill set found 'store'\n",
      "no skill set found 'retrieve'\n",
      "no skill set found 'amount'\n",
      "no skill set found 'easily'\n",
      "no skill set found 'database'\n",
      "no skill set found 'database'\n",
      "no skill set found 'store'\n",
      "no skill set found 'search'\n",
      "no skill set found 'database'\n",
      "no skill set found 'query'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'involves'\n",
      "no skill set found 'synthesis'\n",
      "no skill set found 'manipulation'\n",
      "no skill set found 'connect'\n",
      "no skill set found 'many'\n",
      "no skill set found 'field'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'include'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'processing'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'geometry'\n",
      "no skill set found 'heavily'\n",
      "no skill set found 'field'\n",
      "no skill set found 'special'\n",
      "no skill set found 'video'\n",
      "no skill set found 'develops'\n",
      "no skill set found 'principle'\n",
      "no skill set found 'designer'\n",
      "no skill set found 'satisfactory'\n",
      "no skill set found 'desktop'\n",
      "no skill set found 'laptop'\n",
      "no skill set found 'device'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'science'\n",
      "no skill set found 'field'\n",
      "no skill set found 'concerned'\n",
      "no skill set found 'construct'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'quantitative'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'typically'\n",
      "no skill set found 'application'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'form'\n",
      "no skill set found 'computation'\n",
      "no skill set found 'various'\n",
      "no skill set found 'discipline'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'aim'\n",
      "no skill set found 'require'\n",
      "no skill set found 'synthesize'\n",
      "no skill set found 'adaptation'\n",
      "no skill set found 'found'\n",
      "no skill set found 'animal'\n",
      "no skill set found 'origin'\n",
      "no skill set found 'cybernetics'\n",
      "no skill set found 'dartmouth'\n",
      "no skill set found 'conference'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'necessarily'\n",
      "no skill set found 'expertise'\n",
      "no skill set found 'mathematics'\n",
      "no skill set found 'symbolic'\n",
      "no skill set found 'logic'\n",
      "no skill set found 'semiotics'\n",
      "no skill set found 'electrical'\n",
      "no skill set found 'philosophy'\n",
      "no skill set found 'mind'\n",
      "no skill set found 'neurophysiology'\n",
      "no skill set found 'associate'\n",
      "no skill set found 'popular'\n",
      "no skill set found 'mind'\n",
      "no skill set found 'robotic'\n",
      "no skill set found 'main'\n",
      "no skill set found 'field'\n",
      "no skill set found 'practical'\n",
      "no skill set found 'application'\n",
      "no skill set found 'embed'\n",
      "no skill set found 'component'\n",
      "no skill set found 'require'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'start'\n",
      "no skill set found 'late'\n",
      "no skill set found 'alan'\n",
      "no skill set found 'turing'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'remains'\n",
      "no skill set found 'effectively'\n",
      "no skill set found 'unanswered'\n",
      "no skill set found 'although'\n",
      "no skill set found 'turing'\n",
      "no skill set found 'still'\n",
      "no skill set found 'ass'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'output'\n",
      "no skill set found 'scale'\n",
      "no skill set found 'automation'\n",
      "no skill set found 'evaluative'\n",
      "no skill set found 'predictive'\n",
      "no skill set found 'increasingly'\n",
      "no skill set found 'successful'\n",
      "no skill set found 'substitute'\n",
      "no skill set found 'intervention'\n",
      "no skill set found 'domain'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'application'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'modify'\n",
      "no skill set found 'affordable'\n",
      "no skill set found 'maintainable'\n",
      "no skill set found 'build'\n",
      "no skill set found 'systematic'\n",
      "no skill set found 'involve'\n",
      "no skill set found 'application'\n",
      "no skill set found 'manufacture'\n",
      "no skill set found 'maintenance'\n",
      "no skill set found 'philosopher'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'bill'\n",
      "no skill set found 'rapaport'\n",
      "no skill set found 'note'\n",
      "no skill set found 'three'\n",
      "no skill set found 'great'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'accomplish'\n",
      "no skill set found 'different'\n",
      "no skill set found 'different'\n",
      "no skill set found 'way'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'include'\n",
      "no skill set found 'many'\n",
      "no skill set found 'offer'\n",
      "no skill set found 'support'\n",
      "no skill set found 'paradigm'\n",
      "no skill set found 'distinction'\n",
      "no skill set found 'matter'\n",
      "no skill set found 'conference'\n",
      "no skill set found 'important'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'conference'\n",
      "no skill set found 'researcher'\n",
      "no skill set found 'private'\n",
      "no skill set found 'sector'\n",
      "no skill set found 'recent'\n",
      "no skill set found 'meet'\n",
      "no skill set found 'unlike'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'field'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'prestige'\n",
      "no skill set found 'conference'\n",
      "no skill set found 'paper'\n",
      "no skill set found 'great'\n",
      "no skill set found 'journal'\n",
      "no skill set found 'publication'\n",
      "no skill set found 'propose'\n",
      "no skill set found 'explanation'\n",
      "no skill set found 'relatively'\n",
      "no skill set found 'field'\n",
      "no skill set found 'require'\n",
      "no skill set found 'rapid'\n",
      "no skill set found 'well'\n",
      "no skill set found 'handle'\n",
      "no skill set found 'conference'\n",
      "no skill set found 'journal'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'know'\n",
      "no skill set found 'near'\n",
      "no skill set found 'synonym'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'taught'\n",
      "no skill set found 'school'\n",
      "no skill set found 'since'\n",
      "no skill set found 'day'\n",
      "no skill set found 'batch'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'processing'\n",
      "no skill set found 'mark'\n",
      "no skill set found 'sensitive'\n",
      "no skill set found 'card'\n",
      "no skill set found 'paper'\n",
      "no skill set found 'tape'\n",
      "no skill set found 'usually'\n",
      "no skill set found 'select'\n",
      "no skill set found 'student'\n",
      "no skill set found 'produce'\n",
      "no skill set found 'classroom'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'become'\n",
      "no skill set found 'student'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'student'\n",
      "no skill set found 'importance'\n",
      "no skill set found 'recognise'\n",
      "no skill set found 'become'\n",
      "no skill set found 'compulsory'\n",
      "no skill set found 'part'\n",
      "no skill set found 'national'\n",
      "no skill set found 'curriculum'\n",
      "no skill set found 'september'\n",
      "no skill set found 'become'\n",
      "no skill set found 'entitlement'\n",
      "no skill set found 'pupil'\n",
      "no skill set found 'school'\n",
      "no skill set found 'district'\n",
      "no skill set found 'decide'\n",
      "no skill set found 'curriculum'\n",
      "no skill set found 'provision'\n",
      "no skill set found 'fracture'\n",
      "no skill set found 'accord'\n",
      "no skill set found 'compute'\n",
      "no skill set found 'machinery'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'teacher'\n",
      "no skill set found 'csta'\n",
      "no skill set found 'adopt'\n",
      "no skill set found 'significant'\n",
      "no skill set found 'education'\n",
      "no skill set found 'school'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'institute'\n",
      "no skill set found 'electrical'\n",
      "no skill set found 'electronics'\n",
      "no skill set found 'engineer'\n",
      "no skill set found 'ieee'\n",
      "no skill set found 'produce'\n",
      "no skill set found 'world'\n",
      "no skill set found 'literature'\n",
      "no skill set found 'electrical'\n",
      "no skill set found 'electronics'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'field'\n",
      "no skill set found 'publishing'\n",
      "no skill set found 'well'\n",
      "no skill set found 'journal'\n",
      "no skill set found 'israel'\n",
      "no skill set found 'zealand'\n",
      "no skill set found 'south'\n",
      "no skill set found 'korea'\n",
      "no skill set found 'include'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'national'\n",
      "no skill set found 'secondary'\n",
      "no skill set found 'education'\n",
      "no skill set found 'curriculum'\n",
      "no skill set found 'several'\n",
      "no skill set found 'follow'\n",
      "no skill set found 'many'\n",
      "no skill set found 'country'\n",
      "no skill set found 'significant'\n",
      "no skill set found 'gender'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'education'\n",
      "no skill set found 'percent'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'degree'\n",
      "no skill set found 'united'\n",
      "no skill set found 'award'\n",
      "no skill set found 'woman'\n",
      "no skill set found 'gender'\n",
      "no skill set found 'also'\n",
      "no skill set found 'western'\n",
      "no skill set found 'country'\n",
      "no skill set found 'small'\n",
      "no skill set found 'nonexistent'\n",
      "no skill set found 'part'\n",
      "no skill set found 'world'\n",
      "no skill set found 'woman'\n",
      "no skill set found 'half'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'degree'\n",
      "no skill set found 'malaysia'\n",
      "no skill set found 'percent'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'science'\n",
      "no skill set found 'graduate'\n",
      "no skill set found 'guyana'\n",
      "no skill set found 'woman'\n",
      "no skill set found 'bibliography'\n",
      "no skill set found 'academic'\n",
      "no skill set found 'search'\n",
      "no skill set found 'engine'\n",
      "no skill set found 'misc'\n",
      " Classification algorithms \n",
      "opening first-result\n",
      "in machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.  examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).  classification is an example of pattern recognition.\n",
      "in the terminology of machine learning,[1] classification is considered an instance of supervised learning, i.e., learning where a training set of correctly identified observations is available.  the corresponding unsupervised procedure is known as clustering, and involves grouping data into categories based on some measure of inherent similarity or distance.\n",
      "often, the individual observations are analyzed into a set of quantifiable properties, known variously as explanatory variables or features.  these properties may variously be categorical (e.g. \"a\", \"b\", \"ab\" or \"o\", for blood type), ordinal (e.g. \"large\", \"medium\" or \"small\"), integer-valued (e.g. the number of occurrences of a particular word in an email) or real-valued (e.g. a measurement of blood pressure). other classifiers work by comparing observations to previous observations by means of a similarity or distance function.\n",
      "an algorithm that implements classification, especially in a concrete implementation, is known as a classifier.  the term \"classifier\" sometimes also refers to the mathematical function, implemented by a classification algorithm, that maps input data to a category.\n",
      "terminology across fields is quite varied. in statistics, where classification is often done with logistic regression or a similar procedure, the properties of observations are termed explanatory variables (or independent variables, regressors, etc.), and the categories to be predicted are known as outcomes, which are considered to be possible values of the dependent variable.  in machine learning, the observations are often known as instances, the explanatory variables are termed features (grouped into a feature vector), and the possible categories to be predicted are classes.  other fields may use different terminology: e.g. in community ecology, the term \"classification\" normally refers to cluster analysis, i.e., a type of unsupervised learning, rather than the supervised learning described in this article.\n",
      "\n",
      "no skill set found 'machine'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'belongs'\n",
      "no skill set found 'basis'\n",
      "no skill set found 'contain'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'instance'\n",
      "no skill set found 'whose'\n",
      "no skill set found 'membership'\n",
      "no skill set found 'know'\n",
      "no skill set found 'assign'\n",
      "no skill set found 'email'\n",
      "no skill set found 'spam'\n",
      "no skill set found 'class'\n",
      "no skill set found 'assign'\n",
      "no skill set found 'diagnosis'\n",
      "no skill set found 'patient'\n",
      "no skill set found 'characteristic'\n",
      "no skill set found 'patient'\n",
      "no skill set found 'blood'\n",
      "no skill set found 'pressure'\n",
      "no skill set found 'absence'\n",
      "no skill set found 'certain'\n",
      "no skill set found 'symptom'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'recognition'\n",
      "no skill set found 'terminology'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'instance'\n",
      "no skill set found 'correctly'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'available'\n",
      "no skill set found 'correspond'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'know'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'involves'\n",
      "no skill set found 'inherent'\n",
      "no skill set found 'similarity'\n",
      "no skill set found 'distance'\n",
      "no skill set found 'often'\n",
      "no skill set found 'individual'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'quantifiable'\n",
      "no skill set found 'know'\n",
      "no skill set found 'variously'\n",
      "no skill set found 'explanatory'\n",
      "no skill set found 'variable'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'variously'\n",
      "no skill set found 'categorical'\n",
      "no skill set found 'blood'\n",
      "no skill set found 'type'\n",
      "no skill set found 'ordinal'\n",
      "no skill set found 'small'\n",
      "no skill set found 'number'\n",
      "no skill set found 'occurrence'\n",
      "no skill set found 'particular'\n",
      "no skill set found 'email'\n",
      "no skill set found 'blood'\n",
      "no skill set found 'pressure'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'compare'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'previous'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'mean'\n",
      "no skill set found 'similarity'\n",
      "no skill set found 'distance'\n",
      "no skill set found 'function'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'especially'\n",
      "no skill set found 'concrete'\n",
      "no skill set found 'implementation'\n",
      "no skill set found 'know'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'sometimes'\n",
      "no skill set found 'also'\n",
      "no skill set found 'refers'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'function'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'input'\n",
      "no skill set found 'terminology'\n",
      "no skill set found 'field'\n",
      "no skill set found 'quite'\n",
      "no skill set found 'varied'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'often'\n",
      "no skill set found 'do'\n",
      "no skill set found 'logistic'\n",
      "no skill set found 'regression'\n",
      "no skill set found 'similar'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'explanatory'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'variable'\n",
      "no skill set found 'independent'\n",
      "no skill set found 'variable'\n",
      "no skill set found 'regressors'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'know'\n",
      "no skill set found 'outcome'\n",
      "no skill set found 'consider'\n",
      "no skill set found 'possible'\n",
      "no skill set found 'dependent'\n",
      "no skill set found 'variable'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'often'\n",
      "no skill set found 'know'\n",
      "no skill set found 'instance'\n",
      "no skill set found 'explanatory'\n",
      "no skill set found 'variable'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'grouped'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'possible'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'class'\n",
      "no skill set found 'field'\n",
      "no skill set found 'different'\n",
      "no skill set found 'terminology'\n",
      "no skill set found 'ecology'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'normally'\n",
      "no skill set found 'refers'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'type'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'rather'\n",
      "no skill set found 'described'\n",
      "no skill set found 'article'\n",
      " Training data \n",
      "page-found\n",
      "in machine learning, the study and construction of algorithms that can learn from and make predictions on data[1] is a common task. such algorithms work by making data-driven predictions or decisions,[2]:2 through building a mathematical model from input data.\n",
      "the data used to build the final model usually comes from multiple datasets. in particular, three data sets are commonly used in different stages of the creation of the model.\n",
      "the model is initially fit on a training dataset,[3] that is a set of examples used to fit the parameters (e.g. weights of connections between neurons in artificial neural networks) of the model.[4] the model (e.g. a neural net or a naive bayes classifier) is trained on the training dataset using a supervised learning method (e.g. gradient descent or stochastic gradient descent). in practice, the training dataset often consist of pairs of an input vector (or scalar) and the corresponding output vector (or scalar), which is commonly denoted as the target (or label). the current model is run with the training dataset and produces a result, which is then compared with the target, for each input vector in the training dataset. based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. the model fitting can include both variable selection and parameter estimation.\n",
      "successively, the fitted model is used to predict the responses for the observations in a second dataset called the validation dataset.[3] the validation dataset provides an unbiased evaluation of a model fit on the training dataset while tuning the model's hyperparameters [5] (e.g. the number of hidden units in a neural network[4]). validation datasets can be used for regularization by early stopping: stop training when the error on the validation dataset increases, as this is a sign of overfitting to the training dataset.[6]\n",
      "this simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. this complication has led to the creation of many ad-hoc rules for deciding when overfitting has truly begun.[6]\n",
      "finally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset.[5] when the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.\n",
      "\n",
      "no skill set found 'machine'\n",
      "no skill set found 'construction'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'input'\n",
      "no skill set found 'build'\n",
      "no skill set found 'final'\n",
      "no skill set found 'usually'\n",
      "no skill set found 'come'\n",
      "no skill set found 'datasets'\n",
      "no skill set found 'particular'\n",
      "no skill set found 'three'\n",
      "no skill set found 'commonly'\n",
      "no skill set found 'different'\n",
      "no skill set found 'initially'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'parameter'\n",
      "no skill set found 'weight'\n",
      "no skill set found 'connection'\n",
      "no skill set found 'neuron'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'neural'\n",
      "no skill set found 'neural'\n",
      "no skill set found 'naive'\n",
      "no skill set found 'bayes'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'gradient'\n",
      "no skill set found 'descent'\n",
      "no skill set found 'stochastic'\n",
      "no skill set found 'gradient'\n",
      "no skill set found 'descent'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'often'\n",
      "no skill set found 'consist'\n",
      "no skill set found 'pair'\n",
      "no skill set found 'input'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'scalar'\n",
      "no skill set found 'correspond'\n",
      "no skill set found 'output'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'scalar'\n",
      "no skill set found 'commonly'\n",
      "no skill set found 'denote'\n",
      "no skill set found 'label'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'produce'\n",
      "no skill set found 'compare'\n",
      "no skill set found 'input'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'comparison'\n",
      "no skill set found 'specific'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'parameter'\n",
      "no skill set found 'adjust'\n",
      "no skill set found 'fitting'\n",
      "no skill set found 'include'\n",
      "no skill set found 'variable'\n",
      "no skill set found 'parameter'\n",
      "no skill set found 'estimation'\n",
      "no skill set found 'successively'\n",
      "no skill set found 'fit'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'observation'\n",
      "no skill set found 'second'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'validation'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'validation'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'tune'\n",
      "no skill set found 'hyperparameters'\n",
      "no skill set found 'number'\n",
      "no skill set found 'hidden'\n",
      "no skill set found 'unit'\n",
      "no skill set found 'neural'\n",
      "no skill set found 'validation'\n",
      "no skill set found 'datasets'\n",
      "no skill set found 'regularization'\n",
      "no skill set found 'early'\n",
      "no skill set found 'stop'\n",
      "no skill set found 'stop'\n",
      "no skill set found 'error'\n",
      "no skill set found 'validation'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'increase'\n",
      "no skill set found 'sign'\n",
      "no skill set found 'overfitting'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'simple'\n",
      "no skill set found 'complicate'\n",
      "no skill set found 'fact'\n",
      "no skill set found 'validation'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'error'\n",
      "no skill set found 'fluctuate'\n",
      "no skill set found 'produce'\n",
      "no skill set found 'local'\n",
      "no skill set found 'minimum'\n",
      "no skill set found 'complication'\n",
      "no skill set found 'many'\n",
      "no skill set found 'rule'\n",
      "no skill set found 'decide'\n",
      "no skill set found 'overfitting'\n",
      "no skill set found 'truly'\n",
      "no skill set found 'begin'\n",
      "no skill set found 'finally'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'final'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'never'\n",
      "no skill set found 'dataset'\n",
      "no skill set found 'also'\n",
      "no skill set found 'holdout'\n",
      "no skill set found 'dataset'\n",
      " Learning systems \n",
      "opening first-result\n",
      "\n",
      "a learning management system (lms) is a software application for the administration, documentation, tracking, reporting and delivery of educational courses, training programs, or learning and development programs.[1] the learning management system concept emerged directly from e-learning. although the first lms appeared in the higher education sector, the majority of the lmss today focus on the corporate market. learning management systems make up the largest segment of the learning system market. the first introduction of the lms was in the late 1990s.[2]\n",
      "learning management systems were designed to identify training and learning gaps, utilizing analytical data and reporting. lmss are focused on online learning delivery but support a range of uses, acting as a platform for online content, including courses, both asynchronous based and synchronous based.  an lms may offer classroom management for instructor-led training or a flipped classroom, used in higher education, but not in the corporate space.\n",
      "\n",
      "no skill set found 'application'\n",
      "no skill set found 'documentation'\n",
      "no skill set found 'educational'\n",
      "no skill set found 'course'\n",
      "no skill set found 'emerge'\n",
      "no skill set found 'directly'\n",
      "no skill set found 'although'\n",
      "no skill set found 'appear'\n",
      "no skill set found 'education'\n",
      "no skill set found 'sector'\n",
      "no skill set found 'majority'\n",
      "no skill set found 'lm'\n",
      "no skill set found 'today'\n",
      "no skill set found 'segment'\n",
      "no skill set found 'late'\n",
      "no skill set found 'utilize'\n",
      "no skill set found 'analytical'\n",
      "no skill set found 'lm'\n",
      "no skill set found 'online'\n",
      "no skill set found 'support'\n",
      "no skill set found 'us'\n",
      "no skill set found 'act'\n",
      "no skill set found 'platform'\n",
      "no skill set found 'online'\n",
      "no skill set found 'include'\n",
      "no skill set found 'course'\n",
      "no skill set found 'asynchronous'\n",
      "no skill set found 'synchronous'\n",
      "no skill set found 'offer'\n",
      "no skill set found 'classroom'\n",
      "no skill set found 'flip'\n",
      "no skill set found 'classroom'\n",
      "no skill set found 'education'\n",
      " Educational institutions \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page-found\n",
      "an educational institution is a place where people of different ages gain an education.[1] examples of some institutions are preschools, primary schools, secondary schools, and further and higher education. they provide a large variety of learning environments and learning spaces. the institution can be public, private or unconventional.\n",
      "the american educational system typically divides learning facilities by an age grade system. students are designated to a grade level based on their age, advancing one grade each year. they are required to learn and do tasks at this level or they will be set back a grade. this designation determines what educational institution would be an appropriate setting for the individual student.\n",
      "\n",
      "no skill set found 'educational'\n",
      "no skill set found 'institution'\n",
      "no skill set found 'place'\n",
      "no skill set found 'different'\n",
      "no skill set found 'age'\n",
      "no skill set found 'gain'\n",
      "no skill set found 'education'\n",
      "no skill set found 'institution'\n",
      "no skill set found 'preschool'\n",
      "no skill set found 'primary'\n",
      "no skill set found 'school'\n",
      "no skill set found 'secondary'\n",
      "no skill set found 'school'\n",
      "no skill set found 'education'\n",
      "no skill set found 'variety'\n",
      "no skill set found 'institution'\n",
      "no skill set found 'private'\n",
      "no skill set found 'unconventional'\n",
      "no skill set found 'american'\n",
      "no skill set found 'educational'\n",
      "no skill set found 'typically'\n",
      "no skill set found 'facility'\n",
      "no skill set found 'grade'\n",
      "no skill set found 'student'\n",
      "no skill set found 'designate'\n",
      "no skill set found 'grade'\n",
      "no skill set found 'advance'\n",
      "no skill set found 'grade'\n",
      "no skill set found 'year'\n",
      "no skill set found 'require'\n",
      "no skill set found 'back'\n",
      "no skill set found 'grade'\n",
      "no skill set found 'designation'\n",
      "no skill set found 'determines'\n",
      "no skill set found 'educational'\n",
      "no skill set found 'institution'\n",
      "no skill set found 'would'\n",
      "no skill set found 'appropriate'\n",
      "no skill set found 'individual'\n",
      "no skill set found 'student'\n",
      " Support vector machines \n",
      "page-found\n",
      "in machine learning, support-vector machines (svms, also support-vector networks[1]) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.  given a set of training examples, each marked as belonging to one or the other of two categories, an svm training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as platt scaling exist to use svm in a probabilistic classification setting). a svm model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. new examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
      "in addition to performing linear classification, svms can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
      "when data is unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. the support-vector clustering[2] algorithm, created by hava siegelmann and vladimir vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data, and is one of the most widely used clustering algorithms in industrial applications.[citation needed]\n",
      "\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'svms'\n",
      "no skill set found 'also'\n",
      "no skill set found 'associate'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'regression'\n",
      "no skill set found 'marked'\n",
      "no skill set found 'belonging'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'build'\n",
      "no skill set found 'assigns'\n",
      "no skill set found 'binary'\n",
      "no skill set found 'linear'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'although'\n",
      "no skill set found 'platt'\n",
      "no skill set found 'scale'\n",
      "no skill set found 'exist'\n",
      "no skill set found 'probabilistic'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'mapped'\n",
      "no skill set found 'wide'\n",
      "no skill set found 'possible'\n",
      "no skill set found 'mapped'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'belong'\n",
      "no skill set found 'side'\n",
      "no skill set found 'fall'\n",
      "no skill set found 'addition'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'linear'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'svms'\n",
      "no skill set found 'efficiently'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'kernel'\n",
      "no skill set found 'implicitly'\n",
      "no skill set found 'mapping'\n",
      "no skill set found 'input'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'unlabelled'\n",
      "no skill set found 'possible'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'require'\n",
      "no skill set found 'natural'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'form'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'hava'\n",
      "no skill set found 'siegelmann'\n",
      "no skill set found 'vladimir'\n",
      "no skill set found 'vapnik'\n",
      "no skill set found 'applies'\n",
      "no skill set found 'support'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'developed'\n",
      "no skill set found 'support'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'categorize'\n",
      "no skill set found 'unlabeled'\n",
      "no skill set found 'widely'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'industrial'\n",
      "no skill set found 'application'\n",
      "no skill set found 'citation'\n",
      " Support vector machine classification \n",
      "opening first-result\n",
      "in machine learning, support-vector machines (svms, also support-vector networks[1]) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.  given a set of training examples, each marked as belonging to one or the other of two categories, an svm training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as platt scaling exist to use svm in a probabilistic classification setting). a svm model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. new examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
      "in addition to performing linear classification, svms can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
      "when data is unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. the support-vector clustering[2] algorithm, created by hava siegelmann and vladimir vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data, and is one of the most widely used clustering algorithms in industrial applications.[citation needed]\n",
      "\n",
      "no skill set found 'machine'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'svms'\n",
      "no skill set found 'also'\n",
      "no skill set found 'associate'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'regression'\n",
      "no skill set found 'marked'\n",
      "no skill set found 'belonging'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'build'\n",
      "no skill set found 'assigns'\n",
      "no skill set found 'binary'\n",
      "no skill set found 'linear'\n",
      "no skill set found 'classifier'\n",
      "no skill set found 'although'\n",
      "no skill set found 'platt'\n",
      "no skill set found 'scale'\n",
      "no skill set found 'exist'\n",
      "no skill set found 'probabilistic'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'mapped'\n",
      "no skill set found 'wide'\n",
      "no skill set found 'possible'\n",
      "no skill set found 'mapped'\n",
      "no skill set found 'predict'\n",
      "no skill set found 'belong'\n",
      "no skill set found 'side'\n",
      "no skill set found 'fall'\n",
      "no skill set found 'addition'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'linear'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'svms'\n",
      "no skill set found 'efficiently'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'classification'\n",
      "no skill set found 'kernel'\n",
      "no skill set found 'implicitly'\n",
      "no skill set found 'mapping'\n",
      "no skill set found 'input'\n",
      "no skill set found 'feature'\n",
      "no skill set found 'unlabelled'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no skill set found 'possible'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'require'\n",
      "no skill set found 'natural'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'form'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'hava'\n",
      "no skill set found 'siegelmann'\n",
      "no skill set found 'vladimir'\n",
      "no skill set found 'vapnik'\n",
      "no skill set found 'applies'\n",
      "no skill set found 'support'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'developed'\n",
      "no skill set found 'support'\n",
      "no skill set found 'vector'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'categorize'\n",
      "no skill set found 'unlabeled'\n",
      "no skill set found 'widely'\n",
      "no skill set found 'cluster'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'industrial'\n",
      "no skill set found 'application'\n",
      "no skill set found 'citation'\n",
      " Machine learning \n",
      "page-found\n",
      "machine learning (ml) is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead. it is seen as a subset of artificial intelligence. machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.[1][2]:2 machine learning algorithms are used in a wide variety of applications, such as email filtering, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. machine learning is closely related to computational statistics, which focuses on making predictions using computers. the study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning.[3][4] in its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'effectively'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'specific'\n",
      "no skill set found 'explicit'\n",
      "no skill set found 'instruction'\n",
      "no skill set found 'rely'\n",
      "no skill set found 'inference'\n",
      "no skill set found 'instead'\n",
      "no skill set found 'subset'\n",
      "no skill set found 'artificial'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'build'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'know'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'explicitly'\n",
      "no skill set found 'programmed'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'wide'\n",
      "no skill set found 'variety'\n",
      "no skill set found 'application'\n",
      "no skill set found 'email'\n",
      "no skill set found 'filter'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'infeasible'\n",
      "no skill set found 'algorithm'\n",
      "no skill set found 'specific'\n",
      "no skill set found 'instruction'\n",
      "no skill set found 'perform'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'closely'\n",
      "no skill set found 'related'\n",
      "no skill set found 'computational'\n",
      "no skill set found 'prediction'\n",
      "no skill set found 'computer'\n",
      "no skill set found 'mathematical'\n",
      "no skill set found 'delivers'\n",
      "no skill set found 'application'\n",
      "no skill set found 'domain'\n",
      "no skill set found 'field'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'mining'\n",
      "no skill set found 'field'\n",
      "no skill set found 'within'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'exploratory'\n",
      "no skill set found 'unsupervised'\n",
      "no skill set found 'application'\n",
      "no skill set found 'machine'\n",
      "no skill set found 'also'\n",
      "no skill set found 'refer'\n",
      "no skill set found 'predictive'\n",
      " Data models \n",
      "page-found\n",
      "a data model (or datamodel[1][2][3][4][5]) is an abstract model that organizes elements of data and standardizes how they relate to one another and to properties of the real world entities. for instance, a data model may specify that the data element representing a car be composed of a number of other elements which, in turn, represent the color and size of the car and define its owner.\n",
      "the term data model is used in two distinct but closely related senses. sometimes it refers to an abstract formalization of the objects and relationships found in a particular application domain, for example the customers, products, and orders found in a manufacturing organization. at other times it refers to a set of concepts used in defining such formalizations: for example concepts such as entities, attributes, relations, or tables. so the \"data model\" of a banking application may be defined using the entity-relationship \"data model\". this article uses the term in both senses.\n",
      "a data model explicitly determines the structure of data. data models are specified in a data modeling notation, which is often graphical in form.[7]\n",
      "a data model can sometimes be referred to as a data structure, especially in the context of programming languages. data models are often complemented by function models, especially in the context of enterprise models.\n",
      "\n",
      "no skill set found 'datamodel'\n",
      "no skill set found 'abstract'\n",
      "no skill set found 'organizes'\n",
      "no skill set found 'element'\n",
      "no skill set found 'standardizes'\n",
      "no skill set found 'relate'\n",
      "no skill set found 'another'\n",
      "no skill set found 'world'\n",
      "no skill set found 'entity'\n",
      "no skill set found 'instance'\n",
      "no skill set found 'specify'\n",
      "no skill set found 'element'\n",
      "no skill set found 'represent'\n",
      "no skill set found 'compose'\n",
      "no skill set found 'number'\n",
      "no skill set found 'element'\n",
      "no skill set found 'turn'\n",
      "no skill set found 'represent'\n",
      "no skill set found 'color'\n",
      "no skill set found 'size'\n",
      "no skill set found 'owner'\n",
      "no skill set found 'distinct'\n",
      "no skill set found 'closely'\n",
      "no skill set found 'related'\n",
      "no skill set found 'sens'\n",
      "no skill set found 'sometimes'\n",
      "no skill set found 'refers'\n",
      "no skill set found 'abstract'\n",
      "no skill set found 'formalization'\n",
      "no skill set found 'object'\n",
      "no skill set found 'found'\n",
      "no skill set found 'particular'\n",
      "no skill set found 'application'\n",
      "no skill set found 'domain'\n",
      "no skill set found 'found'\n",
      "no skill set found 'manufacturing'\n",
      "no skill set found 'refers'\n",
      "no skill set found 'formalization'\n",
      "no skill set found 'entity'\n",
      "no skill set found 'attribute'\n",
      "no skill set found 'table'\n",
      "no skill set found 'banking'\n",
      "no skill set found 'application'\n",
      "no skill set found 'article'\n",
      "no skill set found 'us'\n",
      "no skill set found 'sens'\n",
      "no skill set found 'explicitly'\n",
      "no skill set found 'determines'\n",
      "no skill set found 'specify'\n",
      "no skill set found 'notation'\n",
      "no skill set found 'often'\n",
      "no skill set found 'graphical'\n",
      "no skill set found 'form'\n",
      "no skill set found 'sometimes'\n",
      "no skill set found 'refer'\n",
      "no skill set found 'especially'\n",
      "no skill set found 'context'\n",
      "no skill set found 'often'\n",
      "no skill set found 'complement'\n",
      "no skill set found 'function'\n",
      "no skill set found 'especially'\n",
      "no skill set found 'context'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #print(get_first_para('computer vision'))\n",
    "    for original in dore: \n",
    "        print(original)\n",
    "        w1=get_first_para(original)\n",
    "        w2=word_tokenize(w1)\n",
    "        \n",
    "        print(w1)\n",
    "\n",
    "        for word in w2:                                                                 \n",
    "            if word not in stop and word.__len__()>3 and word.isalpha():\n",
    "                w3 = get_skills(skill_dict, word)\n",
    "                for x in w3:\n",
    "                    vo_set.add(x)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'risk assessments',\n",
       " 'conducting procurement',\n",
       " 'information architecture',\n",
       " 'direct marketing',\n",
       " 'technology scope creep management (feature creep)',\n",
       " 'preserving and enhancing reputation',\n",
       " 'program management plans',\n",
       " 'product concept design',\n",
       " 'financial analysis for program decisions',\n",
       " 'strategic cost management',\n",
       " 'self confidence',\n",
       " 'scientific diagrams',\n",
       " 'sales force management',\n",
       " 'strategic decision making',\n",
       " 'information analysis',\n",
       " 'using project management tools',\n",
       " 'mentoring & coaching',\n",
       " 'recognizing employee performance',\n",
       " 'communications',\n",
       " 'advertising strategy and management',\n",
       " 'organization',\n",
       " 'managing large accounts',\n",
       " 'diagrams',\n",
       " 'diplomacy techniques',\n",
       " 'tactical decision making',\n",
       " 'managing productivity',\n",
       " 'developing project management plans',\n",
       " 'program priorities',\n",
       " 'social proof',\n",
       " 'politics',\n",
       " 'managing stress',\n",
       " 'corporate budgets and financial statements',\n",
       " 'scope management',\n",
       " 'niche marketing',\n",
       " 'introducing yourself',\n",
       " 'risk impact analysis',\n",
       " 'leading change',\n",
       " 'cost control',\n",
       " 'demonstrating empathy & understanding of customer problems',\n",
       " 'accountability matrices',\n",
       " 'program lifecycle',\n",
       " 'project team acquisition',\n",
       " 'sponsoring projects and programs',\n",
       " 'conflict management',\n",
       " 'greetings',\n",
       " 'applying patterns of market change',\n",
       " 'perceiving emotions',\n",
       " 'reporting & communication',\n",
       " 'inducing change of perspective',\n",
       " 'improvisation',\n",
       " 'program standards',\n",
       " 'project integration',\n",
       " 'corporate communication',\n",
       " 'visual reasoning',\n",
       " 'conversation',\n",
       " 'mental sharpness and inventiveness',\n",
       " 'time management',\n",
       " 'creating a sense of urgency and ownership',\n",
       " 'cost-benefit analysis',\n",
       " 'delegation of responsibilities',\n",
       " 'strategic market measurement',\n",
       " 'observing & analyzing emotions',\n",
       " 'flexibility',\n",
       " 'intelligent and curious',\n",
       " 'endurance',\n",
       " 'project scheduling',\n",
       " 'customer retention management',\n",
       " 'sales pipeline management',\n",
       " 'applying humor to achieve business results.',\n",
       " 'content marketing',\n",
       " 'market knowledge',\n",
       " 'time analysis',\n",
       " 'meeting management',\n",
       " 'strategic hiring',\n",
       " 'charisma',\n",
       " 'ability to take criticism',\n",
       " 'accounting management',\n",
       " 'emphasis',\n",
       " 'managing contacts',\n",
       " 'targeted communication',\n",
       " 'need creation',\n",
       " 'change impact analysis',\n",
       " 'courage',\n",
       " 'financial analysis for decisions',\n",
       " 'establishing partnerships and alliances',\n",
       " 'applying negotiation strategy',\n",
       " 'storytelling',\n",
       " 'counterparty risk management',\n",
       " 'work breakdown structure',\n",
       " 'organizing',\n",
       " 'verbal communication',\n",
       " 'category strategy',\n",
       " 'promotional merchandise',\n",
       " 'using an advocate (shuttle diplomacy)',\n",
       " 'controlling disruptive emotions',\n",
       " 'account management',\n",
       " 'facilitating',\n",
       " 'managing virtual teams',\n",
       " 'risk reporting',\n",
       " 'corporate social responsibility',\n",
       " 'using accounting tools',\n",
       " 'effect use of space (e.g. walking around)',\n",
       " 'politics & diplomacy',\n",
       " 'procurement logistics',\n",
       " 'personal skills',\n",
       " 'evaluation of commercial opportunities',\n",
       " 'industry knowledge',\n",
       " 'developing relationship audience',\n",
       " 'mobile marketing',\n",
       " 'customer service',\n",
       " 'effective word choice',\n",
       " 'brand strategy',\n",
       " 'developing strategic alliances',\n",
       " 'program & project audits',\n",
       " 'measuring organizational performance',\n",
       " 'setting direction and influencing people to follow.',\n",
       " 'restructuring & corporate governance',\n",
       " 'building trust',\n",
       " 'situation analysis',\n",
       " 'research & development',\n",
       " 'developing rfis and rfps',\n",
       " 'innovation management',\n",
       " 'it standards & best practices (e.g. itil)',\n",
       " 'leading extended enterprises (multi-firm structures)',\n",
       " 'managing teams',\n",
       " 'business process management',\n",
       " 'public speaking & presentations',\n",
       " 'continuous business improvement',\n",
       " 'developing program road maps',\n",
       " 'buying time (e. g. snow job)',\n",
       " 'conciseness',\n",
       " 'agreeableness',\n",
       " 'establishing social proof',\n",
       " 'corporate financial management',\n",
       " 'time awareness',\n",
       " 'emotional intelligence',\n",
       " 'big picture thinking',\n",
       " 'creative thinking',\n",
       " 'sapience',\n",
       " 'decision analysis',\n",
       " 'change management',\n",
       " 'procurement negotiations',\n",
       " 'intuition',\n",
       " 'sales recruiting',\n",
       " 'human resource management',\n",
       " 'technology savvy',\n",
       " 'analogies',\n",
       " 'stakeholder analysis',\n",
       " 'operations management',\n",
       " 'analysis of customer buy cycles',\n",
       " 'aligning others around short term and long range plans',\n",
       " 'trend analysis',\n",
       " 'developing assumption & risk based project plans',\n",
       " 'visual expression of emotion',\n",
       " 'managing change',\n",
       " 'facilitation',\n",
       " 'photography',\n",
       " 'intonation',\n",
       " 'plain language (i.e. avoid needless jargon and flowery words)',\n",
       " 'facial expressions',\n",
       " 'sales and operations planning',\n",
       " 'framing problems',\n",
       " 'diplomatic language',\n",
       " 'strategy planning',\n",
       " 'deflecting personal attacks',\n",
       " 'program direction',\n",
       " 'graphs',\n",
       " 'supply chain management',\n",
       " 'risk response planning',\n",
       " 'engaging conversation',\n",
       " 'developing project resource plans',\n",
       " 'financial performance assessment',\n",
       " 'using emotions',\n",
       " 'tolerance of change and uncertainty',\n",
       " 'financial modeling',\n",
       " 'aesthetic sense',\n",
       " 'developing proposals',\n",
       " 'software development methodologies',\n",
       " 'unbiased thinking',\n",
       " 'advertising management',\n",
       " 'mindmaps',\n",
       " 'soft skills',\n",
       " 'pitching ideas & proposals',\n",
       " 'corporate restructuring',\n",
       " 'influencing & motivation techniques',\n",
       " 'emotion management',\n",
       " 'logistics assessments',\n",
       " 'identification and evaluation of market opportunities',\n",
       " 'identifying and seizing fast breaking opportunities',\n",
       " 'financing operations & investment',\n",
       " 'scope creep management',\n",
       " 'competitive analysis',\n",
       " 'data transformations',\n",
       " 'category management',\n",
       " 'maps (cartography)',\n",
       " 'project budget development',\n",
       " 'managing liability',\n",
       " 'corporate capital structure',\n",
       " 'quick-wittedness',\n",
       " 'leading by example',\n",
       " 'creating a high performance culture',\n",
       " 'visual literacy',\n",
       " 'managing contracts',\n",
       " 'loyalty marketing',\n",
       " 'marketing law (e. g. product liability)',\n",
       " 'targeting information to an audience',\n",
       " 'vendor relationship management',\n",
       " 'stage presence',\n",
       " 'professional ethics',\n",
       " 'technology trend awareness',\n",
       " 'balanced scorecard',\n",
       " 'control of the voice (intonation & inflection)',\n",
       " 'exploring possibilities',\n",
       " 'leadership assessment & development',\n",
       " 'positive words, negative body language',\n",
       " 'managing uncertainty & ambiguity',\n",
       " 'sustainability and corporate social responsibility',\n",
       " 'providing feedback',\n",
       " 'effective greetings',\n",
       " 'graphic design',\n",
       " 'sales promotion',\n",
       " 'taking criticism',\n",
       " 'raising capital',\n",
       " 'team management',\n",
       " 'editing',\n",
       " 'developing cost estimates',\n",
       " 'product demonstration',\n",
       " 'speaking skills',\n",
       " 'problem visualization',\n",
       " 'breakthrough thinking',\n",
       " 'business financing',\n",
       " 'digital marketing',\n",
       " 'integrated marketing communications',\n",
       " 'transition plans',\n",
       " 'visual communication',\n",
       " 'networking (before and after speaking)',\n",
       " 'quality assurance',\n",
       " 'focus groups',\n",
       " 'gestures / using space',\n",
       " 'managing relationships with the board of directors',\n",
       " 'supplier communication',\n",
       " 'visual communication design',\n",
       " 'understanding emotions',\n",
       " 'multi-channel communications',\n",
       " 'marketing vision & mission',\n",
       " 'personal time management',\n",
       " 'critical thinking',\n",
       " 'managing incentives',\n",
       " 'empathy',\n",
       " 'benchmarking',\n",
       " 'program assessments',\n",
       " 'resource allocation',\n",
       " 'procurement',\n",
       " 'commercial perspective',\n",
       " 'cultural competence',\n",
       " 'influencing',\n",
       " 'identifying leads',\n",
       " 'using change management tools',\n",
       " 'organization and time management',\n",
       " 'influencing skills',\n",
       " 'political savvy',\n",
       " 'leading an organization',\n",
       " 'mentoring sales teams',\n",
       " 'networking',\n",
       " 'business development',\n",
       " 'business law',\n",
       " 'selling',\n",
       " 'adaptability',\n",
       " 'hierarchies',\n",
       " 'customer relationships',\n",
       " 'intellectual property law',\n",
       " 'marketing simulation',\n",
       " 'simplifying complex ideas',\n",
       " 'physical communication',\n",
       " 'awareness of procurement laws & regulations',\n",
       " 'pricing management',\n",
       " 'contract law',\n",
       " 'using humor & wit',\n",
       " 'continuous improvement',\n",
       " 'building productive relationships',\n",
       " 'strategy',\n",
       " 'communicating values',\n",
       " 'managing to schedule',\n",
       " 'foot-in-the-door techniques',\n",
       " 'gestures',\n",
       " 'championing initiatives',\n",
       " 'market research',\n",
       " 'product differentiation',\n",
       " 'using silence',\n",
       " 'using sfa & crm tools',\n",
       " 'design analysis',\n",
       " 'sales force deployment',\n",
       " 'prioritization',\n",
       " 'sustaining a brand',\n",
       " 'inspiring',\n",
       " 'establishing a corporate culture',\n",
       " 'identifying project synergies',\n",
       " 'championing a vision',\n",
       " 'risk monitoring and control',\n",
       " 'customer analysis',\n",
       " 'program performance & quality metrics',\n",
       " 'maintaining internal auditing standards',\n",
       " 'knowledge management',\n",
       " 'building rapport',\n",
       " 'word choice',\n",
       " 'managing sales quotas & incentives',\n",
       " 'contract management',\n",
       " 'streamlining',\n",
       " 'humor',\n",
       " 'international marketing',\n",
       " 'self control',\n",
       " 'project closure',\n",
       " 'cross-cultural competence',\n",
       " 'time accounting',\n",
       " 'managing appointments',\n",
       " 'visual expression of concepts',\n",
       " 'call management',\n",
       " 'paraphrasing',\n",
       " 'reduction',\n",
       " 'managing relationships',\n",
       " 'what-if analysis',\n",
       " 'competitive focus',\n",
       " 'cost/benefit analysis',\n",
       " 'introductions',\n",
       " 'leading business transformation',\n",
       " 'managing group dynamics',\n",
       " 'creating and maintaining a high performance culture',\n",
       " 'marketing',\n",
       " 'current state analysis',\n",
       " 'social skills',\n",
       " 'revenue management',\n",
       " 'analyzing rfps',\n",
       " 'order management',\n",
       " 'stress management',\n",
       " 'regulatory compliance',\n",
       " 'project logistics (e.g. establishing a pmo office)',\n",
       " 'developing business plans',\n",
       " 'managing strategic objectives',\n",
       " 'drawing',\n",
       " 'budget control',\n",
       " 'approvals management',\n",
       " 'program strategy & objectives',\n",
       " 'project planning',\n",
       " 'use of objective criteria',\n",
       " 'willingness to take responsibility',\n",
       " 'management of sales training and development programs',\n",
       " 'performance management',\n",
       " 'modeling concepts',\n",
       " 'engineering drawings',\n",
       " 'humor & quick-wittedness',\n",
       " 'project management',\n",
       " 'employment law',\n",
       " 'strategic planning',\n",
       " 'first impressions',\n",
       " 'managing training',\n",
       " 'written and visual communication',\n",
       " 'monitoring results',\n",
       " 'liaison with finance & marketing',\n",
       " 'effective use of a whiteboard',\n",
       " 'strategic decision-making',\n",
       " 'business & industry knowledge',\n",
       " 'marketing operations management',\n",
       " 'managing risk-return',\n",
       " 'risk management tools (e.g. risk databases)',\n",
       " 'schedule buy-in',\n",
       " 'conflict resolution',\n",
       " 'technical assessments',\n",
       " 'avoiding escalations',\n",
       " \"protecting and growing a firm's assets\",\n",
       " 'sales deal approvals',\n",
       " 'procurement management',\n",
       " 'sales communications',\n",
       " 'fluid intelligence',\n",
       " 'remote associations',\n",
       " 'use of props',\n",
       " 'using time management tools',\n",
       " 'presentation skills',\n",
       " 'quality planning',\n",
       " 'project metric development and communications',\n",
       " 'brand management',\n",
       " 'communication plans',\n",
       " 'arrangement',\n",
       " 'establishing rapport',\n",
       " 'research',\n",
       " 'innovation',\n",
       " 'interpersonal skills',\n",
       " 'influencing without authority',\n",
       " 'brand audit',\n",
       " 'managing stakeholder expectations',\n",
       " 'opportunity management',\n",
       " 'consistency',\n",
       " 'media selection and planning',\n",
       " 'protecting and growing assets',\n",
       " 'defining mission, vision and values',\n",
       " 'business trend awareness',\n",
       " 'product portfolio management',\n",
       " 'budget administration',\n",
       " 'developing strategic business models',\n",
       " 'swot analysis',\n",
       " 'real estate strategy',\n",
       " 'cross-cultural leadership',\n",
       " 'communications to executive leadership',\n",
       " 'hypothesis testing',\n",
       " 'self awareness',\n",
       " 'program performance analysis',\n",
       " 'implementing and maintaining standards & best practices',\n",
       " 'creating brand ambassadors',\n",
       " 'page layout design',\n",
       " 'distributed team management (geographically distributed project teams)',\n",
       " 'multiple idea facilitation',\n",
       " 'goal & objective planning',\n",
       " 'building relationships of trust',\n",
       " 'launch marketing',\n",
       " 'giving feedback',\n",
       " 'kpis',\n",
       " 'cost leadership',\n",
       " 'influence to negotiate',\n",
       " 'visual presentation',\n",
       " 'governance',\n",
       " 'personal branding',\n",
       " 'strategic planning and analysis',\n",
       " 'active listening',\n",
       " 'financial metrics',\n",
       " 'managing social dilemmas',\n",
       " 'disability awareness',\n",
       " 'compensation and benefits',\n",
       " 'collaborating',\n",
       " 'managing remote teams',\n",
       " 'developing quality plans',\n",
       " 'the ability to influence an audience.',\n",
       " 'sales forecasting',\n",
       " 'crafting a brand',\n",
       " 'payment of sales commissions & incentives',\n",
       " \"ability to see other people's point of view\",\n",
       " 'negotiating across organizational boundaries',\n",
       " 'web design',\n",
       " 'managerial statistics',\n",
       " 'applying innovation techniques',\n",
       " 'listening.',\n",
       " 'integration management',\n",
       " 'nibble techniques',\n",
       " 'fashion sense',\n",
       " 'developing a relationship with an audience',\n",
       " 'dealing with difficult personalities',\n",
       " 'short-term financial management',\n",
       " 'playfulness',\n",
       " 'decision tree analysis',\n",
       " 'account-based marketing',\n",
       " 'transnational market strategies',\n",
       " 'task tracking',\n",
       " 'financial analysis for corporate decisions',\n",
       " 'reasoning',\n",
       " 'leadership approvals & financial authorizations',\n",
       " 'managing communications to the board of directors',\n",
       " 'managing project issues',\n",
       " 'listening skills',\n",
       " 'marketing communications',\n",
       " 'body language',\n",
       " 'taking criticism resilience',\n",
       " 'portfolio management',\n",
       " 'business forecasting',\n",
       " 'inflection of the voice',\n",
       " 'work breakdown structures (wbs)',\n",
       " 'employment law awareness',\n",
       " 'feasibility analysis',\n",
       " 'quality strategy',\n",
       " 'franchising',\n",
       " 'developing metrics & kpi',\n",
       " 'risk analysis',\n",
       " 'artistic ability',\n",
       " 'strategic management',\n",
       " 'style',\n",
       " 'lateral thinking',\n",
       " 'strategic decisions to acquire, merge or divest',\n",
       " 'sales organization design',\n",
       " 'business process improvement',\n",
       " 'action-oriented',\n",
       " 'marketing management',\n",
       " 'international business',\n",
       " 'managing emotions',\n",
       " 'business planning',\n",
       " 'writing reports and proposals',\n",
       " 'making a good first impression',\n",
       " 'speaking rhythm',\n",
       " 'sustainability',\n",
       " 'empowering others',\n",
       " 'logistics',\n",
       " 'remote consequences',\n",
       " 'providing clear direction',\n",
       " 'structuring acquisitions',\n",
       " 'organization skills',\n",
       " 'door-in-the-face techniques',\n",
       " 'optimism',\n",
       " 'leveraging a brand',\n",
       " 'win-win thinking',\n",
       " 'pareto analysis (80-rule)',\n",
       " 'marketing change',\n",
       " 'product benchmarking',\n",
       " 'sense of urgency',\n",
       " 'consumer insights',\n",
       " 'variance forecasting',\n",
       " 'root cause analysis',\n",
       " 'curiosity',\n",
       " 'building rapport with an audience',\n",
       " 'recognizing attempts to trigger emotional responses',\n",
       " 'office politics',\n",
       " 'networking skills',\n",
       " 'operational analysis',\n",
       " 'results-focus',\n",
       " 'training',\n",
       " 'designing graphics',\n",
       " 'architecture management',\n",
       " 'divergent thinking',\n",
       " 'removing obstacles for teams',\n",
       " 'design sense',\n",
       " 'applying economic models',\n",
       " 'validates relevance',\n",
       " 'real estate financial analysis',\n",
       " 'forecasting',\n",
       " 'training, coaching & mentoring',\n",
       " 'strategic human resource management',\n",
       " 'stakeholder management',\n",
       " 'analysis of customer-side politics',\n",
       " 'intellectual property laws and guidelines',\n",
       " 'developing business plans & estimates',\n",
       " 'establishing rapport with clients',\n",
       " 'corporate multi-national tax strategy',\n",
       " 'service level agreements',\n",
       " 'developing sales proposals',\n",
       " 'identifying underlying conflict',\n",
       " 'sourcing',\n",
       " 'effective meetings',\n",
       " 'global operations strategy',\n",
       " 'assessing the emotions of others',\n",
       " 'business ethics',\n",
       " 'market assessments',\n",
       " 'expectation management',\n",
       " 'interpersonal relationships',\n",
       " 'delegation',\n",
       " 'mediation',\n",
       " 'identifying & prioritizing alternatives',\n",
       " 'holding leaders accountable for results',\n",
       " 'program strategy alignment',\n",
       " 'corporate innovation',\n",
       " 'supervising',\n",
       " 'scenario analysis',\n",
       " 'status communication',\n",
       " 'energy',\n",
       " 'diversity awareness',\n",
       " 'targeted communications',\n",
       " 'organization design',\n",
       " 'business & product development',\n",
       " 'job planning',\n",
       " 'developing interpersonal relationships',\n",
       " 'channel management',\n",
       " 'managing estimates',\n",
       " 'test marketing',\n",
       " 'train the trainer',\n",
       " 'task planning',\n",
       " 'questioning clients & identifying customer requirements',\n",
       " 'enterprise resource planning',\n",
       " 'mental state shift',\n",
       " 'regulatory and legal constraints',\n",
       " 'modeling information',\n",
       " 'language proficiency',\n",
       " 'managing project execution',\n",
       " 'managing sales partners',\n",
       " 'international business negotiations (e.g. inter-cultural)',\n",
       " 'business model development',\n",
       " 'promoting improved methods',\n",
       " 'managing budgets',\n",
       " 'managing difficult people',\n",
       " 'visualization standards',\n",
       " 'building tension and suspense',\n",
       " 'presenting to a hostile audience',\n",
       " 'controlling impulses',\n",
       " 'product development',\n",
       " 'art',\n",
       " 'enterprise resource management',\n",
       " 'assertiveness',\n",
       " 'sales program formulation',\n",
       " 'decisions making',\n",
       " 'governance processes and procedures',\n",
       " 'establishing rapport & trust',\n",
       " 'procurement planning',\n",
       " 'persuasion (ethos, pathos, and logos)',\n",
       " 'identifying needs',\n",
       " 'procurement issue management',\n",
       " 'passion for pursuing goals',\n",
       " 'critical design',\n",
       " 'managing global operations',\n",
       " 'thought experiment',\n",
       " 'choice modeling',\n",
       " 'concept maps',\n",
       " 'developing strategic profit models',\n",
       " 'establishing common ground',\n",
       " 'negotiation',\n",
       " 'managing procurement closure activities',\n",
       " 'communication skills',\n",
       " 'modeling business decisions',\n",
       " 'financial closure processes',\n",
       " 'introspection',\n",
       " 'vendor management',\n",
       " 'sampling (statistics)',\n",
       " 'maintaining long-term relationships',\n",
       " 'product research',\n",
       " 'accountability',\n",
       " 'allocating resources',\n",
       " 'measurement of ad effectiveness',\n",
       " 'fostering personal courage in others',\n",
       " 'financial analysis for project decisions',\n",
       " 'closing deals',\n",
       " 'risk probability analysis',\n",
       " 'trend awareness',\n",
       " 'scheduling',\n",
       " 'business savvy',\n",
       " 'benefit optimization',\n",
       " 'whiteboarding',\n",
       " 'quality standards & best practices',\n",
       " 'negotiating techniques and strategy',\n",
       " 'strategic management of technology',\n",
       " 'new product development',\n",
       " 'r&d management',\n",
       " 'developing project charters',\n",
       " 'scope control and verification',\n",
       " 'counterfactual thinking',\n",
       " 'delivering a call to action',\n",
       " 'business writing (e.g. reports, emails)',\n",
       " 'environmental regulations',\n",
       " 'performance appraisal',\n",
       " 'budget variance analysis',\n",
       " 'timelines',\n",
       " 'monitoring',\n",
       " 'dispute resolution',\n",
       " 'marketing intelligence management',\n",
       " 'symbols',\n",
       " 'imagination',\n",
       " 'managing integrated teams',\n",
       " 'continual improvement',\n",
       " 'public relations',\n",
       " 'preparing executive summaries',\n",
       " 'cost forecasting',\n",
       " 'selective listening',\n",
       " 'new product acceptance',\n",
       " 'effective use of visual aids',\n",
       " 'interviewing',\n",
       " 'slogans',\n",
       " 'abc analysis',\n",
       " 'activity sequencing',\n",
       " 'corporate entrepreneurship',\n",
       " 'dealing with ambiguity',\n",
       " 'brainstorming',\n",
       " 'cost management',\n",
       " 'process improvement',\n",
       " 'reporting task status',\n",
       " 'artistic sense',\n",
       " 'risk management',\n",
       " 'public speaking',\n",
       " 'using visual display technologies',\n",
       " 'branding',\n",
       " 'multi-party negotiations',\n",
       " 'digital strategy',\n",
       " 'marketing mix modeling',\n",
       " 'project management information systems',\n",
       " 'target market analysis',\n",
       " 'negotiation strategy',\n",
       " 'communication',\n",
       " 'strategic procurement',\n",
       " 'managing resistance to change',\n",
       " 'managing priorities',\n",
       " 'business negotiations',\n",
       " 'commercialization of business capabilities',\n",
       " 'friendliness',\n",
       " 'program schedule management',\n",
       " 'human resource requirements',\n",
       " 'managing a portfolio of it investments',\n",
       " 'plain language (clear word choice that avoids jargon)',\n",
       " 'guerrilla marketing',\n",
       " 'developing communication plans',\n",
       " 'budgeting & financial management',\n",
       " 'investor relations',\n",
       " 'sales motivation & sales contests',\n",
       " 'managing people',\n",
       " 'performance evaluation',\n",
       " 'ethics',\n",
       " 'facilitating meetings',\n",
       " 'influence over external power structures (e.g. industry influence)',\n",
       " 'social and opinion research',\n",
       " 'managing business analysis',\n",
       " 'sales territory management',\n",
       " 'ability to simplify complex ideas',\n",
       " 'management',\n",
       " 'managing business architecture',\n",
       " 'planning & scheduling',\n",
       " 'project status communications',\n",
       " 'speculative design',\n",
       " 'modeling decisions',\n",
       " 'program initiation',\n",
       " 'business analysis',\n",
       " 'developing sales collaterals',\n",
       " 'building retreat paths',\n",
       " 'attunement to social norms',\n",
       " 'developing high potential talent',\n",
       " 'leading teams',\n",
       " 'focus',\n",
       " 'developing schedules',\n",
       " 'writing',\n",
       " 'user-centered design',\n",
       " 'strategic tax planning',\n",
       " 'market and business forecasting',\n",
       " 'quote management',\n",
       " 'manage sales partners',\n",
       " 'resilience',\n",
       " 'incubation techniques',\n",
       " 'demonstrating good faith',\n",
       " 'short term and long term focus',\n",
       " 'motivating salespeople',\n",
       " 'identifying & validating assumptions',\n",
       " 'clearing roadblocks',\n",
       " 'project gate reviews',\n",
       " 'customer retention strategy',\n",
       " 'selling product benefits',\n",
       " 'identifying project constraints',\n",
       " 'contract negotiation',\n",
       " 'sales information & technology strategy',\n",
       " 'program scope',\n",
       " 'mentoring',\n",
       " 'strategic analysis',\n",
       " 'managing executive stakeholders',\n",
       " 'program communications',\n",
       " 'community engagement',\n",
       " 'managing radical change',\n",
       " 'sales collaterals',\n",
       " 'conceptual blending',\n",
       " 'information privacy',\n",
       " 'strategic management of innovation',\n",
       " 'coaching',\n",
       " 'morphological analysis',\n",
       " 'brand asset management',\n",
       " 'sales metrics & kpi',\n",
       " 'aleatory techniques',\n",
       " 'gut decisions',\n",
       " 'language abilities',\n",
       " 'program mission and vision',\n",
       " 'network visualization (representing relationships)',\n",
       " 'sales-marketing alignment',\n",
       " 'financial management in a dynamic regulatory environment',\n",
       " 'benefits management',\n",
       " 'self-discipline',\n",
       " 'lessons learned',\n",
       " 'governance models',\n",
       " 'sales team performance management',\n",
       " 'prioritization and resource allocation',\n",
       " 'program management',\n",
       " 'decision making by formalizing trade-offs',\n",
       " 'financial policy decisions',\n",
       " 'fashion and look',\n",
       " 'openness',\n",
       " 'establishing contacts',\n",
       " 'organizing a company (legal structure)',\n",
       " 'managing difficult conversations',\n",
       " 'digital business strategy',\n",
       " 'running sales contests',\n",
       " 'pareto analysis',\n",
       " 'developing work breakdown structures',\n",
       " 'persuasion.',\n",
       " 'making good first impressions',\n",
       " 'business disputes',\n",
       " 'managing team dynamics',\n",
       " 'functional sense',\n",
       " 'goal focus',\n",
       " 'product positioning',\n",
       " 'developing useful metaphors',\n",
       " 'promoting brand awareness',\n",
       " 'planning',\n",
       " 'corporate governance',\n",
       " 'body language & facial expressions',\n",
       " 'expense management',\n",
       " 'treemaping',\n",
       " 'visual analytics',\n",
       " 'strategic analysis of accounting information',\n",
       " 'articulate speech',\n",
       " 'answering questions',\n",
       " 'innovative thinking',\n",
       " 'spatial analysis',\n",
       " 'business acumen',\n",
       " 'developing solutions to multidimensional problems',\n",
       " 'earned value management',\n",
       " 'tone',\n",
       " 'technical drawings',\n",
       " 'statistical graphics',\n",
       " 'channels management',\n",
       " 'presentation skills & public speaking',\n",
       " 'rewards & loyalty programs',\n",
       " 'willingness to lead',\n",
       " 'business communication',\n",
       " 'creative direction',\n",
       " 'intelligence',\n",
       " 'managing financial risk',\n",
       " 'using visualization tools',\n",
       " 'project audits',\n",
       " 'active silence',\n",
       " 'quality control',\n",
       " 'project work control',\n",
       " 'simplifying complex ideas with visual representations',\n",
       " 'presentation flow',\n",
       " 'brand measurement and reporting',\n",
       " 'managing a client engagement',\n",
       " 'applying data to decisions',\n",
       " 'cross-cultural management',\n",
       " 'organizational awareness',\n",
       " 'establishing trust',\n",
       " 'protecting your time',\n",
       " 'physical communication & body language',\n",
       " 'managing risk',\n",
       " 'compliance',\n",
       " 'sales reporting',\n",
       " 'managing diversity',\n",
       " 'operations financing',\n",
       " 'quality management',\n",
       " 'real estate management',\n",
       " 'developing and reporting metrics and kpis',\n",
       " 'escalating schedule issues',\n",
       " 'answering customer questions',\n",
       " 'program budgeting',\n",
       " 'copy writing',\n",
       " 'statistical analysis',\n",
       " 'computer-aided design',\n",
       " 'capturing and maintaining attention',\n",
       " 'risk prioritization',\n",
       " 'managing selling costs',\n",
       " 'product launch',\n",
       " 'scope development',\n",
       " 'ensuring corporate transparency',\n",
       " 'argument maps',\n",
       " 'commercializing business capabilities',\n",
       " 'illustration',\n",
       " 'dealing with difficult people',\n",
       " 'framing (i. e. framing a visual argument)',\n",
       " 'project team development',\n",
       " 'strong eye contact',\n",
       " 'tolerance for ambiguity',\n",
       " 'provide direction & focus',\n",
       " 'funding models',\n",
       " 'endurance & persistence',\n",
       " 'project management best practices',\n",
       " 'bmarketing',\n",
       " 'effective presentation of self',\n",
       " 'variance monitoring',\n",
       " 'originality',\n",
       " 'establishing authority',\n",
       " 'operations strategy',\n",
       " 'advertising',\n",
       " 'engaging employees',\n",
       " 'debating',\n",
       " 'intercultural competence',\n",
       " 'developing presentations',\n",
       " 'setting sales targets, quotas and incentives',\n",
       " 'developing a vision',\n",
       " 'action focus',\n",
       " 'order fulfillment management',\n",
       " 'organizational planning',\n",
       " 'strategic business development',\n",
       " 'building an effective argument',\n",
       " 'identifying critical success factors',\n",
       " 'infonomics',\n",
       " 'trust & verify',\n",
       " 'business value measurement',\n",
       " 'business etiquette',\n",
       " 'separating the people from the problem',\n",
       " 'gap analysis',\n",
       " 'defending a brand',\n",
       " 'self assessment',\n",
       " 'organizational design',\n",
       " 'time management strategy',\n",
       " 'networking with external executive leaders',\n",
       " 'conscientiousness',\n",
       " 'problem solving',\n",
       " 'identifying constraints',\n",
       " 'presentations',\n",
       " 'customer segmentation',\n",
       " 'posture',\n",
       " 'developing and managing budgets',\n",
       " 'product life cycle management',\n",
       " 'appealing to group narcissism (e.g. chicago is my favorite town!)',\n",
       " 'social media marketing',\n",
       " 'adaptability & resilience',\n",
       " 'sales management',\n",
       " 'crisis communication',\n",
       " 'verbal & visual communication',\n",
       " 'more: management skills',\n",
       " 'negotiating',\n",
       " 'resilience & endurance',\n",
       " 'issue escalation',\n",
       " 'setting priorities',\n",
       " 'photo editing',\n",
       " 'resource leveling',\n",
       " 'schedule control',\n",
       " 'long-term financial management',\n",
       " 'market economics',\n",
       " 'conducting feasibility studies',\n",
       " 'decision frameworks',\n",
       " 'executive communication',\n",
       " 'product knowledge',\n",
       " 'technical communication',\n",
       " 'communications to customers',\n",
       " 'team building',\n",
       " 'manager management',\n",
       " 'clarity',\n",
       " 'product strategy',\n",
       " 'presentations to hostile audiences',\n",
       " 'sales force supervision',\n",
       " 'market segmentation',\n",
       " 'developing requirements',\n",
       " 'bringing conflict into the open',\n",
       " 'international business negotiations',\n",
       " 'performance feedback',\n",
       " 'setting goals',\n",
       " 'art direction',\n",
       " 'effective use of microphone and sound system',\n",
       " 'reputation management',\n",
       " 'communications to stakeholders',\n",
       " 'performance management (talent management)',\n",
       " 'gap identification',\n",
       " 'managing top talent',\n",
       " 'sales strategy',\n",
       " 'time management leadership',\n",
       " 'price models',\n",
       " 'self-presentation',\n",
       " 'diplomacy',\n",
       " 'change control management',\n",
       " 'delivery',\n",
       " 'regulatory reporting',\n",
       " 'plan sales training & development',\n",
       " 'licensing (intellectual property)',\n",
       " 'client and stakeholder relationship management',\n",
       " 'ability to analyze your own emotions',\n",
       " 'managing upsell activities',\n",
       " 'monitoring & controlling projects',\n",
       " 'customer experience management',\n",
       " 'social skill',\n",
       " 'results focus',\n",
       " 'managing quality',\n",
       " 'eye contact',\n",
       " 'corporate image',\n",
       " 'identifying customer requirements & needs',\n",
       " 'logistics management',\n",
       " 'typography',\n",
       " 'persuasion',\n",
       " 'program & project issue management',\n",
       " 'listening',\n",
       " 'market analysis',\n",
       " 'technology management',\n",
       " 'heatmaps',\n",
       " 'project & program governance',\n",
       " 'strategic program management',\n",
       " 'communicating change',\n",
       " 'sensemaking',\n",
       " 'retention strategy',\n",
       " 'distribution strategy',\n",
       " 'financial management',\n",
       " 'defining activities',\n",
       " 'game theory and business strategy',\n",
       " 'financial reporting',\n",
       " 'entrepreneurial thinking',\n",
       " 'calling bluffs & naming negotiation tricks',\n",
       " 'recruiting',\n",
       " 'software development lifecycle',\n",
       " 'motivating',\n",
       " 'saying no with positive words',\n",
       " 'public speaking & presentation skills',\n",
       " 'sales performance management',\n",
       " 'decision making',\n",
       " 'language ability',\n",
       " 'positioning',\n",
       " 'product concept testing',\n",
       " 'marketing measurement (metrics & kpi)',\n",
       " 'market segmentation analysis',\n",
       " 'event management',\n",
       " 'cultural sense',\n",
       " 'use-centered design',\n",
       " 'competitor analysis',\n",
       " 'a fundamental aspect of communication in every culture.',\n",
       " 'sales margin management',\n",
       " 'applying data to decision making',\n",
       " 'working capital efficiency',\n",
       " 'divide and conquer',\n",
       " 'social intelligence',\n",
       " 'it governance',\n",
       " 'setting objectives',\n",
       " 'manage customer relationship management (crm) information',\n",
       " 'managing',\n",
       " 'succession planning',\n",
       " 'managing sales productivity',\n",
       " 'leadership',\n",
       " 'creative questioning',\n",
       " 'benefits analysis',\n",
       " 'financial analysis',\n",
       " 'organizational planning for projects',\n",
       " 'work force diversity',\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facilitation skills\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def load_skill_set2():\n",
    "\n",
    "    skill_dict = dict()\n",
    "    pick_file = open(\"final_skill_dict_2.pickle\", \"rb\")\n",
    "    skill_dict = pickle.load(pick_file)\n",
    "    pick_file.close()\n",
    "    return skill_dict\n",
    "\n",
    "\n",
    "def get_skill2(skill_dic,topic):\n",
    "    return skill_dic[ lemmatizer.lemmatize(topic.strip()) ]\n",
    "\n",
    "\n",
    "# skill_dict = make_skill_dict()\n",
    "skill_dict2 = load_skill_set2()\n",
    "\n",
    "print(get_skill2(skill_dict2,'procurement management'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(vo_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = set()\n",
    "for i in vo_set:\n",
    "    if i in skill_dict2:\n",
    "        new_set.add(get_skill2(skill_dict2,i))\n",
    "\n",
    "len(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------NON- TECHNICAL SKILLS---------------\n",
      "legal & compliance\n",
      "observing & analyzing\n",
      "influencing to negotiate\n",
      "hard bargaining\n",
      "business & product development\n",
      "idea formation\n",
      "leadership of visual communication\n",
      "persuasion techniques\n",
      "scope management\n",
      "sale\n",
      "legal, risk & compliance\n",
      "negotiation skills\n",
      "quality management\n",
      "program lifecycle\n",
      "marketing\n",
      "operation\n",
      "reporting & communication\n",
      "perceiving emotions\n",
      "sales strategy\n",
      "time management\n",
      "technology\n",
      "sales pipeline management\n",
      "information visualization\n",
      "targeted communication\n",
      "negotiation\n",
      "communication skills\n",
      "mba skills\n",
      "organizational behavior\n",
      "marketing & sales\n",
      "conflict resolution\n",
      "personal skills\n",
      "visual abilities\n",
      "basic leadership skills\n",
      "procurement management\n",
      "artistic abilities\n",
      "core executive leadership skills\n",
      "executive management\n",
      "presentation skills\n",
      "core skills\n",
      "managing teams\n",
      "brand management\n",
      "problem solving\n",
      "technology (for it project management)\n",
      "establishing rapport\n",
      "interpersonal skills\n",
      "innovation\n",
      "emotional intelligence\n",
      "marketing approaches\n",
      "entrepreneurial skills\n",
      "change management\n",
      "sales management\n",
      "creative skills\n",
      "presenting visual information\n",
      "finance\n",
      "negotiating\n",
      "information modeling & design\n",
      "selling skills\n",
      "facilitation skills\n",
      "cost management\n",
      "core project management skills\n",
      "managing visual information\n",
      "risk management\n",
      "using emotions\n",
      "managerial finance\n",
      "soft skills\n",
      "interpersonal\n",
      "professional skills\n",
      "governance\n",
      "communication\n",
      "diplomacy\n",
      "delivery\n",
      "applying innovation techniques\n",
      "negotiation planning\n",
      "integration management\n",
      "stage presence\n",
      "persuasion\n",
      "management\n",
      "management focus areas\n",
      "strategic program management\n",
      "professional communication\n",
      "public speaking skills\n",
      "sales operations\n",
      "time management methods\n",
      "marketing communications\n",
      "writing\n",
      "speaking skills\n",
      "decision making\n",
      "visual communication\n",
      "business execution\n",
      "mergers, acquisitions & divestiture\n",
      "core management skills\n",
      "human resources\n",
      "understanding emotions\n",
      "international business\n",
      "managing emotions\n",
      "promotion\n",
      "project\n",
      "marketing strategy & planning\n",
      "leadership\n",
      "marketing operations & sales\n",
      "technical skills\n",
      "cultural competence\n",
      "benefits management\n",
      "influencing\n",
      "networking\n",
      "human resources management\n",
      "business development\n",
      "business law\n",
      "selling\n",
      "stakeholder management\n",
      "strategy\n",
      "complex negotiations\n",
      "market research\n",
      "program management skills\n"
     ]
    }
   ],
   "source": [
    "print('--------------NON- TECHNICAL SKILLS---------------')\n",
    "for word in new_set:\n",
    "    print(word)\n",
    "my_list2 = list(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('nontech2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(my_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out reading just the extract for the technical skills\n",
    "import os\n",
    "files = [os.path.join('testing', fi) for fi in os.listdir('testing')]\n",
    "my_text = []\n",
    "from nltk.tokenize import word_tokenize\n",
    "for fil in files:\n",
    "    with open(fil) as fi:\n",
    "            line = fi.read()\n",
    "            temp= word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = list(temp)\n",
    "my_text =  [w.lower() for w in temp2 if not w.lower() in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['support', 'vector', 'machines']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_set = set()\n",
    "for q in my_text:\n",
    "    if q in skill_dict:\n",
    "        veu = get_skills(skill_dict,q)\n",
    "        for qw in veu:\n",
    "            q_set.add(qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qw in q_set:\n",
    "    print(qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_set = set()\n",
    "for i in q_set:\n",
    "    qq_set.add(get_skill2(skill_dict2,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for ele in qq_set:\n",
    "    temp = temp + (word_tokenize(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict123 = {}\n",
    "my_final = {}\n",
    "my_final['others'] = set()\n",
    "print(temp)\n",
    "for i in temp:\n",
    "    if i in dict123:\n",
    "        dict123[i] = dict123[i]+1\n",
    "    else:\n",
    "        dict123[i] = 1\n",
    "for ele in qq_set:\n",
    "    w = word_tokenize(ele)\n",
    "    for i in w:\n",
    "        if dict123[i]>5:\n",
    "            if i in my_final:\n",
    "                my_final[i].add(ele)\n",
    "            else:\n",
    "                my_final[i] = set()\n",
    "                my_final[i].add(ele)\n",
    "        if dict123[i]<2:\n",
    "            my_final['others'].add(ele)\n",
    "len(qq_set)\n",
    "len(my_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'others': set()}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------    Anupams dictionary  --------  ###\n",
    "\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import pickle\n",
    "# import xlrd\n",
    "\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# # print(sheet.cell_value(0,0))\n",
    "\n",
    "\n",
    "# def make_skill_dict_final():\n",
    "\n",
    "#     file = (\"test_files/skills_anupam.xlsx\")\n",
    "\n",
    "#     wb = xlrd.open_workbook(file)\n",
    "#     sheet = wb.sheet_by_index(0)\n",
    "\n",
    "#     # print(len(lines))\n",
    "#     skill_dict = {}\n",
    "\n",
    "#     root_skill = ''\n",
    "#     for i in range(sheet.nrows):\n",
    "#         if sheet.cell_value(i,0) != '':\n",
    "#             root_skill = lemmatizer.lemmatize(sheet.cell_value(i, 0).strip().lower())\n",
    "\n",
    "#         for j in range(sheet.ncols):\n",
    "\n",
    "#             if sheet.cell_value(i, j) != '':\n",
    "#                 key = lemmatizer.lemmatize(sheet.cell_value(i, j).strip().lower())\n",
    "\n",
    "#                 if key in skill_dict:\n",
    "#                     skill_dict[key].add(root_skill)\n",
    "#                 else:\n",
    "#                     skill_dict[key] = {root_skill}\n",
    "\n",
    "#     print(\"printing dict.......\")\n",
    "#     for key in skill_dict:\n",
    "#         print(str(key).ljust(40) + str(skill_dict[key]).rjust(40))\n",
    "\n",
    "#     pick_file = open(\"anupam_skill_dict.pickle\",\"wb\")\n",
    "#     pickle.dump(skill_dict, pick_file)\n",
    "#     pick_file.close()\n",
    "\n",
    "#     return skill_dict\n",
    "\n",
    "\n",
    "# def load_skill_set_final():\n",
    "\n",
    "#     pick_file = open(\"anupam_skill_dict.pickle\", \"rb\")\n",
    "#     skill_dict = pickle.load(pick_file)\n",
    "#     pick_file.close()\n",
    "#     return skill_dict\n",
    "\n",
    "\n",
    "# def get_skill_final(skill_dic,topic):\n",
    "#     topic = lemmatizer.lemmatize(topic.strip().lower())\n",
    "#     if topic in skill_dic:\n",
    "#         return skill_dic[topic]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # skill_dict = make_skill_dict()\n",
    "# skill_dict_final = load_skill_set()\n",
    "\n",
    "# print(get_skill_final(skill_dict_final,'motivate'))\n",
    "# # while True:\n",
    "# #     inp = input(\"topic:\")\n",
    "# #     print(get_skill(skill_dict,inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Technical skills---------------\n",
      " Machine learning algorithms \n",
      " Computer science \n",
      " Classification algorithms \n",
      " Training data \n",
      " Learning systems \n",
      " Educational institutions \n",
      " Support vector machines \n",
      " Support vector machine classification \n",
      " Machine learning \n",
      " Data models \n",
      "\n",
      "----------------Technical skills---------------\n",
      "\n",
      "--------------------------------\n",
      "             -- others --\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------------Technical skills---------------')\n",
    "for zzz in dore:\n",
    "    print(zzz)\n",
    "print()\n",
    "print('----------------Technical skills---------------')\n",
    "print()\n",
    "\n",
    "for i in my_final:\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('             --', i , '--')\n",
    "    print('---------------------------------')\n",
    "    for j in my_final[i]:\n",
    "        print(j, ',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
