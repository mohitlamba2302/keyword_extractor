Alleviating Credit Assignment problem using deep representation learning with application to Push Recovery learning
we propose two new methods to accelerate the learning of a task using Q-learning algorithm. We focus specifically on learning of a task, which has the Credit Assignment (CA) problem. A Reinforcement Algorithm (RL) agent is performing this task in high dimensional state-space. The main idea of this paper is to use latent variables that deep autoencoders provide, to make a better rewarding system. We show that using these new rewards speeds up learning of the task in the similar circumstances. The task chosen for the algorithm is Push Recovery (PR) in a simulated environment.
